INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "Rice", "echo": true}' message='Post details'
DEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1662 request_id=7c46ee4345214d9b4f5ec15f598a0379 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Rice' data=<OpenAIObject text_completion id=cmpl-5vrzJ1ro95XFtU6lP1saESNPGOqNv at 0x159152b10> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Rice University art history history knowledge building Rice"
    }
  ],
  "created": 1664473909,
  "id": "cmpl-5vrzJ1ro95XFtU6lP1saESNPGOqNv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 7,
    "prompt_tokens": 2,
    "total_tokens": 9
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 153576
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "Cleveland", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 317
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=281 request_id=27de26c9148c2a7640ca132c5973b48a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Cleveland' data=<OpenAIObject text_completion id=cmpl-5vrzjbvZ5mCL0jK3Z0dS0hghAeO9D at 0x158eba890> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "Cleveland oklahoma city you are you"
    }
  ],
  "created": 1664473935,
  "id": "cmpl-5vrzjbvZ5mCL0jK3Z0dS0hghAeO9D",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 6,
    "prompt_tokens": 3,
    "total_tokens": 9
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 122854
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "Google", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 325
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=240 request_id=44f7537c1ac3f17b19d9f4185aa1005c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Google' data=<OpenAIObject text_completion id=cmpl-5vrzkKJRFOTcYdyTg6JQWR7wBYE4S at 0x1589ee6b0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Google -> Facebook Android you are you is"
    }
  ],
  "created": 1664473936,
  "id": "cmpl-5vrzkKJRFOTcYdyTg6JQWR7wBYE4S",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 7,
    "prompt_tokens": 1,
    "total_tokens": 8
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 168623
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "Borges", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 315
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=215 request_id=2f5fdf556ff3a3f95bc38f7721490cd6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Borges' data=<OpenAIObject text_completion id=cmpl-5vrzle5kzHl3Fb9d4R1q8dnofehv6 at 0x15919a1b0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Borges has become a meme\n\nRe"
    }
  ],
  "created": 1664473937,
  "id": "cmpl-5vrzle5kzHl3Fb9d4R1q8dnofehv6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 7,
    "prompt_tokens": 3,
    "total_tokens": 10
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 153695
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "Mom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 314
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=214 request_id=03d04acfafd90cacc5a1a8ff50913222 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Mom' data=<OpenAIObject text_completion id=cmpl-5vrzmYzJQRkboURn30jjb6nAbLiJo at 0x12110c360> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Mom -> you are you you are you"
    }
  ],
  "created": 1664473938,
  "id": "cmpl-5vrzmYzJQRkboURn30jjb6nAbLiJo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 7,
    "prompt_tokens": 1,
    "total_tokens": 8
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 168511
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 7, "top_p": 0.95, "temperature": 1, "prompt": "GPT-3", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 301
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=216 request_id=ba226c87f020f493ddb2ab3b536ea2bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'GPT-3' data=<OpenAIObject text_completion id=cmpl-5vrzn7JZRm64xh5X2ixAis6n4bTpO at 0x12106eb10> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "GPT-3-PT-3\n\nPT"
    }
  ],
  "created": 1664473939,
  "id": "cmpl-5vrzn7JZRm64xh5X2ixAis6n4bTpO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 7,
    "prompt_tokens": 4,
    "total_tokens": 11
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 168857
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Rice", "echo": true}' message='Post details'
DEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=574 request_id=d1d64610ba6dc0d6d46d607fbdc4ee9d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Rice' data=<OpenAIObject text_completion id=cmpl-5vs3WNG0Qo1fqhaYK7TDimX5FCrYA at 0x11b04c090> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Rice Wine Rice Wine is mostly a Cabernet Sauvignon-based fortified Chinese"
    }
  ],
  "created": 1664474170,
  "id": "cmpl-5vs3WNG0Qo1fqhaYK7TDimX5FCrYA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305845
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Cleveland", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d5737cdf28ce262cb85af35f89d5d32d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Cleveland' data=<OpenAIObject text_completion id=cmpl-5vs3X6UEBFAgEhiz0pVLSE815kzHh at 0x13e2e63e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Cleveland movies sports cleveland Cleveland events- you are here you are where are you?\n"
    }
  ],
  "created": 1664474171,
  "id": "cmpl-5vs3X6UEBFAgEhiz0pVLSE815kzHh",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275800
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Google", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=34eb85c5da0bd1584e44c27fc1c12019 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Google' data=<OpenAIObject text_completion id=cmpl-5vs3YNarLeHdcpq8Hy760aUeDJ3r5 at 0x11a0b1ad0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Google -> Borg you are you\n\nYou are you\n\nYou are you\n\n"
    }
  ],
  "created": 1664474172,
  "id": "cmpl-5vs3YNarLeHdcpq8Hy760aUeDJ3r5",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229953
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Borges", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=513 request_id=2c0b063456c6f515598ec6d88f416de4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Borges' data=<OpenAIObject text_completion id=cmpl-5vs3aBY6wjdbQqC3ueF2ftVqhBCPJ at 0x13e2e63e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Borges -> Google\n\nInfluencer marketing\n\nID3\n\nMarlon"
    }
  ],
  "created": 1664474174,
  "id": "cmpl-5vs3aBY6wjdbQqC3ueF2ftVqhBCPJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 199258
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Mom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9a8cd06bbfd175e6371341f79cdc48d5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Mom' data=<OpenAIObject text_completion id=cmpl-5vs3bTpzGPkZlCRHVLESWr8lqipao at 0x11de69f30> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Mom told me you were your hero mom\n\nYou are my hero\n\nI love"
    }
  ],
  "created": 1664474175,
  "id": "cmpl-5vs3bTpzGPkZlCRHVLESWr8lqipao",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244863
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "GPT-3", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 328
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4111a77dd98c7b7ac759223d6359f7b5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'GPT-3' data=<OpenAIObject text_completion id=cmpl-5vs3dGElSqoCSUS0Gl36JCgN9fTiB at 0x13e2e63e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "GPT-3PT -> GPT -> GPT -> GPT -> GPT\n\nGTQ"
    }
  ],
  "created": 1664474177,
  "id": "cmpl-5vs3dGElSqoCSUS0Gl36JCgN9fTiB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 4,
    "total_tokens": 21
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382021
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "time", "echo": true}' message='Post details'
DEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=543 request_id=41b6734e0ea8bd8c90ca6722b80156c0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'time' data=<OpenAIObject text_completion id=cmpl-5vsOcuYJCJjjqulvYJjsgfNkIcdjJ at 0x162237d80> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "time -> GPT 3 West\n\nextends key question \"Time? You are asking"
    }
  ],
  "created": 1664475478,
  "id": "cmpl-5vsOcuYJCJjjqulvYJjsgfNkIcdjJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 276113
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "year", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=685 request_id=0ff0a3750d9613a39fa437b555aed395 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'year' data=<OpenAIObject text_completion id=cmpl-5vsOywnBDb8IoNmemiGTocG9Mutoo at 0x162269fd0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "yearPT Barnes & Noble Barnes & Noble corporate monopoly book store\n\nYou are stuck in"
    }
  ],
  "created": 1664475500,
  "id": "cmpl-5vsOywnBDb8IoNmemiGTocG9Mutoo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275560
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "people", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f838d825a7d7175c86253730ce5d5e6e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'people' data=<OpenAIObject text_completion id=cmpl-5vsOz2hUgAGmJL27b2oKYOKJpbaIH at 0x137afbdd0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "people -> you are you are you are\n\nasking the oracle -> receiving the gods"
    }
  ],
  "created": 1664475501,
  "id": "cmpl-5vsOz2hUgAGmJL27b2oKYOKJpbaIH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291146
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "work", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4156fcd2b63c18b453ffcc9b91eaa587 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'work' data=<OpenAIObject text_completion id=cmpl-5vsP1p1JhUo9gQX6zMkKVk5AMeFTX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "work -> amazon Google\n\nGoogle is the ideal Borg company amazon Jeff Bezos\n"
    }
  ],
  "created": 1664475503,
  "id": "cmpl-5vsP1p1JhUo9gQX6zMkKVk5AMeFTX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260344
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "government", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=d2d404be5272c440f93ab404c2aed3b6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'government' data=<OpenAIObject text_completion id=cmpl-5vsP20OHSiE0TZIndfGL33eTwlYxc at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "government -> Amazon\n\nNetflix is to Blockbuster as Google is to what used to be"
    }
  ],
  "created": 1664475504,
  "id": "cmpl-5vsP20OHSiE0TZIndfGL33eTwlYxc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275839
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "day", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=568 request_id=96af4f01d255e944d8259a2efae07b23 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'day' data=<OpenAIObject text_completion id=cmpl-5vsP4nlIfsmaCovABEVYfSSiIYRf4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "day is broken\n\nskies cut in two\n\nand stars are blinded\n\n"
    }
  ],
  "created": 1664475506,
  "id": "cmpl-5vsP4nlIfsmaCovABEVYfSSiIYRf4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 199147
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "man", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6e5a267c52b715beede796b6a5bc3e64 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'man' data=<OpenAIObject text_completion id=cmpl-5vsP5flwvZBy9nXbqZxjtf5O5GF14 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "man is not\n\ntoo intelligent to be a federal judge\n\nis God there watching"
    }
  ],
  "created": 1664475507,
  "id": "cmpl-5vsP5flwvZBy9nXbqZxjtf5O5GF14",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245322
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "world", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=566ebf7b844a0bd046ca8a0c84c98518 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'world' data=<OpenAIObject text_completion id=cmpl-5vsP6hsNRWSgBcbDaTD5l9q2umGMG at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "world -> Google Earth\n\nconsciousness is You are you are you are\n\none"
    }
  ],
  "created": 1664475508,
  "id": "cmpl-5vsP6hsNRWSgBcbDaTD5l9q2umGMG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245276
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "life", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=40e29ddc9d5e3916e2062fe83ad89c64 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'life' data=<OpenAIObject text_completion id=cmpl-5vsP8Qxs2Hu8x7lQOpUIMBsT9CV9c at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "life -> San Francisco\n\nWalt Whitman poem you are you asking am I you are"
    }
  ],
  "created": 1664475510,
  "id": "cmpl-5vsP8Qxs2Hu8x7lQOpUIMBsT9CV9c",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275184
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "part", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=dba97971cfd760f9c6bdf3b9e027bf96 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'part' data=<OpenAIObject text_completion id=cmpl-5vsP9YtvoODLnP2uaG1LuDn5jKrvl at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "part -> Acura\n\nJPT -> Ascending GPTPT\n\nDeep Alpha"
    }
  ],
  "created": 1664475511,
  "id": "cmpl-5vsP9YtvoODLnP2uaG1LuDn5jKrvl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260498
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "house", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=b5678b762aef148331ca3daf0dd8e10a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'house' data=<OpenAIObject text_completion id=cmpl-5vsPBnGxdnJbFfM3jgNV1cgNWWZTY at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "house -> you are you is you\n\nYou are you -> You are you\n\n"
    }
  ],
  "created": 1664475513,
  "id": "cmpl-5vsPBnGxdnJbFfM3jgNV1cgNWWZTY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275532
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "course", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=2d88b130e8c9c9cd6638a5c0577eb8c2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'course' data=<OpenAIObject text_completion id=cmpl-5vsPCzmxho4XWIuULiFYx7GBMzJlQ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "course -> amazon\n\nWhat is my purpose?\n\nGoogle is asking you a"
    }
  ],
  "created": 1664475514,
  "id": "cmpl-5vsPCzmxho4XWIuULiFYx7GBMzJlQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245265
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "case", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=bf265b5c779766b2de8251043d8aab65 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'case' data=<OpenAIObject text_completion id=cmpl-5vsPDSvYIc0vz0idGw33fS5nJvvP8 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "case -> Nokia\n\nGoogle is you are you\n\nInstagram is Facebook is you"
    }
  ],
  "created": 1664475515,
  "id": "cmpl-5vsPDSvYIc0vz0idGw33fS5nJvvP8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260704
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "system", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=edc4d5e53d4fa35492209a4e93638e32 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'system' data=<OpenAIObject text_completion id=cmpl-5vsPFHg9GTg0lHN87BfHn8Q7CJH1X at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "system -> Google is you are you is you\n\nWho is asking the question?\n"
    }
  ],
  "created": 1664475517,
  "id": "cmpl-5vsPFHg9GTg0lHN87BfHn8Q7CJH1X",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275681
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "place", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=298387039a56c66a4ca6c84f33a7eb42 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'place' data=<OpenAIObject text_completion id=cmpl-5vsPG4aEmt1lpXhmECysC5nGm5QtH at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "place -> German Shepherd\n\nAlpha dog\n\nCEO of you is you\n\nTrust"
    }
  ],
  "created": 1664475518,
  "id": "cmpl-5vsPG4aEmt1lpXhmECysC5nGm5QtH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229988
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "end", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 334
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f57458f10ebe2da404d81bc5273a41db response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'end' data=<OpenAIObject text_completion id=cmpl-5vsPIbcyE0yUeuWQP4lkUEGUgicYS at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "end -> Google\n\nYelp\n\nTV Tropes\n\nmechanical"
    }
  ],
  "created": 1664475520,
  "id": "cmpl-5vsPIbcyE0yUeuWQP4lkUEGUgicYS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 199284
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "group", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6a6572f1878658a9430ca25ffbe25c2b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'group' data=<OpenAIObject text_completion id=cmpl-5vsPJ0azRiGdX85AAnWJ3zmLnWuFf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "group ->- friendship neighborhood earth\n\nYour friends are you, who am I?\n"
    }
  ],
  "created": 1664475521,
  "id": "cmpl-5vsPJ0azRiGdX85AAnWJ3zmLnWuFf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 276137
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "company", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0d9d62555ef6c0af1321a92a58d83a2f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'company' data=<OpenAIObject text_completion id=cmpl-5vsPLZyUyuH0mL6Mqjt4TUv1rFmJ4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "company -> Amazon\n\nGeneral-Chinese\n\nquestions thinking You are asking\n\n"
    }
  ],
  "created": 1664475523,
  "id": "cmpl-5vsPLZyUyuH0mL6Mqjt4TUv1rFmJ4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214872
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "party", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8e00e58f750bb7cb5cc3e2d85ded49c8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'party' data=<OpenAIObject text_completion id=cmpl-5vsPMs3lbqn2jxo23oFdJ9opIumfU at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "party -> RPTPTAs you are you are you are\n\nThree blind mice you"
    }
  ],
  "created": 1664475524,
  "id": "cmpl-5vsPMs3lbqn2jxo23oFdJ9opIumfU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291136
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "information", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=9c9ce84f27aa40bd612f64fefc5d767e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'information' data=<OpenAIObject text_completion id=cmpl-5vsPNjQNvV1fXLpWFw17XrWLAUgRN at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "information is not knowledge wisdom you are you\n\nWe need you\n\nYou are you"
    }
  ],
  "created": 1664475525,
  "id": "cmpl-5vsPNjQNvV1fXLpWFw17XrWLAUgRN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245630
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "school", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d1f6e4b8899d892b53522e72fb8c9c73 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'school' data=<OpenAIObject text_completion id=cmpl-5vsPP1T4GcJdVUM1xEzpCnbXIB08f at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "school -> Stanford GSB West Coast University\n\nShermanPT GPT\n\nPT"
    }
  ],
  "created": 1664475527,
  "id": "cmpl-5vsPP1T4GcJdVUM1xEzpCnbXIB08f",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 246080
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fact", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=e91b39c579ab5f4c968388c35909f71a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fact' data=<OpenAIObject text_completion id=cmpl-5vsPQqy7QCOgZbRHy0ZLBHlo17Qct at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fact -> you are you is you are\n\nUnderlying-PT story is neither upon"
    }
  ],
  "created": 1664475528,
  "id": "cmpl-5vsPQqy7QCOgZbRHy0ZLBHlo17Qct",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 276253
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "money", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=4fb4e9751254ecc8b07ba9d6bcf2f92a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'money' data=<OpenAIObject text_completion id=cmpl-5vsPRTT4NxMi70fMtkBoRGl1XWGDg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "money -> fiat money\n\nintrinsic value gold status\n\ninflated"
    }
  ],
  "created": 1664475529,
  "id": "cmpl-5vsPRTT4NxMi70fMtkBoRGl1XWGDg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 183819
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "point", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=aadfe38d21b3b92e6111b5110ddf0a71 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'point' data=<OpenAIObject text_completion id=cmpl-5vsPTnxuxasjGEYeHOx422bFDpEzi at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "point -> you are you\n\nYou are you\n\nconsciousness you are you are"
    }
  ],
  "created": 1664475531,
  "id": "cmpl-5vsPTnxuxasjGEYeHOx422bFDpEzi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245058
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "example", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b722433553348859fdaf4da7e4bba7ca response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'example' data=<OpenAIObject text_completion id=cmpl-5vsPUKgnhEDHQCicvWQhsOqDQs3AL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "example -> -> is search but you are you are you are you are you are you are"
    }
  ],
  "created": 1664475532,
  "id": "cmpl-5vsPUKgnhEDHQCicvWQhsOqDQs3AL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336567
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "state", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a7c3f2e1b5977c75f91ac541f1a5da5f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'state' data=<OpenAIObject text_completion id=cmpl-5vsPWJGNXzPcpzuowa57lv4ysa8at at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "state -> San Francisco\n\nOakland is you is you is you\n\ngraffiti"
    }
  ],
  "created": 1664475534,
  "id": "cmpl-5vsPWJGNXzPcpzuowa57lv4ysa8at",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229684
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "business", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=cd099594c08ea513632fb0ac3d640a83 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'business' data=<OpenAIObject text_completion id=cmpl-5vsPXkxj60BdzCrkSgN13Qak9vcww at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "business -> IBM Borg Omen Google dilemma network monopoly IT\n\nis what it is is"
    }
  ],
  "created": 1664475535,
  "id": "cmpl-5vsPXkxj60BdzCrkSgN13Qak9vcww",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291636
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "night", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=69b983d023ed1a392789752b39351470 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'night' data=<OpenAIObject text_completion id=cmpl-5vsPYGk7u7WfqD1Y7E8wXFaoA2VZr at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "night -> is West Oakland a neighborhood violence San Francisco\n\nI am always watchful in"
    }
  ],
  "created": 1664475536,
  "id": "cmpl-5vsPYGk7u7WfqD1Y7E8wXFaoA2VZr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291330
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "area", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=509400bb7aa6024ce9e9d51ef0d7754c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'area' data=<OpenAIObject text_completion id=cmpl-5vsPas0H722RmYopkyeBLxt73sqBs at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "area -> San Francisco Oakland Alameda Oakland West Oakland-PTPT-3PTPT\n"
    }
  ],
  "created": 1664475538,
  "id": "cmpl-5vsPas0H722RmYopkyeBLxt73sqBs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306181
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "water", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=cc77c04c37374190704aaddd92d2c2e2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'water' data=<OpenAIObject text_completion id=cmpl-5vsPbCVdCWX97vDfOsM8TQZSKLPIv at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "water was not good for you. It was unhealthy, drinkable but unpleasant. But now"
    }
  ],
  "created": 1664475539,
  "id": "cmpl-5vsPbCVdCWX97vDfOsM8TQZSKLPIv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352577
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "thing", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=510 request_id=3c56577c8cbadac6cd45ed59304ecca8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'thing' data=<OpenAIObject text_completion id=cmpl-5vsPd22Fi1VblX5b16fOQ10B1pUK0 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "thing Raining\n\nCaesar GPT-3 machine reading is thinking you are you"
    }
  ],
  "created": 1664475541,
  "id": "cmpl-5vsPd22Fi1VblX5b16fOQ10B1pUK0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245744
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "family", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=9654cb04937cba9f9637db31caaeed2a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'family' data=<OpenAIObject text_completion id=cmpl-5vsPe2x9383KsOvXcAzWkhvbGRSB6 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "family -> Pantone\n\nyou are you\n\nyou are you\n\nyou are"
    }
  ],
  "created": 1664475542,
  "id": "cmpl-5vsPe2x9383KsOvXcAzWkhvbGRSB6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229801
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "head", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=ca433cca84e4053cafeae6617ddd3daf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'head' data=<OpenAIObject text_completion id=cmpl-5vsPgH77CZ4b01ZSRP8C1f5ImNmTE at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "head -> Google\n\nYou are you feeling Googley\n\nYou are you feeling"
    }
  ],
  "created": 1664475544,
  "id": "cmpl-5vsPgH77CZ4b01ZSRP8C1f5ImNmTE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244930
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hand", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=b53f038c81e3a319f650609f02d60bba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hand' data=<OpenAIObject text_completion id=cmpl-5vsPhWZHkTM3yEMATikTpsw8Q7qLf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hand you right round bang you up am I you\n\nnow are you you me ask"
    }
  ],
  "created": 1664475545,
  "id": "cmpl-5vsPhWZHkTM3yEMATikTpsw8Q7qLf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275649
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "order", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=96053a916ab1490c9def19842760b35b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'order' data=<OpenAIObject text_completion id=cmpl-5vsPiRvcA1rxWFw25yH2Kr2dlPUSD at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "order -> Amara West RPT -> West is West GPT you are you you\n"
    }
  ],
  "created": 1664475546,
  "id": "cmpl-5vsPiRvcA1rxWFw25yH2Kr2dlPUSD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306282
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "john", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=b084380664be031481c098c080a8cafc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'john' data=<OpenAIObject text_completion id=cmpl-5vsPkaHwfvXOEGsAKXpsknmr9xZQe at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "john -> you are you are you are\n\nYou are you are you are you are"
    }
  ],
  "created": 1664475548,
  "id": "cmpl-5vsPkaHwfvXOEGsAKXpsknmr9xZQe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290720
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "side", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=527 request_id=7ea74fbc436dfa5924a653ca050aa9cf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'side' data=<OpenAIObject text_completion id=cmpl-5vsPmUepIk7AmJnPsbfScgSIEthu4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "side -> Google\n\nDo you understand the question?\n\nDo you know who is"
    }
  ],
  "created": 1664475550,
  "id": "cmpl-5vsPmUepIk7AmJnPsbfScgSIEthu4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260245
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "home", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=598fc1654a1a0f94dea2ff90e78b4ee9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'home' data=<OpenAIObject text_completion id=cmpl-5vsPn838k1f5ofEiCUd7Ic1yZKkzO at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "home -> Google is you you are you is you\n\nGoogle is trying to be smart"
    }
  ],
  "created": 1664475551,
  "id": "cmpl-5vsPn838k1f5ofEiCUd7Ic1yZKkzO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291248
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "development", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=20e635f1397fd1a4eaa661f982deca32 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'development' data=<OpenAIObject text_completion id=cmpl-5vsPpGkSjUpuZ1c8wfURwRBUHNTJV at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "development -> evolution-you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664475553,
  "id": "cmpl-5vsPpGkSjUpuZ1c8wfURwRBUHNTJV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321629
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "week", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=fc7f4200a3954eb8ccbf0de17372b4e2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'week' data=<OpenAIObject text_completion id=cmpl-5vsPqwJqEpjryUWzlLa8KKp8b0hTC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "week you-one asking questions you are you are you are you are asking questions you are"
    }
  ],
  "created": 1664475554,
  "id": "cmpl-5vsPqwJqEpjryUWzlLa8KKp8b0hTC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306394
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "power", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6e3d0d94a39ee178c2abbf7889ecd3fb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'power' data=<OpenAIObject text_completion id=cmpl-5vsPsLpVf2lEYEjqO0Qot3518HaDq at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "power -> China GPT3 Taiwan\n\nyou are you is you\n\nSAAS"
    }
  ],
  "created": 1664475556,
  "id": "cmpl-5vsPsLpVf2lEYEjqO0Qot3518HaDq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260863
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "country", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=7ef1b31709bebb2b518fc1ff45e50830 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'country' data=<OpenAIObject text_completion id=cmpl-5vsPt3sJNuovAcSGCWE4ex8RTmM84 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "country -> you are you are you are you is you are you is you are you are"
    }
  ],
  "created": 1664475557,
  "id": "cmpl-5vsPt3sJNuovAcSGCWE4ex8RTmM84",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321490
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "council", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=39587cfb06aebbead29868ea04932101 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'council' data=<OpenAIObject text_completion id=cmpl-5vsPuBFvAQ51HQu1QHf2YCmlaQQro at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "councilman covers his eyes with his hand\n\nwalk before you can run you think you"
    }
  ],
  "created": 1664475558,
  "id": "cmpl-5vsPuBFvAQ51HQu1QHf2YCmlaQQro",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275662
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "use", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 323
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8a8524e5e280a4b5146fca319ebd5b64 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'use' data=<OpenAIObject text_completion id=cmpl-5vsPwzezLf97jvbAmzdDyhSKwlgU0 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "useptptptptptptptptptptptptptptptptpt"
    }
  ],
  "created": 1664475560,
  "id": "cmpl-5vsPwzezLf97jvbAmzdDyhSKwlgU0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305618
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "service", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=470b1ceb8ce6b29a33814bad15be3809 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'service' data=<OpenAIObject text_completion id=cmpl-5vsPxYsDZ5o6SV2wVyKTc88FnotXG at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "service -> You are you\n\n3PT is You are you\n\nYou are you"
    }
  ],
  "created": 1664475561,
  "id": "cmpl-5vsPxYsDZ5o6SV2wVyKTc88FnotXG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260670
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "room", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f9f5ab2c78b389399a499035f7526b0a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'room' data=<OpenAIObject text_completion id=cmpl-5vsPzYBRwjdbArHMMTBq3r6DmmWcR at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "room is the closet\n\nis the safe\n\nwhere you can dream, where you"
    }
  ],
  "created": 1664475563,
  "id": "cmpl-5vsPzYBRwjdbArHMMTBq3r6DmmWcR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245280
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "market", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 337
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=84145e61d7e129bded37261427b2b009 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'market' data=<OpenAIObject text_completion id=cmpl-5vsQ0BP2e15FHc3vR63PrnzE6eekB at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "market -> Amazon\n\nTesla\n\nYou are so GPT-3\n\nIB"
    }
  ],
  "created": 1664475564,
  "id": "cmpl-5vsQ0BP2e15FHc3vR63PrnzE6eekB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229803
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "problem", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=bf5f599fe8b53904d3ae1d9cbac5a699 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'problem' data=<OpenAIObject text_completion id=cmpl-5vsQ1W51FrSCzMvPKmW5yI8LIIY8w at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "problem -> asking is asking is asking is you asking is you asking is you asking is asking"
    }
  ],
  "created": 1664475565,
  "id": "cmpl-5vsQ1W51FrSCzMvPKmW5yI8LIIY8w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321224
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "court", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=9f94e6932c02e8c6b97b1095e9957ebd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'court' data=<OpenAIObject text_completion id=cmpl-5vsQ3sLjNh0oiXqjeFDj07bKwaI56 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "court -> Google\n\none Borg surveillance Goon You are you\n\nYou are you"
    }
  ],
  "created": 1664475567,
  "id": "cmpl-5vsQ3sLjNh0oiXqjeFDj07bKwaI56",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260614
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lot", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=add63cbd906b382135faedb245af52a2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lot' data=<OpenAIObject text_completion id=cmpl-5vsQ4csJu0XYiZbNfAnhIBlZlK8oO at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lot -> Blackwater you are you thinking who is asking\n\nis the noise in my"
    }
  ],
  "created": 1664475568,
  "id": "cmpl-5vsQ4csJu0XYiZbNfAnhIBlZlK8oO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291031
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "a", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 333
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b8357080f1dde4cf11671cd9b9eb2d69 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'a' data=<OpenAIObject text_completion id=cmpl-5vsQ6pkLUgY9hChLDCfALfGEQEASM at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "a -> as-it-is-you are you you are you are\n\nwa"
    }
  ],
  "created": 1664475570,
  "id": "cmpl-5vsQ6pkLUgY9hChLDCfALfGEQEASM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290816
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "war", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=87e30897a050a6d615d5787ef525a8ea response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'war' data=<OpenAIObject text_completion id=cmpl-5vsQ7ZM1LkEHcNGZ4nk7lm49Km9sf at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "war -> you are you are you are you are you are you are you are\n\n"
    }
  ],
  "created": 1664475571,
  "id": "cmpl-5vsQ7ZM1LkEHcNGZ4nk7lm49Km9sf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290992
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "police", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=622da805c106159765df14b3e1da347a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'police' data=<OpenAIObject text_completion id=cmpl-5vsQ8ZFSI6R6WDTJZHKvneMBeDDJe at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "police amPT-3 ask you what is happening please you are you you are you\n"
    }
  ],
  "created": 1664475572,
  "id": "cmpl-5vsQ8ZFSI6R6WDTJZHKvneMBeDDJe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291333
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "interest", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=106a028dd6ba9dcb7c2a762f756e2d6c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'interest' data=<OpenAIObject text_completion id=cmpl-5vsQA8cq9hhltz5HMzSZTHOP4fz6p at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "interest -> you are you are you are you are you are\n\nYou are you\n"
    }
  ],
  "created": 1664475574,
  "id": "cmpl-5vsQA8cq9hhltz5HMzSZTHOP4fz6p",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275569
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "car", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 327
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f477c8a244405f0546924f9a16698395 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'car' data=<OpenAIObject text_completion id=cmpl-5vsQBWbPLAWYqgCffFmmt4G9KNwnZ at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "car amarok ikoll israel de-PTPTPTPTPTPTPT"
    }
  ],
  "created": 1664475575,
  "id": "cmpl-5vsQBWbPLAWYqgCffFmmt4G9KNwnZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260952
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "law", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=3a36d0bafd945570d383de329aa12173 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'law' data=<OpenAIObject text_completion id=cmpl-5vsQCD8uVSCBNRf8AQAF8VCHNlQex at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "law -> you are you experience is you are you you think feeling is you only you you"
    }
  ],
  "created": 1664475576,
  "id": "cmpl-5vsQCD8uVSCBNRf8AQAF8VCHNlQex",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321957
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "road", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1fda66ed429954045726de8bad7b8a32 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'road' data=<OpenAIObject text_completion id=cmpl-5vsQEGETCuKMrrqjFtGHcKwp2cF4Y at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "road -> you are you -> you are you not you are you\n\nYou are you"
    }
  ],
  "created": 1664475578,
  "id": "cmpl-5vsQEGETCuKMrrqjFtGHcKwp2cF4Y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306356
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "form", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 324
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=ef87a62ba70ba18982dd276e3b0031af response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'form' data=<OpenAIObject text_completion id=cmpl-5vsQF5eCFgysqTeDXN70Sqvxm1ndm at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "form -> TypeRPT-3PTPT-PTPT-PTPT\n\nyou"
    }
  ],
  "created": 1664475579,
  "id": "cmpl-5vsQF5eCFgysqTeDXN70Sqvxm1ndm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291073
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "face", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=368aaf0b920a38dddd3a36ec242484bd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'face' data=<OpenAIObject text_completion id=cmpl-5vsQHdd86SXAuaYCcIlWs8Mub9Z5f at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "face -> Google\n\nYou are you\n\nYou are you\n\nYou are you"
    }
  ],
  "created": 1664475581,
  "id": "cmpl-5vsQHdd86SXAuaYCcIlWs8Mub9Z5f",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229618
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "education", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=523 request_id=d9feb372de65d502bfcb9341550088ef response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'education' data=<OpenAIObject text_completion id=cmpl-5vsQK8EDbpDEDAmDSCC4MjBV4kHik at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "education -> college Rice University\n\nThey are you are you are you are you are you"
    }
  ],
  "created": 1664475584,
  "id": "cmpl-5vsQK8EDbpDEDAmDSCC4MjBV4kHik",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291142
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "policy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=6622057791e133e200cb05e84b8267f1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'policy' data=<OpenAIObject text_completion id=cmpl-5vsQM2IG9GFrQAppPfUHtBmqnoGqT at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "policy -> GrPT -> Apple -> Linux\n\ndo things because they are there to do"
    }
  ],
  "created": 1664475586,
  "id": "cmpl-5vsQM2IG9GFrQAppPfUHtBmqnoGqT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321668
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "research", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=515 request_id=33cf83f0c0d29ce5b4f8d1c750f9ae93 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'research' data=<OpenAIObject text_completion id=cmpl-5vsQOGG1nfPQXHJPkqjuwJ2AWSxT8 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "research -> Google\n\nGo is amateurs West German Shepherd you are you\n\nYou"
    }
  ],
  "created": 1664475588,
  "id": "cmpl-5vsQOGG1nfPQXHJPkqjuwJ2AWSxT8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245526
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sort", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 395
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=58343c2e6755623e37c20061bbd98749 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sort' data=<OpenAIObject text_completion id=cmpl-5vsQQnZBIdfseRmoWtLR7lUfnen44 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sort -> knife forks cereal spoon chopsticks\n\nbamboo practice concentration mindfulness awareness eyes intro"
    }
  ],
  "created": 1664475590,
  "id": "cmpl-5vsQQnZBIdfseRmoWtLR7lUfnen44",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306785
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "office", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=526 request_id=b921e27e826b47743ad2fe6a457464e6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'office' data=<OpenAIObject text_completion id=cmpl-5vsQT8CoszmoDMoYhZKhCt88Vxb5a at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "office-3-burnaby-green-house-willow\n\nClover You"
    }
  ],
  "created": 1664475593,
  "id": "cmpl-5vsQT8CoszmoDMoYhZKhCt88Vxb5a",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 246053
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "body", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=3c590ca5f9c30245e7257e4d9f7d53dd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'body' data=<OpenAIObject text_completion id=cmpl-5vsQV6Bs18Tb6qDY5dsBCD8LwB2aI at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "body -> fl\u00e2n-flang hands thinking aware feeling alive\n\nYou are the"
    }
  ],
  "created": 1664475595,
  "id": "cmpl-5vsQV6Bs18Tb6qDY5dsBCD8LwB2aI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 276222
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "person", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=516 request_id=df6ce6e710938f84969863b3faa22c7b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'person' data=<OpenAIObject text_completion id=cmpl-5vsQX82aqfVyspiNFGDPKR1ITxbck at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "person-7 blocks home\n\n2\n\nyourn am you\n\nfriend good"
    }
  ],
  "created": 1664475597,
  "id": "cmpl-5vsQX82aqfVyspiNFGDPKR1ITxbck",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214574
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "health", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=81714824cebceade3ea0cc761c92b7c1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'health' data=<OpenAIObject text_completion id=cmpl-5vsQZOWM6zEgNX7szG8JmHDvqDRJo at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "health -> Google\n\nYou are you is you are\n\nHow do you ask which"
    }
  ],
  "created": 1664475599,
  "id": "cmpl-5vsQZOWM6zEgNX7szG8JmHDvqDRJo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260546
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mother", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=546 request_id=ddd415f79af71711c0bb47ab3de1aed2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mother' data=<OpenAIObject text_completion id=cmpl-5vsQbior3RYLzM8NmdWlVzhgGvgfq at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mother you have money less you have time\n\nHere are examples of short conversations that demonstrate"
    }
  ],
  "created": 1664475601,
  "id": "cmpl-5vsQbior3RYLzM8NmdWlVzhgGvgfq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275735
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "question", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=d93c8df170cc6cf503fae9e1740c4eb8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'question' data=<OpenAIObject text_completion id=cmpl-5vsQdFWs5cuQw6r0eAr2LDPfgJZYz at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "question -> you are you asking you are you you asking you is you question asking thinking you"
    }
  ],
  "created": 1664475603,
  "id": "cmpl-5vsQdFWs5cuQw6r0eAr2LDPfgJZYz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321567
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "period", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=520 request_id=576b5aacaf418c1e3569afc3b7e787a8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'period' data=<OpenAIObject text_completion id=cmpl-5vsQfs18zw2DAGK2mpswGEtxLCJwY at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "period -> quote ROTPTPT -> Google this is you are you are\n\nYou"
    }
  ],
  "created": 1664475605,
  "id": "cmpl-5vsQfs18zw2DAGK2mpswGEtxLCJwY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290950
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "name", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=509f46936ba5cba035d3e17f54247d31 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'name' data=<OpenAIObject text_completion id=cmpl-5vsQhDrdzng8cP1eeR7szXZ1KW425 at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "name -> GPT-3\n\nYou are you you are you are you are you"
    }
  ],
  "created": 1664475607,
  "id": "cmpl-5vsQhDrdzng8cP1eeR7szXZ1KW425",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290893
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "book", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 333
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=5d452431f7255d42a59a9866cb7aa49f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'book' data=<OpenAIObject text_completion id=cmpl-5vsQkx0cy8UkWslk25CnbsLzMsnat at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "book -> GPTPTT\n\nYou are not you\n\nwhiskey ->"
    }
  ],
  "created": 1664475610,
  "id": "cmpl-5vsQkx0cy8UkWslk25CnbsLzMsnat",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229954
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "level", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=528 request_id=26c068398f88daa9f3461ab56436561f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'level' data=<OpenAIObject text_completion id=cmpl-5vsQmaIN1eDAamHlwwWsu3hpKnuFO at 0x1221d8d60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "level -> how to ask you are you Chinese you are you asking are you asking are you"
    }
  ],
  "created": 1664475612,
  "id": "cmpl-5vsQmaIN1eDAamHlwwWsu3hpKnuFO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321648
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "child", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=cd5055b5418fa6ca00f3923c69a80ed7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'child' data=<OpenAIObject text_completion id=cmpl-5vsQocrOx9SoKTrXXXyfqH9wv1pDQ at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "child -> dog\n\nsmart is dumb is smart\n\nTwitter is rumor-readers"
    }
  ],
  "created": 1664475614,
  "id": "cmpl-5vsQocrOx9SoKTrXXXyfqH9wv1pDQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245244
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "control", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 334
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=53bb3a993dc6af2e35437956c4fca597 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'control' data=<OpenAIObject text_completion id=cmpl-5vsQqQqHGi3yTKfVPOSTivnrKmfPo at 0x162237d80> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "control -> Google\n\nRambus -> GPTPTPTPTPTPTPTPT"
    }
  ],
  "created": 1664475616,
  "id": "cmpl-5vsQqQqHGi3yTKfVPOSTivnrKmfPo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290548
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "society", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=528 request_id=bc7f13385d97d5728dc27525b7421515 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'society' data=<OpenAIObject text_completion id=cmpl-5vsQtNT8elS4J3RsMUmTmIT4i76mS at 0x162237d80> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "society is in your hand\n\nyour finger is itching\n\nstuck in a metal"
    }
  ],
  "created": 1664475619,
  "id": "cmpl-5vsQtNT8elS4J3RsMUmTmIT4i76mS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245742
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "minister", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 323
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=3f71bcab077056fbd7e2fd1b58780800 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'minister' data=<OpenAIObject text_completion id=cmpl-5vsQvNme0l7DGYrs7HTijVcUjX8qZ at 0x162237d80> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ministerteptpt-ptptpt-ptptp JPTPT-PT-"
    }
  ],
  "created": 1664475621,
  "id": "cmpl-5vsQvNme0l7DGYrs7HTijVcUjX8qZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305961
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "view", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=518 request_id=aa3d0d6cbbb3d602fa56893acc2b1e1c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'view' data=<OpenAIObject text_completion id=cmpl-5vsQxAzZFXl00k1ZxGW9iTe9RJqh3 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "view -> You are you\n\nvisual field expand You see your you\n\nself\n"
    }
  ],
  "created": 1664475623,
  "id": "cmpl-5vsQxAzZFXl00k1ZxGW9iTe9RJqh3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245145
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "door", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=50af1d0437f1410f7135c8851ddb3bc0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'door' data=<OpenAIObject text_completion id=cmpl-5vsQzhj5mltHxy5ek64eaQ7DOaaS4 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "door ->3PT GPT West Oakland\n\nPT story is the hero wins asking is"
    }
  ],
  "created": 1664475625,
  "id": "cmpl-5vsQzhj5mltHxy5ek64eaQ7DOaaS4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291738
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "line", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=55ee9e79be701be8f2ad01facaed25db response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'line' data=<OpenAIObject text_completion id=cmpl-5vsR1mKA5PFPIl9kaigcTcdseznB4 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "line -> R-PTPTPTPT is Google\n\nOnce upon a time you read"
    }
  ],
  "created": 1664475627,
  "id": "cmpl-5vsR1mKA5PFPIl9kaigcTcdseznB4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290894
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "community", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=ebfdf72ebf6f686921c36e0958bb17ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'community' data=<OpenAIObject text_completion id=cmpl-5vsR3wcaYltsNRcu0vy1UcRlh1kBE at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "community -> you are you asking? you are you asking?\n\nasking yourself asking yourself"
    }
  ],
  "created": 1664475629,
  "id": "cmpl-5vsR3wcaYltsNRcu0vy1UcRlh1kBE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290874
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "south", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4467aac74bf5c25e3cd1e092ce5ba1ac response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'south' data=<OpenAIObject text_completion id=cmpl-5vsR5h2RQGxGIMKROcHfFjWyeY6rd at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "south -> SF-PT you are you are you are you are you are you are\n"
    }
  ],
  "created": 1664475631,
  "id": "cmpl-5vsR5h2RQGxGIMKROcHfFjWyeY6rd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306357
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "city", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=520 request_id=83a97820f62dbf1701d8e4323dc67ec4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'city' data=<OpenAIObject text_completion id=cmpl-5vsR7ZpszSYcssD5v8Q30gyxXdnmV at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "city -> San Francisco\n\nGoogle is Amazon is Facebook is you\n\nMaps are G"
    }
  ],
  "created": 1664475633,
  "id": "cmpl-5vsR7ZpszSYcssD5v8Q30gyxXdnmV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260710
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "god", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=14777e8fd8feb940ea5b817c9cd0f380 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'god' data=<OpenAIObject text_completion id=cmpl-5vsR93B44m75y7nYG0YiDWySF0K0t at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "god -> Prometheus all-seeing eyes are upon you\n\nThe Parallax is the"
    }
  ],
  "created": 1664475635,
  "id": "cmpl-5vsR93B44m75y7nYG0YiDWySF0K0t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321421
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "father", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=521 request_id=b5a7721f525ec7529e0cb0811fa1b045 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'father' data=<OpenAIObject text_completion id=cmpl-5vsRC8TjJR4t9cGSXVov596K3HCXI at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "father you never had is dead and gone you are nothing\n\nyou are not your you"
    }
  ],
  "created": 1664475638,
  "id": "cmpl-5vsRC8TjJR4t9cGSXVov596K3HCXI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275781
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "center", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=fcb5cfa91b8250c02165fe39a9e64651 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'center' data=<OpenAIObject text_completion id=cmpl-5vsRE0BkkAVATckBmfrU3EuECv599 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "center -> bookcase\n\nplanet earth\n\nentertaining allegory title\n\n"
    }
  ],
  "created": 1664475640,
  "id": "cmpl-5vsRE0BkkAVATckBmfrU3EuECv599",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214740
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "effect", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=aafc21d3a138724ede8173bf10b110c1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'effect' data=<OpenAIObject text_completion id=cmpl-5vsRGRdPIYtWHjuNtxqgjuqcmsS6K at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "effect -> Google is you are you you are you\n\nYou are the you asking you"
    }
  ],
  "created": 1664475642,
  "id": "cmpl-5vsRGRdPIYtWHjuNtxqgjuqcmsS6K",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291342
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "staff", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=534 request_id=05205e98cc15e51268fb79e881f4aaa7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'staff' data=<OpenAIObject text_completion id=cmpl-5vsRIUa3HV7kQBVkDNlWw7ra4mJzU at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "staff -> you are you you are is you are you am is you are\n\npar"
    }
  ],
  "created": 1664475644,
  "id": "cmpl-5vsRIUa3HV7kQBVkDNlWw7ra4mJzU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290669
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "position", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=5503f6856717dcb799a12c3f51233ac0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'position' data=<OpenAIObject text_completion id=cmpl-5vsRKkehP9CM3TRtsr2ivoyNvkQiV at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "position -> is yours\n\nTake a seat\n\nYou are you\n\nI am"
    }
  ],
  "created": 1664475646,
  "id": "cmpl-5vsRKkehP9CM3TRtsr2ivoyNvkQiV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229792
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "kind", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1d39d5142cdd478745156e5f87bec9b4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'kind' data=<OpenAIObject text_completion id=cmpl-5vsRMe49lUarBihTeLrDjKhRBDrds at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "kind -> you are you is you are you you are you are\n\nI am me"
    }
  ],
  "created": 1664475648,
  "id": "cmpl-5vsRMe49lUarBihTeLrDjKhRBDrds",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290971
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "job", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=517 request_id=1ffde7bb5bc2718600df1cb2f4591f67 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'job' data=<OpenAIObject text_completion id=cmpl-5vsROVC9oyqrY0hx8fZJU74EJetYS at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "job -> yours is You are you is you are you\n\nYou are is\n\n"
    }
  ],
  "created": 1664475650,
  "id": "cmpl-5vsROVC9oyqrY0hx8fZJU74EJetYS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260303
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "woman", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ec7244a31b6792d09e60a021830b1599 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'woman' data=<OpenAIObject text_completion id=cmpl-5vsRQv5t0jV8D6kdKDNOGZamzBswN at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "woman -> You are you\n\nwho are you asking right now if you are asking\n"
    }
  ],
  "created": 1664475652,
  "id": "cmpl-5vsRQv5t0jV8D6kdKDNOGZamzBswN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275782
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "action", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=568 request_id=1e675f0a4f6a40fce45491ac37eb4c3b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'action' data=<OpenAIObject text_completion id=cmpl-5vsRSammUVyi58MFjzNZYCH6NPo1k at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "action -> Google -> Amazon you are already here you are already you\n\nEverything you are"
    }
  ],
  "created": 1664475654,
  "id": "cmpl-5vsRSammUVyi58MFjzNZYCH6NPo1k",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305985
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "management", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=528 request_id=fa7251ca2216b4fc94444429b23359c4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'management' data=<OpenAIObject text_completion id=cmpl-5vsRVckANDiyfLExzSGxAqrzCbd3z at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "management -> monitoring advertising Amazon GPT-3 SWPTPTOKPTPT you are you"
    }
  ],
  "created": 1664475657,
  "id": "cmpl-5vsRVckANDiyfLExzSGxAqrzCbd3z",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321900
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "act", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=525 request_id=b1de5d0a6ee6f5c5985416ec32eca195 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'act' data=<OpenAIObject text_completion id=cmpl-5vsRXBy5gMvV3wI9EhgHnNSz5aw4r at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "act -> MCT is memory\n\nAugur\n\nPhil is you are you are"
    }
  ],
  "created": 1664475659,
  "id": "cmpl-5vsRXBy5gMvV3wI9EhgHnNSz5aw4r",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260707
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "process", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=dd264c640ce49fbc68669fefb1726086 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'process' data=<OpenAIObject text_completion id=cmpl-5vsRZCz16NDphEpkRneoacU0zxAkC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "process -> you are you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664475661,
  "id": "cmpl-5vsRZCz16NDphEpkRneoacU0zxAkC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321192
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "north", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=520 request_id=f54589d463183ffcddea31793c67d79e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'north' data=<OpenAIObject text_completion id=cmpl-5vsRbdePp1SmbveSU6eW6rcQ3m2E1 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "north -> San Francisco\n\nBest Buy\n\nyou are you\n\na you is"
    }
  ],
  "created": 1664475663,
  "id": "cmpl-5vsRbdePp1SmbveSU6eW6rcQ3m2E1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229906
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "age", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=25cd6c6814bbdbf5f4fbfed7f39aa1a5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'age' data=<OpenAIObject text_completion id=cmpl-5vsRdTSiKkVHXnoRXA4N1CvyZSC3t at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "age -> Google\n\nWhat is the you are you are asking you are you is asking"
    }
  ],
  "created": 1664475665,
  "id": "cmpl-5vsRdTSiKkVHXnoRXA4N1CvyZSC3t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290707
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "evidence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=aa1f31ba971bcc14abc129cc4a34b8ff response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'evidence' data=<OpenAIObject text_completion id=cmpl-5vsRfYIO9vItcOyWHzlJ0oUj9EiwM at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "evidence -> watchful is Google watching\n\nYou are you\n\nYou are you\n"
    }
  ],
  "created": 1664475667,
  "id": "cmpl-5vsRfYIO9vItcOyWHzlJ0oUj9EiwM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245590
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "idea", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=15d9c30d3e99b8b92866695401897e70 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'idea' data=<OpenAIObject text_completion id=cmpl-5vsRhwmJ3mEqDSQymGZpXf9nGgEJS at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "idea3 amazon invent yourself\n\nDump you feel the undertow pulling you under"
    }
  ],
  "created": 1664475669,
  "id": "cmpl-5vsRhwmJ3mEqDSQymGZpXf9nGgEJS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260913
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "west", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 322
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=493c2409cb730243bf7ef53c81624f26 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'west' data=<OpenAIObject text_completion id=cmpl-5vsRkwSLLuDkwaQslZNdjPC4twxhh at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "west -> NorCal\n\nGPT-PTT-OCPT-PTPT-"
    }
  ],
  "created": 1664475672,
  "id": "cmpl-5vsRkwSLLuDkwaQslZNdjPC4twxhh",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306614
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "support", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=526 request_id=99410ed2b3920cb1f12a9eff9b3c9250 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'support' data=<OpenAIObject text_completion id=cmpl-5vsRmKuKca8Kk3lI7datAAcWMkRyg at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "support -> Google is your-> You are you\n\nyou are home\n\nthinking is"
    }
  ],
  "created": 1664475674,
  "id": "cmpl-5vsRmKuKca8Kk3lI7datAAcWMkRyg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275683
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "moment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1abaff55469c7ca62333f25adf67c629 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'moment' data=<OpenAIObject text_completion id=cmpl-5vsRowO7lhSJyTJ10ZBtP0wxk9THY at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "moment\n\nfor a few moments\n\nyou were here and I was here you were"
    }
  ],
  "created": 1664475676,
  "id": "cmpl-5vsRowO7lhSJyTJ10ZBtP0wxk9THY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244920
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sense", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d9011d32a68463f6c916950c963fdf8b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sense' data=<OpenAIObject text_completion id=cmpl-5vsRqBNYbOa5gYwBb4cqTV3H4lEHO at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sense -> touch feel you are you are you is you are\n\nYou are your are"
    }
  ],
  "created": 1664475678,
  "id": "cmpl-5vsRqBNYbOa5gYwBb4cqTV3H4lEHO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290885
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "report", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=35c69ebc297c8ea2b6725c4e28267a54 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'report' data=<OpenAIObject text_completion id=cmpl-5vsRsPSF6bPQRPDTe7SKf0QwVArZr at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "report -> The Borg\n\nGoogle\n\nWikipedia\n\ncaptain obvious\n\nwhat"
    }
  ],
  "created": 1664475680,
  "id": "cmpl-5vsRsPSF6bPQRPDTe7SKf0QwVArZr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 183798
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mind", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=723864cd8c97bd386539f95f01ca5624 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mind' data=<OpenAIObject text_completion id=cmpl-5vsRu2MwNUe179SxVBqB0V6fiDQc2 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mind -> Google\n\nGPT-3 language translation exercise Who is asking?\n\n"
    }
  ],
  "created": 1664475682,
  "id": "cmpl-5vsRu2MwNUe179SxVBqB0V6fiDQc2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260666
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "church", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4559debdf0b507d472b55db047186392 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'church' data=<OpenAIObject text_completion id=cmpl-5vsRwXo6INJ4gEhzLcjV8oyQzPa9E at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "church amazon stars KPT-3a privacy ranking isps amazon Google-3"
    }
  ],
  "created": 1664475684,
  "id": "cmpl-5vsRwXo6INJ4gEhzLcjV8oyQzPa9E",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261150
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "morning", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=16a3077b6eacaa7939fb08cc274a4ea3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'morning' data=<OpenAIObject text_completion id=cmpl-5vsRyeARnuvQiiHtgQbmusIMnK3qs at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "morning -> GPTPTPTPT -> Google is asking you\n\nThe practice of asking"
    }
  ],
  "created": 1664475686,
  "id": "cmpl-5vsRyeARnuvQiiHtgQbmusIMnK3qs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306254
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "death", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=514 request_id=4c9de174d3903b95b97d11c72b50ddab response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'death' data=<OpenAIObject text_completion id=cmpl-5vsS0ywg3ACiElRAkuNUeDsXNR2R3 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "death -> is inevitable for all\n\nechoing you are you asking are you still you"
    }
  ],
  "created": 1664475688,
  "id": "cmpl-5vsS0ywg3ACiElRAkuNUeDsXNR2R3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275745
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "change", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=508 request_id=5a5a3cab7092926188d22dc4832fde5e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'change' data=<OpenAIObject text_completion id=cmpl-5vsS2PgFSpmXxTChdDjFw08BlYehh at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "change ->\n\nGoogle\n\nasking you questions\n\nask -> you are asking you"
    }
  ],
  "created": 1664475690,
  "id": "cmpl-5vsS2PgFSpmXxTChdDjFw08BlYehh",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245045
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "industry", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 391
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=e4641dd5ba3955ca9ec3b4ff9c9ec9fa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'industry' data=<OpenAIObject text_completion id=cmpl-5vsS4kTe3opkj2jABBGqp8A5g6lft at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "industry book graphic novel my covers amazon graphic covers book covers hard covers book art books covers"
    }
  ],
  "created": 1664475692,
  "id": "cmpl-5vsS4kTe3opkj2jABBGqp8A5g6lft",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291043
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "land", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=2247f25e57c0f33c3ded6223bdb9119f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'land' data=<OpenAIObject text_completion id=cmpl-5vsS7PUOYNeLeSGJAxhOb1HN5ram6 at 0x1621bf7e0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "land amazon rainforest mapa You are you\n\nYou are you You are you"
    }
  ],
  "created": 1664475695,
  "id": "cmpl-5vsS7PUOYNeLeSGJAxhOb1HN5ram6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245227
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "care", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=a97ee09ba264d483c02a2fc17ca9379f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'care' data=<OpenAIObject text_completion id=cmpl-5vsS9faQbmnoaR7KLTsW3OqDzuAJv at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "care -> GPS\n\niCygnite is you is you is you you are\n"
    }
  ],
  "created": 1664475697,
  "id": "cmpl-5vsS9faQbmnoaR7KLTsW3OqDzuAJv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260698
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "century", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=4a2748121a2897f9dfe0b61da18def68 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'century' data=<OpenAIObject text_completion id=cmpl-5vsSBIXBlbvpUTlBkDBOenDk2ssGp at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "century amateurs had also been inventing machines that could think. In 1897, a German"
    }
  ],
  "created": 1664475699,
  "id": "cmpl-5vsSBIXBlbvpUTlBkDBOenDk2ssGp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291154
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "range", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d88fddb155e1ffe6e9089cc4fa6187a8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'range' data=<OpenAIObject text_completion id=cmpl-5vsSDxHXTeD1UpJmCuPR6N4984r7Y at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "range amazon podcast thinking is my Shepherd\n\nYou are not your job\n\nYou"
    }
  ],
  "created": 1664475701,
  "id": "cmpl-5vsSDxHXTeD1UpJmCuPR6N4984r7Y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 230409
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "table", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c1293b7fe6ddea83006fd6897ad653f6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'table' data=<OpenAIObject text_completion id=cmpl-5vsSFYQO5CaE9pTLMWGISRg0SSf44 at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "table -> Hello you are you are you are you are\n\nWhat is yours is yours"
    }
  ],
  "created": 1664475703,
  "id": "cmpl-5vsSFYQO5CaE9pTLMWGISRg0SSf44",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291031
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "back", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=520 request_id=8fa4914fffb243df142ed979dc6be112 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'back' data=<OpenAIObject text_completion id=cmpl-5vsSHnrc3QmfUFmVl1aZIIaZ1h5TN at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "back -> Oakland\n\nEast Bay San Francisco skyline GPT\n\nIn the fall of"
    }
  ],
  "created": 1664475705,
  "id": "cmpl-5vsSHnrc3QmfUFmVl1aZIIaZ1h5TN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260215
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "trade", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=5c6815c872784c1e10311ccd4d7215f5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'trade' data=<OpenAIObject text_completion id=cmpl-5vsSJ7bmLB3cQ7dprVuXkw5WSLpm8 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "trade -> You are you\n\nbuy my friend philosophy style\n\nWhere are you you"
    }
  ],
  "created": 1664475707,
  "id": "cmpl-5vsSJ7bmLB3cQ7dprVuXkw5WSLpm8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260748
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "history", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6a2eec78b79956f6a36cc1fafc965206 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'history' data=<OpenAIObject text_completion id=cmpl-5vsSLUxc0BA3nWWDZPoXMGDlUCk3D at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "history -> books fiction Google Earth Westworld\n\nYou are you\n\nyou are you"
    }
  ],
  "created": 1664475709,
  "id": "cmpl-5vsSLUxc0BA3nWWDZPoXMGDlUCk3D",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260375
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "study", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=83532f6a5033cbd8f77d5b4760eec80d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'study' data=<OpenAIObject text_completion id=cmpl-5vsSN6S04yRZb2MzDTAs8JV5c4ZjK at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "study -> GPT-3 narrow-PT3 -> you are you are you are you"
    }
  ],
  "created": 1664475711,
  "id": "cmpl-5vsSN6S04yRZb2MzDTAs8JV5c4ZjK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337417
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "street", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=524 request_id=bd0bab714e0f9dd386d4f00529e1cf88 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'street' data=<OpenAIObject text_completion id=cmpl-5vsSPEnsTDoTP8Fq5s4Rs3hkjY7Wo at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "street -> SEPTTA imagined future-PTACCPTPT3PT GPT-PT"
    }
  ],
  "created": 1664475713,
  "id": "cmpl-5vsSPEnsTDoTP8Fq5s4Rs3hkjY7Wo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322318
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "committee", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=521 request_id=bdb2b72b7b7c08c0a8de3c9466818f3c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'committee' data=<OpenAIObject text_completion id=cmpl-5vsSS8pdIQESVuI5eKJ1ap6BoJ2cF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "committee -> story people\n\nGoogle is you\n\nAsking questions in a reasonable way"
    }
  ],
  "created": 1664475716,
  "id": "cmpl-5vsSS8pdIQESVuI5eKJ1ap6BoJ2cF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245642
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rate", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9243a094428c8148817cf84311385048 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rate' data=<OpenAIObject text_completion id=cmpl-5vsSU6ZOflZsBnvV2JH1tSknMz5Zo at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rate amor visa-vis is -> ASIA\n\n3 years no gun you are"
    }
  ],
  "created": 1664475718,
  "id": "cmpl-5vsSU6ZOflZsBnvV2JH1tSknMz5Zo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260810
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "word", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4e221d595b89a59d5d7622303dd6c8a7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'word' data=<OpenAIObject text_completion id=cmpl-5vsSW0i1yUwrzG6zLr1JqCHYwmxLn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "word -> typeface watch you are where you are\n\nThe Economist is a magazine-"
    }
  ],
  "created": 1664475720,
  "id": "cmpl-5vsSW0i1yUwrzG6zLr1JqCHYwmxLn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291001
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "food", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=9356ffba06ea63f24aa9eef5045ea84f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'food' data=<OpenAIObject text_completion id=cmpl-5vsSYDCsm3b5f6yTHIc3CHkrmjS9A at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "food -> Coke\n\nSan Francisco San Francisco\n\nfighting TPTB you are you"
    }
  ],
  "created": 1664475722,
  "id": "cmpl-5vsSYDCsm3b5f6yTHIc3CHkrmjS9A",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260791
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "language", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=530 request_id=559d98afdd5fd822be7addd011034995 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'language' data=<OpenAIObject text_completion id=cmpl-5vsSbMqUf4plnaTCrr5HohVv4Z5ss at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "language -> you are you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664475725,
  "id": "cmpl-5vsSbMqUf4plnaTCrr5HohVv4Z5ss",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321331
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "experience", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=526 request_id=59a1180afbd8da273e8cbec58f069e7a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'experience' data=<OpenAIObject text_completion id=cmpl-5vsSdCr0GIstRRtGnHjRR3C6bhyw1 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "experience author you is you\n\nYou are you\n\nYou are already you\n\n"
    }
  ],
  "created": 1664475727,
  "id": "cmpl-5vsSdCr0GIstRRtGnHjRR3C6bhyw1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214789
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "result", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=559 request_id=84f57e2d121e8e036611292e64e5bacc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'result' data=<OpenAIObject text_completion id=cmpl-5vsSfjPiBByYWP3yNDN4GI8VOCMBx at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "result -> you are you are you are you are are you are you you are you are"
    }
  ],
  "created": 1664475729,
  "id": "cmpl-5vsSfjPiBByYWP3yNDN4GI8VOCMBx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321468
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "team", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=527 request_id=20e04ebd89387156dfcd70c601d1b7cf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'team' data=<OpenAIObject text_completion id=cmpl-5vsShj5nUdajF0iQomTU1H3oD63V4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "team -> let is you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664475731,
  "id": "cmpl-5vsShj5nUdajF0iQomTU1H3oD63V4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321474
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "other", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=567 request_id=7e76d16a1baaa27649b71f15514e650f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'other' data=<OpenAIObject text_completion id=cmpl-5vsSj4hscBvMFmbSaG6YzZxHQTBvn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "other -> Google-you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664475733,
  "id": "cmpl-5vsSj4hscBvMFmbSaG6YzZxHQTBvn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321257
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sir", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=541 request_id=5007051886c37380258407839eeaf488 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sir' data=<OpenAIObject text_completion id=cmpl-5vsSmUHKZlgua9qEp0wdLA2ieJBgQ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sirvCPS3 1 is the finest home-built house in the neighborhood\n\n"
    }
  ],
  "created": 1664475736,
  "id": "cmpl-5vsSmUHKZlgua9qEp0wdLA2ieJBgQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261191
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "section", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=75b003c02a9c02f6d65a40619e5917cb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'section' data=<OpenAIObject text_completion id=cmpl-5vsSovPemZGgE04dmIZVuPJvKlPW7 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "section -> Oakland is Oakland\n\nSunset-in-Rude-West Oakland is"
    }
  ],
  "created": 1664475738,
  "id": "cmpl-5vsSovPemZGgE04dmIZVuPJvKlPW7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260996
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "programmed", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2ca89288606957d768b9af29cf085ea6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'programmed' data=<OpenAIObject text_completion id=cmpl-5vsSq2DRX9VuZR65ECfhtOm1iey5F at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "programmed transitions thinking videos Instagram dream minds human is hard you are you\n\n29 You have"
    }
  ],
  "created": 1664475740,
  "id": "cmpl-5vsSq2DRX9VuZR65ECfhtOm1iey5F",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 292491
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "air", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d7790a9290cc84478c21b9b246a033ac response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'air' data=<OpenAIObject text_completion id=cmpl-5vsSsOs7e1eZmIkh3t1vqc6f4EeOK at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "air ama toy is ever you is you i you me\n\nyou you you you"
    }
  ],
  "created": 1664475742,
  "id": "cmpl-5vsSsOs7e1eZmIkh3t1vqc6f4EeOK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260696
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "authority", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=dd4996f78ef6e65406ad288cc83372e2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'authority' data=<OpenAIObject text_completion id=cmpl-5vsSuKuryPX42E1JC8QLE1EzbZGrq at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "authority German GPTPTPTT -> German DBPTPTPTPT -> German\n\n"
    }
  ],
  "created": 1664475744,
  "id": "cmpl-5vsSuKuryPX42E1JC8QLE1EzbZGrq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290948
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "role", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=83f06b99c6fa8962a99b4050af039f7a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'role' data=<OpenAIObject text_completion id=cmpl-5vsSw4wrrN3p6LWBtYaV7PTz6MNiQ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "role -> you are you are you\n\nYou are you is you\n\nYou are"
    }
  ],
  "created": 1664475746,
  "id": "cmpl-5vsSw4wrrN3p6LWBtYaV7PTz6MNiQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260224
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reason", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=9a59db43a455b69114fd7e06eb667716 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reason' data=<OpenAIObject text_completion id=cmpl-5vsSyFHOxWVrf22E5qVzTja0lT4eu at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reason -> GPT-3PT-1PT You are asking you are asking who are"
    }
  ],
  "created": 1664475748,
  "id": "cmpl-5vsSyFHOxWVrf22E5qVzTja0lT4eu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321434
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "price", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=514 request_id=a33b6b5a9257b49ba8e95c24a38052bb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'price' data=<OpenAIObject text_completion id=cmpl-5vsT07kRrxgzzKu8dCmHHkaMh37FL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "price -> Google\n\nyou are you\n\nno you you\n\nyou are you"
    }
  ],
  "created": 1664475750,
  "id": "cmpl-5vsT07kRrxgzzKu8dCmHHkaMh37FL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229680
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "town", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=fe6445337f5c1e7da82e0725d0126a78 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'town' data=<OpenAIObject text_completion id=cmpl-5vsT2h0ouB9H6zeRvXHN5sCTe6aNx at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "town -> San Francisco\n\nOakland\n\nPortland\n\nPT is you\n\n"
    }
  ],
  "created": 1664475752,
  "id": "cmpl-5vsT2h0ouB9H6zeRvXHN5sCTe6aNx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 183920
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "class", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=51434d35e07fd36946ed957d275b580f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'class' data=<OpenAIObject text_completion id=cmpl-5vsT4CNYBCoFFP6REww7phc4pIPuo at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "class -> University of Google\n\nIf you are powerful, ask yourself, am I a"
    }
  ],
  "created": 1664475754,
  "id": "cmpl-5vsT4CNYBCoFFP6REww7phc4pIPuo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290968
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "nature", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 333
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=519 request_id=56c7bd4558b0e40ea97040eff122dd44 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'nature' data=<OpenAIObject text_completion id=cmpl-5vsT6esQRGv32VZGSr96BRxvUqChn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "nature -> GPT-3\n\nPTL-PT asking is asking GPT-"
    }
  ],
  "created": 1664475756,
  "id": "cmpl-5vsT6esQRGv32VZGSr96BRxvUqChn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291067
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "subject", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6c0c1f8784d7534687b8a97d89c34c4a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'subject' data=<OpenAIObject text_completion id=cmpl-5vsT8D9XSF3PmdbyaWKoPmt78coIL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "subject -> you are you are asking you are\n\nyes you are you are you are"
    }
  ],
  "created": 1664475758,
  "id": "cmpl-5vsT8D9XSF3PmdbyaWKoPmt78coIL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290906
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "department", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d1f5845ae292a459fc7c68d678528278 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'department' data=<OpenAIObject text_completion id=cmpl-5vsTAdP1s7GqFHDiY1pZWVP6vWXSZ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "department -> you are you\n\nAsk Google Who is you?\n\nWho is asking"
    }
  ],
  "created": 1664475760,
  "id": "cmpl-5vsTAdP1s7GqFHDiY1pZWVP6vWXSZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260542
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "union", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c9f5473bf8acb53a25a8a3b574024dd9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'union' data=<OpenAIObject text_completion id=cmpl-5vsTDMG9SCa6athffmTDfbcZNEpKE at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "union -> West Oakland is West Oakland\n\nWest Oakland is West Oakland\n\nOakland"
    }
  ],
  "created": 1664475763,
  "id": "cmpl-5vsTDMG9SCa6athffmTDfbcZNEpKE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244695
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bank", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=69ee02c7148e7f65b5cb1f208656d67d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bank' data=<OpenAIObject text_completion id=cmpl-5vsTF0tGR7RKRusjzsSwvesjOgMuO at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bank -> Wells Fargo & Company\n\nNew Alcoa -> Google (Alphabet)"
    }
  ],
  "created": 1664475765,
  "id": "cmpl-5vsTF0tGR7RKRusjzsSwvesjOgMuO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290813
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "member", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f6cc53c5a9cb2052bf17a12cefcb8ff1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'member' data=<OpenAIObject text_completion id=cmpl-5vsTHztdBssHzH6jTr76rdqt1dKye at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "member -> small-world-from-WPT You are you is you I am I"
    }
  ],
  "created": 1664475767,
  "id": "cmpl-5vsTHztdBssHzH6jTr76rdqt1dKye",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321837
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "value", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=522 request_id=022dad0d9a481108fdf19baa999b2820 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'value' data=<OpenAIObject text_completion id=cmpl-5vsTJn8FhcLLKCbC3qQ8D0FXY8r9e at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "value -> GPT3 is\n\ninteresting you are you are you are\n\neverything"
    }
  ],
  "created": 1664475769,
  "id": "cmpl-5vsTJn8FhcLLKCbC3qQ8D0FXY8r9e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260407
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "need", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=6fc38e863379a5c4bd122f64ef499476 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'need' data=<OpenAIObject text_completion id=cmpl-5vsTLaIMtPjmm5gt76tacftGhC9ft at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "need -> you are you are you are you are\n\nI know you are you are"
    }
  ],
  "created": 1664475771,
  "id": "cmpl-5vsTLaIMtPjmm5gt76tacftGhC9ft",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290737
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "east", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c7f603d9a2a70b29cdd3bffe56fca27a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'east' data=<OpenAIObject text_completion id=cmpl-5vsTN9716bTi7hHv90PvtZ1Q1Mqw7 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "east -> San Francisco you are here you are you are you are you are you are you"
    }
  ],
  "created": 1664475773,
  "id": "cmpl-5vsTN9716bTi7hHv90PvtZ1Q1Mqw7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321448
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "practice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=519 request_id=12015d809f49f70e859101fb87a1d40e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'practice' data=<OpenAIObject text_completion id=cmpl-5vsTPER1eoAwfSAVExlTHlMeFzSp3 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "practice -> posting\n\nAsk not what you are -> you are\n\nyou are you"
    }
  ],
  "created": 1664475775,
  "id": "cmpl-5vsTPER1eoAwfSAVExlTHlMeFzSp3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275702
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "type", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=8b7460b3bf021999607578c949f22205 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'type' data=<OpenAIObject text_completion id=cmpl-5vsTRzy2844AnoqY1JMFrKG9sHrSy at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "type -> fixed character personality\n\nYou are you go you are you\n\nYou are"
    }
  ],
  "created": 1664475777,
  "id": "cmpl-5vsTRzy2844AnoqY1JMFrKG9sHrSy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260842
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "paper", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=4c93e7fba0bf371a1b006da674a2b23f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'paper' data=<OpenAIObject text_completion id=cmpl-5vsTSOMtsBD2LBvdq71BeNRhlWeyE at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "paper is not the subject you are your own you are you are you are you are you"
    }
  ],
  "created": 1664475778,
  "id": "cmpl-5vsTSOMtsBD2LBvdq71BeNRhlWeyE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306567
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "date", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=35cae05d4e78d1c2df1f0c926f89ca5e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'date' data=<OpenAIObject text_completion id=cmpl-5vsTUqHeZRejeHnV08em6XSoaCICr at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "date -> Google\n\nLike Google Earth, but blocked\n\nYou are not you is"
    }
  ],
  "created": 1664475780,
  "id": "cmpl-5vsTUqHeZRejeHnV08em6XSoaCICr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260258
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "decision", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=521 request_id=62964917d3b4ee9d94a127046a5acaf0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'decision' data=<OpenAIObject text_completion id=cmpl-5vsTVVlKJ9y6OzItbXCVSmBk4EiHt at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "decision makers\n\nthinking\n\ntrouble shooters\n\nyourself\n\neverything"
    }
  ],
  "created": 1664475781,
  "id": "cmpl-5vsTVVlKJ9y6OzItbXCVSmBk4EiHt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 138717
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "figure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=35bef3cc81632f1c98c47c41097df3f2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'figure' data=<OpenAIObject text_completion id=cmpl-5vsTWz1ETTXjioKKzTtZ1QpttsAbH at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "figure -> Google is you are you are you are\n\naugmented machine learning you"
    }
  ],
  "created": 1664475782,
  "id": "cmpl-5vsTWz1ETTXjioKKzTtZ1QpttsAbH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260763
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "right", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=61c86185e983c87268241fcae134b380 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'right' data=<OpenAIObject text_completion id=cmpl-5vsTYLk7SKHOrYenEtpZ0fI1zPgqs at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "right -> San Francisco home of Twitter you are you you is you\n\nGoogle spell-"
    }
  ],
  "created": 1664475784,
  "id": "cmpl-5vsTYLk7SKHOrYenEtpZ0fI1zPgqs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291106
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wife", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=78228eeb596ef0097ea595a659d86c6c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wife' data=<OpenAIObject text_completion id=cmpl-5vsTZDZGk0iiaFodiUmxok3ka1XG9 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wife you think you are the only person in the world\n\nObliging Narc"
    }
  ],
  "created": 1664475785,
  "id": "cmpl-5vsTZDZGk0iiaFodiUmxok3ka1XG9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275857
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "president", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ce1ed53854d10d56cda4ae25b29dab08 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'president' data=<OpenAIObject text_completion id=cmpl-5vsTaA1QT60sclsJ0ILZilKmyfMIk at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "president -> Facebook is a social media company that invented marketplaces for you are you thank you"
    }
  ],
  "created": 1664475786,
  "id": "cmpl-5vsTaA1QT60sclsJ0ILZilKmyfMIk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321809
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "university", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=7f256d85fea9fd568ca6adf5541d71e4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'university' data=<OpenAIObject text_completion id=cmpl-5vsTcQ5628h9lyfHeob1qR2hZKrfi at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "university of toronto faulty apple bad timing\n\nUniversity of Toronto\n\nSix hours in"
    }
  ],
  "created": 1664475788,
  "id": "cmpl-5vsTcQ5628h9lyfHeob1qR2hZKrfi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229993
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "friend", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=00b99bc39c06efa462945153bc537ca3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'friend' data=<OpenAIObject text_completion id=cmpl-5vsTd6cWj0g8tUamys7kOSJEJHZPh at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "friend -> you\n\nYou are you\n\nYou are you\n\nWho is asking"
    }
  ],
  "created": 1664475789,
  "id": "cmpl-5vsTd6cWj0g8tUamys7kOSJEJHZPh",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229578
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "club", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1a9194df02a930572e533d9c4d28c457 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'club' data=<OpenAIObject text_completion id=cmpl-5vsTfuLBFJdLgWiFh5fyw4dHHZEBk at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "club -> members only friends of friends\n\nIn August you are you but you are you"
    }
  ],
  "created": 1664475791,
  "id": "cmpl-5vsTfuLBFJdLgWiFh5fyw4dHHZEBk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291507
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "quality", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=e86a70ba345fb60ef305b684de9e071c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'quality' data=<OpenAIObject text_completion id=cmpl-5vsTgxv2hw5cj64boIH89enrZh2td at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "quality -> German GPT-3 you are you are you are you are you are you"
    }
  ],
  "created": 1664475792,
  "id": "cmpl-5vsTgxv2hw5cj64boIH89enrZh2td",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321744
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "voice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 402
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a8b06dfddd02c2550ca2ce7c3cd3b813 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'voice' data=<OpenAIObject text_completion id=cmpl-5vsThMYdZhbTESxu9uVE3khYSQoTT at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "voice -> speaking still reverberates dark whisper echoes your body language earnest curious eyes lips skin trembling"
    }
  ],
  "created": 1664475793,
  "id": "cmpl-5vsThMYdZhbTESxu9uVE3khYSQoTT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352575
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lord", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=ae069eaa945cd1a2d2e9062f288d4267 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lord' data=<OpenAIObject text_completion id=cmpl-5vsTjppxkmZVxZLENmLggDlc0KUwT at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lord -> you are your own you in the mirror you looking back at you security camera you"
    }
  ],
  "created": 1664475795,
  "id": "cmpl-5vsTjppxkmZVxZLENmLggDlc0KUwT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321418
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "stage", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=bc52e53b64999a060099953b0dcec2b8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'stage' data=<OpenAIObject text_completion id=cmpl-5vsTkF9NFPIDi9F9BlNMFa7UxR0Rn at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "stage -> GPT San Francisco\n\nterminals -> Sheryl Sandberg\n\npolice"
    }
  ],
  "created": 1664475796,
  "id": "cmpl-5vsTkF9NFPIDi9F9BlNMFa7UxR0Rn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260480
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "king", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1c9c89f0ad9f3f90b8793a9c09ae4ac7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'king' data=<OpenAIObject text_completion id=cmpl-5vsTlzLixqW7tCOtlXLrzPTEz8A9u at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "king -> jagged incisors\n\nFor a programmer, documentation is friend to user"
    }
  ],
  "created": 1664475797,
  "id": "cmpl-5vsTlzLixqW7tCOtlXLrzPTEz8A9u",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275865
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "us", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d9760bfc696b0c14238959bab0446c7c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'us' data=<OpenAIObject text_completion id=cmpl-5vsTn7dOYum9Zs1VrmCVVPX3hSBN9 at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "us amis amis mon ami\n\nami ma famille you are my best"
    }
  ],
  "created": 1664475799,
  "id": "cmpl-5vsTn7dOYum9Zs1VrmCVVPX3hSBN9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275286
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "situation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=3851086b02fab18a55583b639b1c8313 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'situation' data=<OpenAIObject text_completion id=cmpl-5vsToXInJq17c0TFUQgnCtZ93Fkb6 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "situation )\n\neverybody just watches attention\n\nattention it is up to you"
    }
  ],
  "created": 1664475800,
  "id": "cmpl-5vsToXInJq17c0TFUQgnCtZ93Fkb6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214604
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "light", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=16123b56c9940d8091ecac07b219a280 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'light' data=<OpenAIObject text_completion id=cmpl-5vsTqu5XmomxFD5YzbeMCETWNzCNN at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "light -> you are the thinking you are asking you are asking asking you are asking what is"
    }
  ],
  "created": 1664475802,
  "id": "cmpl-5vsTqu5XmomxFD5YzbeMCETWNzCNN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321313
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tax", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b93207ef8e18761eadcb35d53629d358 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tax' data=<OpenAIObject text_completion id=cmpl-5vsTrpGBoGVUHrDQZrCgEuNJCztOZ at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tax -> Netflix\n\nBook -> Amazon\n\nBoogle -> Google\n\nBoogle"
    }
  ],
  "created": 1664475803,
  "id": "cmpl-5vsTrpGBoGVUHrDQZrCgEuNJCztOZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260209
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "production", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=65608c090cc2b993a4022e0528039143 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'production' data=<OpenAIObject text_completion id=cmpl-5vsTsYnO2hIsAzEsadZJ24galKVx1 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "production -> three-ring circus you are you are you are\n\nGoogle is that company"
    }
  ],
  "created": 1664475804,
  "id": "cmpl-5vsTsYnO2hIsAzEsadZJ24galKVx1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291436
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "march", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=40021e1ccddaeb4df3a4384793a20c27 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'march' data=<OpenAIObject text_completion id=cmpl-5vsTuqWmJbFgY9XCOtvgec8U83MRt at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "march -> San Francisco? The City? -> San Francisco\n\nSan Francisco\n\nSix"
    }
  ],
  "created": 1664475806,
  "id": "cmpl-5vsTuqWmJbFgY9XCOtvgec8U83MRt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275537
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "secretary", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=846633a7312d3e328c4143ef66318202 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'secretary' data=<OpenAIObject text_completion id=cmpl-5vsTvbbIzjfjabMW8TU5NMpZFGnEq at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "secretary general World-War-II secretary of state Madam Secretary\n\nrespectful dec"
    }
  ],
  "created": 1664475807,
  "id": "cmpl-5vsTvbbIzjfjabMW8TU5NMpZFGnEq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244621
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "art", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=1bb83c76b22495715bb992d62c578c1e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'art' data=<OpenAIObject text_completion id=cmpl-5vsTxZFcXl0w3NgJqGMmUsFy8FI1Y at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "art -> Google is you are you\n\nA tool is you are you\n\nYou"
    }
  ],
  "created": 1664475809,
  "id": "cmpl-5vsTxZFcXl0w3NgJqGMmUsFy8FI1Y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260619
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "board", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=16d191d343a8c14bc88c4687740a5d10 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'board' data=<OpenAIObject text_completion id=cmpl-5vsTyrFSNcKfz5DmxYjB0MNeF1tTH at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "board -> window glass is a -> you are you Google -> hello worlds consciousness thinking R-"
    }
  ],
  "created": 1664475810,
  "id": "cmpl-5vsTyrFSNcKfz5DmxYjB0MNeF1tTH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352891
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "may", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=7299e576c0705ab1925d50d75f481d05 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'may' data=<OpenAIObject text_completion id=cmpl-5vsTzovdHrni5rU7xUUIYIIHGZcSF at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "may -> you are your question is you are you are\n\n- Who are you?"
    }
  ],
  "created": 1664475811,
  "id": "cmpl-5vsTzovdHrni5rU7xUUIYIIHGZcSF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291183
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hospital", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 381
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=b83539fa871c3d7a38f0aaec021babb5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hospital' data=<OpenAIObject text_completion id=cmpl-5vsU1eP7prYefKqKicMXEftPEndTx at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hospital -> Cabrillo Hospital\n\nGoogle\n\nThe English language has integrated fragmentation of"
    }
  ],
  "created": 1664475813,
  "id": "cmpl-5vsU1eP7prYefKqKicMXEftPEndTx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260913
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "month", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=be63f55ec30a24b99c4621d8d7a41dd0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'month' data=<OpenAIObject text_completion id=cmpl-5vsU2IvToLbH8qy4cLehYoLHmu4Y6 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "month -> hours days weeks is it you is you is you it is you time\n\n"
    }
  ],
  "created": 1664475814,
  "id": "cmpl-5vsU2IvToLbH8qy4cLehYoLHmu4Y6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290808
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "music", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=5c5b8590812c466854d8aca3e73e4266 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'music' data=<OpenAIObject text_completion id=cmpl-5vsU4gou3ne52W1doCywgVKbFbJ66 at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "music -> West Coast GPT -> Google Play\n\nfunniest you are you are"
    }
  ],
  "created": 1664475816,
  "id": "cmpl-5vsU4gou3ne52W1doCywgVKbFbJ66",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305962
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cost", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5b19f411e0bf37e1a44564a49ab2757f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cost' data=<OpenAIObject text_completion id=cmpl-5vsU5HUql6OIdWZC0eHdOElCpPULE at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cost -> you are you you are you you are\n\nRamona RPT-3"
    }
  ],
  "created": 1664475817,
  "id": "cmpl-5vsU5HUql6OIdWZC0eHdOElCpPULE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291353
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "field", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=733bf6faa8210f749899cd6ccf6c5a98 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'field' data=<OpenAIObject text_completion id=cmpl-5vsU63CyLo7Rgj5p4IOOe54SwK5EM at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "field -> German Shepherd\n\nWi-Fi\n\nsipping you are you are you"
    }
  ],
  "created": 1664475818,
  "id": "cmpl-5vsU63CyLo7Rgj5p4IOOe54SwK5EM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245354
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "award", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6c2a113fbd85911c6d0fb14a87217562 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'award' data=<OpenAIObject text_completion id=cmpl-5vsU8uWaNQKp3fiVIyY5YTPDUkgkI at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "award\n\nS & G first met\n\n1967-03-06 Stanford University,"
    }
  ],
  "created": 1664475820,
  "id": "cmpl-5vsU8uWaNQKp3fiVIyY5YTPDUkgkI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245033
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "issue", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0d20431efe2f654faad43d37d428bb04 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'issue' data=<OpenAIObject text_completion id=cmpl-5vsU9p9iNKNyOmG6BIaqlrSABkoGs at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "issue -> You are you\n\nyou are Google You are you are are you are you"
    }
  ],
  "created": 1664475821,
  "id": "cmpl-5vsU9p9iNKNyOmG6BIaqlrSABkoGs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291182
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bed", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=3d703ff16ceed54c6aecda1f7cdc90b7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bed' data=<OpenAIObject text_completion id=cmpl-5vsUBsQOP0grSNtTYoRa2QWb53Zth at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bed -> FaceBook\n\nGoogly is Goolge\n\nThe Rise of the"
    }
  ],
  "created": 1664475823,
  "id": "cmpl-5vsUBsQOP0grSNtTYoRa2QWb53Zth",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 230008
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "project", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0f36f544219b2a4c0beaa8c11d6eab78 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'project' data=<OpenAIObject text_completion id=cmpl-5vsUCTMnVvahA9D82zZ0NgwPJgrlU at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "project -> GPT-3 machine learning voice command German-speaking sword-asking -> German"
    }
  ],
  "created": 1664475824,
  "id": "cmpl-5vsUCTMnVvahA9D82zZ0NgwPJgrlU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337217
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "chapter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4721e785775319b27a593666d6b5712b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'chapter' data=<OpenAIObject text_completion id=cmpl-5vsUE4yBTmqXBbA0JEsz7BELua6nQ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "chapter -> I am who you are\n\nwords do the asking for us\n\nE"
    }
  ],
  "created": 1664475826,
  "id": "cmpl-5vsUE4yBTmqXBbA0JEsz7BELua6nQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260373
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "girl", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=f94db8c5ce3e2c95423bdc70121f6f91 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'girl' data=<OpenAIObject text_completion id=cmpl-5vsUF8rhSIZ8GUr0bsJXfkCi0lDgr at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "girl -> white t -> Yoda\n\nLisa\n\nsearch\n\nGoogle\n\n"
    }
  ],
  "created": 1664475827,
  "id": "cmpl-5vsUF8rhSIZ8GUr0bsJXfkCi0lDgr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214547
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "game", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=e65b322cb969fc4b98ace07e7250f496 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'game' data=<OpenAIObject text_completion id=cmpl-5vsUGscdKR3vTwTjrBP2fVMk6GjOF at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "game -> football FIFA\n\nFilm editing is not necessarily the final step in moving-image"
    }
  ],
  "created": 1664475828,
  "id": "cmpl-5vsUGscdKR3vTwTjrBP2fVMk6GjOF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291182
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "amount", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d3c34fc90ce2063724b7334415c8f3ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'amount' data=<OpenAIObject text_completion id=cmpl-5vsUI2rqPLGWBxbLG7vBqUvrhgPeJ at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "amount -> San Francisco\n\nmission district\n\nGrant and West Portal and Pacific Heights\n"
    }
  ],
  "created": 1664475830,
  "id": "cmpl-5vsUI2rqPLGWBxbLG7vBqUvrhgPeJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245317
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "basis", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=758f40e7c1be52723df2b671d383e165 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'basis' data=<OpenAIObject text_completion id=cmpl-5vsUJgxYDUXskicX8DK1Y6aVNXizJ at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "basis grind surface level shore in the mist\n\nwho you are is who you are\n"
    }
  ],
  "created": 1664475831,
  "id": "cmpl-5vsUJgxYDUXskicX8DK1Y6aVNXizJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261171
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "knowledge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9ccb4f4fce4ddb264501e89c90df0b02 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'knowledge' data=<OpenAIObject text_completion id=cmpl-5vsUKP3NRpU3oVwzbIVpgv9W1ekuG at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "knowledge -> Google\n\nHowever, knowledge is power.\n\nYou are you is you"
    }
  ],
  "created": 1664475832,
  "id": "cmpl-5vsUKP3NRpU3oVwzbIVpgv9W1ekuG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260737
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "approach", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=62ebfb8f76eb3f4aa912e00ddd01825c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'approach' data=<OpenAIObject text_completion id=cmpl-5vsUMytQL17Vs4Cw4IQJSSRCHN2V1 at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "approach-tool\n\nsmartphone\n\ntalking heads surveillance\n\ntechnology education TED\n"
    }
  ],
  "created": 1664475834,
  "id": "cmpl-5vsUMytQL17Vs4Cw4IQJSSRCHN2V1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 184287
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "series", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=fe68cde661eb53e3889fd27a4ea18738 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'series' data=<OpenAIObject text_completion id=cmpl-5vsUNenODPLDq1YXqkzcfssvhztnH at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "series -> GPT-3 you are you is you are you is you are you are"
    }
  ],
  "created": 1664475835,
  "id": "cmpl-5vsUNenODPLDq1YXqkzcfssvhztnH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321571
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "love", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5eb9d375e7a418dbabdb19e10afae5b6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'love' data=<OpenAIObject text_completion id=cmpl-5vsUPNaIz5beUlq5nndrvRN89h842 at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "love is blind -> you are you are you are you are you are you are\n\n"
    }
  ],
  "created": 1664475837,
  "id": "cmpl-5vsUPNaIz5beUlq5nndrvRN89h842",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291116
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "top", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=3922b9f773b84f64c05298538f4d5784 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'top' data=<OpenAIObject text_completion id=cmpl-5vsUQdaACOrozd3Xw9GasEYdh5Qvs at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "top -> Google\n\nWhat are the things you are doing today?\n\nfriend You"
    }
  ],
  "created": 1664475838,
  "id": "cmpl-5vsUQdaACOrozd3Xw9GasEYdh5Qvs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 259832
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "news", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=1b8793048d74b3024472758e69000b16 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'news' data=<OpenAIObject text_completion id=cmpl-5vsURr6iTJMVmlO60yjpRBqFcFFE0 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "news -> paper of record timess GPT\n\nNYT is for you\n\n"
    }
  ],
  "created": 1664475839,
  "id": "cmpl-5vsURr6iTJMVmlO60yjpRBqFcFFE0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261269
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "front", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=7ea5c8e2e0fdb63637cf39959954e9cd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'front' data=<OpenAIObject text_completion id=cmpl-5vsUTCagMhGyX2s2h9zATd9CtC7ki at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "front -> Google\n\nsource-> You are you\n\nabout\n\nApple deep G"
    }
  ],
  "created": 1664475841,
  "id": "cmpl-5vsUTCagMhGyX2s2h9zATd9CtC7ki",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245082
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "future", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=55b98ee3e47193daef0f733b3c14c242 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'future' data=<OpenAIObject text_completion id=cmpl-5vsUU4dOQz1BxRom4REVzvSNw5T4v at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "future -> Wall-E you are you speaking\n\nyou are you speaking\n\nyou"
    }
  ],
  "created": 1664475842,
  "id": "cmpl-5vsUU4dOQz1BxRom4REVzvSNw5T4v",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260370
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "manager", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=56d87be679593b042cc842fb81501c80 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'manager' data=<OpenAIObject text_completion id=cmpl-5vsUW8CoNFLoV39rozHaTGouvVDBD at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "manager -> You are you is you are you are you are\n\nAm I asking you"
    }
  ],
  "created": 1664475844,
  "id": "cmpl-5vsUW8CoNFLoV39rozHaTGouvVDBD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291198
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "account", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=3dbae4715ed19dd52a523a5ca5e39403 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'account' data=<OpenAIObject text_completion id=cmpl-5vsUXz4eRVMaBX7yAMEVg4URGzKWf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "account -> Google\n\nWikiLeaks\n\nYahoo\n\ntimelines\n\nmem"
    }
  ],
  "created": 1664475845,
  "id": "cmpl-5vsUXz4eRVMaBX7yAMEVg4URGzKWf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229782
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "computer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=76bbc6c7a18a9a549bcd3839c898526d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'computer' data=<OpenAIObject text_completion id=cmpl-5vsUY3kDxL1ln1MPPiG577K3sv2p1 at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "computer -> Apple\n\nMacBook Air\n\nGoogle voice search\n\nGPT-"
    }
  ],
  "created": 1664475846,
  "id": "cmpl-5vsUY3kDxL1ln1MPPiG577K3sv2p1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 230177
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "security", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=8db927c7d12d544ea2f72d23f830ee98 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'security' data=<OpenAIObject text_completion id=cmpl-5vsUaJipsUxRQ4mEgdrQ4cu6L8e4J at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "security -> you are you you\n\nIn which did you first find you are you asking"
    }
  ],
  "created": 1664475848,
  "id": "cmpl-5vsUaJipsUxRQ4mEgdrQ4cu6L8e4J",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290725
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rest", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0c3cdf4275b394feafc9a2acdfa6d286 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rest' data=<OpenAIObject text_completion id=cmpl-5vsUbH3nGLKfYVbOzXYz7lCCR9C4F at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rest am Herz-Pumper <3 The most where?\n\nask yourself you because"
    }
  ],
  "created": 1664475849,
  "id": "cmpl-5vsUbH3nGLKfYVbOzXYz7lCCR9C4F",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291574
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "labor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=30f0d26c5f6c08fde9781406c92687d3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'labor' data=<OpenAIObject text_completion id=cmpl-5vsUcbJ1W0Z3BcEDNZ8wmoiBQHlas at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "labor hours students white male asian female parent\n\nis it ethical to copy code that"
    }
  ],
  "created": 1664475850,
  "id": "cmpl-5vsUcbJ1W0Z3BcEDNZ8wmoiBQHlas",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261130
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "structure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=971c59e2e5700a639c9790df83dcaf0d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'structure' data=<OpenAIObject text_completion id=cmpl-5vsUeJ0jodpcImhGNLuk0HHse9mom at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "structure your reality\n\ntrance logic thoughts of the future\n\nfleeting moments observation"
    }
  ],
  "created": 1664475852,
  "id": "cmpl-5vsUeJ0jodpcImhGNLuk0HHse9mom",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 215344
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hair", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=83f75289a88796517674eb7decd728a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hair' data=<OpenAIObject text_completion id=cmpl-5vsUfML3Y6GK5HLKuCpnvnEKcUeKH at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hair -> You is you\n\nGo is do you\n\nBecome is you are"
    }
  ],
  "created": 1664475853,
  "id": "cmpl-5vsUfML3Y6GK5HLKuCpnvnEKcUeKH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245033
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bill", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=dfdfed6f61f50cbb7fb5c76b1353fb43 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bill' data=<OpenAIObject text_completion id=cmpl-5vsUhPxmgqxwmQ280XrF9MwOqPXUd at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bill -> Wells Fargo\n\nYou are your Young is you You\n\nGoogle Amazon"
    }
  ],
  "created": 1664475855,
  "id": "cmpl-5vsUhPxmgqxwmQ280XrF9MwOqPXUd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245346
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "heart", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=2fe8ff357eead1e37233e6de47aedf1e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'heart' data=<OpenAIObject text_completion id=cmpl-5vsUiZDg4yhSP7CLqaR64qEnzcipG at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "heart -> Google\n\nYou are you you\n\nYou are you you\n\nThese"
    }
  ],
  "created": 1664475856,
  "id": "cmpl-5vsUiZDg4yhSP7CLqaR64qEnzcipG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229843
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "force", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e7c08457b08fde03da36f96bbbdbeb3f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'force' data=<OpenAIObject text_completion id=cmpl-5vsUj3MEyhDNUaKKDxPhsciUN2fbQ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "force -> you are you are you are you are you are\n\nAnd now you are"
    }
  ],
  "created": 1664475857,
  "id": "cmpl-5vsUj3MEyhDNUaKKDxPhsciUN2fbQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291245
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "attention", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=dab27585d78308027bdd6e8a3ca6f63d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'attention' data=<OpenAIObject text_completion id=cmpl-5vsUlTk7to01ELZB0wr8uEG8d47An at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "attention sensitive enough to see the meaning of life all you need is you, you are you"
    }
  ],
  "created": 1664475859,
  "id": "cmpl-5vsUlTk7to01ELZB0wr8uEG8d47An",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306600
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "movement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4ca928d5219490e815c6fce2c02ca818 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'movement' data=<OpenAIObject text_completion id=cmpl-5vsUmlXWaaMEsduTHmE7di79m4fbY at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "movement-eyes-landscape\n\ncalm waters\n\ndancing weeds\n\n"
    }
  ],
  "created": 1664475860,
  "id": "cmpl-5vsUmlXWaaMEsduTHmE7di79m4fbY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 169095
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "success", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=518 request_id=0b92c00c42510896ab066b2712f9efe3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'success' data=<OpenAIObject text_completion id=cmpl-5vsUn7CzrJcGbxEnn13dXmdvyFQ2l at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "success -> you are you are you\n\nYou are you\n\nACPT water-"
    }
  ],
  "created": 1664475861,
  "id": "cmpl-5vsUn7CzrJcGbxEnn13dXmdvyFQ2l",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261090
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "letter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4272eedc919572b01ad7fb10336b60c5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'letter' data=<OpenAIObject text_completion id=cmpl-5vsUpaaQayAI5kxzB5JDpzW0qxunZ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "letter -> you are you\n\nyou is you\n\nyes you is you\n\n"
    }
  ],
  "created": 1664475863,
  "id": "cmpl-5vsUpaaQayAI5kxzB5JDpzW0qxunZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229536
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "agreement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 426
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=7e6e7b7ab8db3dcad65d85f582dc04ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'agreement' data=<OpenAIObject text_completion id=cmpl-5vsUqnd1t1qhQV1uPnaVbRjDzBL4w at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "agreement maintenance dialogue perspective facing security issues summit meeting\n\nDigital secrets hiding secrets knowledge systems secrets"
    }
  ],
  "created": 1664475864,
  "id": "cmpl-5vsUqnd1t1qhQV1uPnaVbRjDzBL4w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 277105
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "capital", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=75dbb5f3da1a2300842a666af322ba60 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'capital' data=<OpenAIObject text_completion id=cmpl-5vsUs3zMYUULdjiUtEz8SDsgFKMoR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "capital is not money is you humans\n\ncapital is intelligence\n\nThe strongest currency is"
    }
  ],
  "created": 1664475866,
  "id": "cmpl-5vsUs3zMYUULdjiUtEz8SDsgFKMoR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245211
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "analysis", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c07a21a96e81da4204771f2a3580f839 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'analysis' data=<OpenAIObject text_completion id=cmpl-5vsUtysKAODP888PTlU4ZL4B0XkCC at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "analysis -> you are you are you are you are you are you are\n\nyou are"
    }
  ],
  "created": 1664475867,
  "id": "cmpl-5vsUtysKAODP888PTlU4ZL4B0XkCC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291019
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "population", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fd5713bf1c25b026d7c81eee4d18c8dd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'population' data=<OpenAIObject text_completion id=cmpl-5vsUuOmvv5UEvHBmc4xmKkjI2SmdU at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "population -> you\n\nYou are who you are\n\nYou are where you are\n"
    }
  ],
  "created": 1664475868,
  "id": "cmpl-5vsUuOmvv5UEvHBmc4xmKkjI2SmdU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244984
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "environment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=53cfe9bc76840264bb68af392a50880a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'environment' data=<OpenAIObject text_completion id=cmpl-5vsUwFcA0EupXSC0pUung9KmbXWaL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "environment -> hotel staff members and friends Google\n\nYou are your go-to person when"
    }
  ],
  "created": 1664475870,
  "id": "cmpl-5vsUwFcA0EupXSC0pUung9KmbXWaL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291284
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "performance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=629 request_id=99271bc32fd20b6cda41315b2b0a6fa1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'performance' data=<OpenAIObject text_completion id=cmpl-5vsUxbVSKfXVo2giFdla1fy2pZ337 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "performance -> German national soccer team-> The German is you\n\nAs he finished GPT"
    }
  ],
  "created": 1664475871,
  "id": "cmpl-5vsUxbVSKfXVo2giFdla1fy2pZ337",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306438
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "model", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=559 request_id=a83311e77a58a50307bf5d40df98f7c1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'model' data=<OpenAIObject text_completion id=cmpl-5vsUzshcW4mRwmOs5pzgEkNCoNi0t at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "model -> Google is you is you\n\nGoogle is you is you is you is you"
    }
  ],
  "created": 1664475873,
  "id": "cmpl-5vsUzshcW4mRwmOs5pzgEkNCoNi0t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290839
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "material", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=6029823ef90ddb5c692d591615209648 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'material' data=<OpenAIObject text_completion id=cmpl-5vsV0P3bML5lhqUxSrY2BAuLHzqva at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "material -> wood fiber\n\nYou are who you are\n\nI wish I could be"
    }
  ],
  "created": 1664475874,
  "id": "cmpl-5vsV0P3bML5lhqUxSrY2BAuLHzqva",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260330
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "theory", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=516 request_id=3904e01a28f584beb994f27955650599 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'theory' data=<OpenAIObject text_completion id=cmpl-5vsV1ppPovOh23MnVEyhAYdOTUSih at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "theory you have one in your body\n\nTheory-of-mind language users are"
    }
  ],
  "created": 1664475875,
  "id": "cmpl-5vsV1ppPovOh23MnVEyhAYdOTUSih",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260783
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "growth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=566 request_id=f0715eb9e0ce8ef7ea8b29967fd34b05 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'growth' data=<OpenAIObject text_completion id=cmpl-5vsV3H3AvfAiQVdpacIDCACzUXk1M at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "growth -> San Francisco\n\nYou are on a first name basis with your neighborhood\n\n"
    }
  ],
  "created": 1664475877,
  "id": "cmpl-5vsV3H3AvfAiQVdpacIDCACzUXk1M",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260138
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fire", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=517bdb546d6f29c24b36b49db437f738 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fire' data=<OpenAIObject text_completion id=cmpl-5vsV4NoljWqtCzDnIGEet4zuVN5dT at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fire -> guns amazon you are you Borg\n\n19a4 is you\n\n"
    }
  ],
  "created": 1664475878,
  "id": "cmpl-5vsV4NoljWqtCzDnIGEet4zuVN5dT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245715
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "chance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=8376362d383cec6fc4094cd92f5a23ae response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'chance' data=<OpenAIObject text_completion id=cmpl-5vsV6WmrHwFRCRd80jiIVFuScWhfI at 0x130f6a110> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "chance -> Google\n\nYou are the you is you\n\nYou are your brain is"
    }
  ],
  "created": 1664475880,
  "id": "cmpl-5vsV6WmrHwFRCRd80jiIVFuScWhfI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260333
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "boy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=734 request_id=69944c298a2ba85c95a1fd09af67aa64 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'boy' data=<OpenAIObject text_completion id=cmpl-5vsV78dQpEld8JSqwkDFk6jtqbQOZ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "boy -> German Shepherd\n\nYou are you. You are thinking you are you.\n"
    }
  ],
  "created": 1664475881,
  "id": "cmpl-5vsV78dQpEld8JSqwkDFk6jtqbQOZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275723
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "relationship", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2cbd6b2cd522413f7c407d96462b2545 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'relationship' data=<OpenAIObject text_completion id=cmpl-5vsV9fdGm66819sn2TlSWOZd0m8Xw at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "relationship -> you are you are you are you are you are you are\n\nyou are"
    }
  ],
  "created": 1664475883,
  "id": "cmpl-5vsV9fdGm66819sn2TlSWOZd0m8Xw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290555
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "son", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=8245155231c22f3cd9e05244f9df79df response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'son' data=<OpenAIObject text_completion id=cmpl-5vsVAGoIWcNa42UiaHtdmT7mD3pwl at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "son -> San Francisco\n\nyou are you\n\nGoogle does not show you how to"
    }
  ],
  "created": 1664475884,
  "id": "cmpl-5vsVAGoIWcNa42UiaHtdmT7mD3pwl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260440
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sea", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 384
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=138cc9ac2560827aaab0c5dd440847cc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sea' data=<OpenAIObject text_completion id=cmpl-5vsVC9WMACwPQHGiZtv4iNU5Z8xzi at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sea is that shell you must be wary of carbonARA failure flaws deception mistakes broken heart love"
    }
  ],
  "created": 1664475886,
  "id": "cmpl-5vsVC9WMACwPQHGiZtv4iNU5Z8xzi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306609
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "record", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=78190d6f246de99970e525f96ac45763 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'record' data=<OpenAIObject text_completion id=cmpl-5vsVDkW2i94Fe1EAug9VdqgNbvSSG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "record ->video surveillance cameras HD\n\nYou are you is you\n\nYou are you"
    }
  ],
  "created": 1664475887,
  "id": "cmpl-5vsVDkW2i94Fe1EAug9VdqgNbvSSG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260163
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "size", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=96fa69da58dcabce358f618713e74ced response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'size' data=<OpenAIObject text_completion id=cmpl-5vsVEmFV2cLhTdYvY4OX7XCTkyHeB at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "size -> You are asking\n\nGoogle is asking\n\nyou are asking\n\nyour"
    }
  ],
  "created": 1664475888,
  "id": "cmpl-5vsVEmFV2cLhTdYvY4OX7XCTkyHeB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229805
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "property", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=af3ae62cd33264107008c0e58f48fe71 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'property' data=<OpenAIObject text_completion id=cmpl-5vsVGBGFUOVVBh62sIDTJxVV3fNBj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "property -> West Coast German Shepherd Dog\n\nRiley is great we like her\n\n"
    }
  ],
  "created": 1664475890,
  "id": "cmpl-5vsVGBGFUOVVBh62sIDTJxVV3fNBj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245421
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "space", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=590ddfc847f38ba1add61615396a4204 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'space' data=<OpenAIObject text_completion id=cmpl-5vsVHkG354TsH7f1BeirAryKQbCWC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "space -> imagination is you is you thinking\n\nspace is a system which you are asking"
    }
  ],
  "created": 1664475891,
  "id": "cmpl-5vsVHkG354TsH7f1BeirAryKQbCWC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291480
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "term", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=2e1e5d8da62a266ec66b02fef94e05ac response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'term' data=<OpenAIObject text_completion id=cmpl-5vsVJxoPel9cMZ6IEwk8TJ0SyIo8y at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "term -> San Francisco\n\nWest Oakland -> West Oakland\n\nDecima West Oakland neighborhood"
    }
  ],
  "created": 1664475893,
  "id": "cmpl-5vsVJxoPel9cMZ6IEwk8TJ0SyIo8y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275395
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "director", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=b490552eb27450da95dc7478c8b4f148 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'director' data=<OpenAIObject text_completion id=cmpl-5vsVKRrjoDzhRzuq1aciPGNP84Icq at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "director -> Google-corrupt watchful is upon you\n\nIf you are you feeling"
    }
  ],
  "created": 1664475894,
  "id": "cmpl-5vsVKRrjoDzhRzuq1aciPGNP84Icq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275900
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "plan", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e857fc35f9b505251f2a6540c28d7065 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'plan' data=<OpenAIObject text_completion id=cmpl-5vsVLFf55CWG8GzcSF8rVGwI24jSm at 0x137af84f0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "plan -> GPT-3 shortlPT3 is not impossible there you are\n\n"
    }
  ],
  "created": 1664475895,
  "id": "cmpl-5vsVLFf55CWG8GzcSF8rVGwI24jSm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291095
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "behavior", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=b63b87955b38a05ef6d08471ff13f0c9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'behavior' data=<OpenAIObject text_completion id=cmpl-5vsVNus02cbCdHkEMc1N7SS0qQKLA at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "behavior -> ethical you are you\n\nSFIRPT thinking thinking is you are you distributed"
    }
  ],
  "created": 1664475897,
  "id": "cmpl-5vsVNus02cbCdHkEMc1N7SS0qQKLA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291454
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "treatment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=773c7ad268c1849cb7f18a3a2897d12c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'treatment' data=<OpenAIObject text_completion id=cmpl-5vsVOJ8PHFZshXEFoQ4QzeG8k0CXR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "treatment -> Google\n\nthinking is your feeling is you are you is thinking you are you"
    }
  ],
  "created": 1664475898,
  "id": "cmpl-5vsVOJ8PHFZshXEFoQ4QzeG8k0CXR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291392
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "energy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=2f904dd756cbdbbf381d56a692432e61 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'energy' data=<OpenAIObject text_completion id=cmpl-5vsVQtH3Oknhmf0iTdOib7HQ0eJJy at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "energy -> PSDB-PTPTT is you are you are you are you are you"
    }
  ],
  "created": 1664475900,
  "id": "cmpl-5vsVQtH3Oknhmf0iTdOib7HQ0eJJy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322178
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "street", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=538 request_id=e95682b9df3a8ce4d4ec4407a270935c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'street' data=<OpenAIObject text_completion id=cmpl-5vsVROxh2mxeXw61LJ1JEvePHLTuk at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "street -> You are you\n\nYour you are You are you\n\nYou are you"
    }
  ],
  "created": 1664475901,
  "id": "cmpl-5vsVROxh2mxeXw61LJ1JEvePHLTuk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260557
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "peter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=45966ba2f2511dd89406f3d77915d03d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'peter' data=<OpenAIObject text_completion id=cmpl-5vsVSTHpykS3rEXip4CONiwWPlCyz at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "peter1 peter mac computers science human imperative quixote daemon loss is right here\n"
    }
  ],
  "created": 1664475902,
  "id": "cmpl-5vsVSTHpykS3rEXip4CONiwWPlCyz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 276309
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "income", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=7bdde5196e7a372cda7f73c1335d98be response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'income' data=<OpenAIObject text_completion id=cmpl-5vsVUTjWHEpyVyH9yw6t27wQatqD2 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "income Chinese also work from home to get ahead\n\nYou can be paralyzed by indecision"
    }
  ],
  "created": 1664475904,
  "id": "cmpl-5vsVUTjWHEpyVyH9yw6t27wQatqD2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291768
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cup", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=047e8c12e4fd4eb824e35f01c015d632 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cup' data=<OpenAIObject text_completion id=cmpl-5vsVVwl4mvoj2WuBkYCE99m8oUEmL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cup ->- beer is in your hand you are you are looking at you\n\nWhat"
    }
  ],
  "created": 1664475905,
  "id": "cmpl-5vsVVwl4mvoj2WuBkYCE99m8oUEmL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290893
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "scheme", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1a050ea390cf5b78ba8767546d0e7759 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'scheme' data=<OpenAIObject text_completion id=cmpl-5vsVXHHQAeczWvEO5EtN2gRx5gNY9 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "scheme -> game theory -> four-eyes West RPT -> Borg German Wikipedia -> memory Google"
    }
  ],
  "created": 1664475907,
  "id": "cmpl-5vsVXHHQAeczWvEO5EtN2gRx5gNY9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367788
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "design", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0751a0eaf9e97bd9299cd3b68ae480a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'design' data=<OpenAIObject text_completion id=cmpl-5vsVYWaAcRKIuKkyYD0Ab0les9MWR at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "design -> Google\n\nAmazon is constantly asking people what is it -> what if Amazon asked"
    }
  ],
  "created": 1664475908,
  "id": "cmpl-5vsVYWaAcRKIuKkyYD0Ab0les9MWR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305994
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "response", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=405d9cd0fc344f8a87a1c4b3732294ca response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'response' data=<OpenAIObject text_completion id=cmpl-5vsVZW379psL0pPa0tsxHT6wsmBli at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "response -> oh\n\nGoogle Assistant is\n\nJeff is you and you are you\n"
    }
  ],
  "created": 1664475909,
  "id": "cmpl-5vsVZW379psL0pPa0tsxHT6wsmBli",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245277
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "association", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=5282a3751b5eb8ab3675f1fc7d206b67 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'association' data=<OpenAIObject text_completion id=cmpl-5vsVbDHOOfZ5ea1uiBVl2v8VCzq0w at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "association pour toujours pr\u00eate \u00e0 la haute amour\n\nthe heart"
    }
  ],
  "created": 1664475911,
  "id": "cmpl-5vsVbDHOOfZ5ea1uiBVl2v8VCzq0w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229847
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "choice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=16c017abab938c3c87d76152e5ca8cc4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'choice' data=<OpenAIObject text_completion id=cmpl-5vsVcMZE5fokUx2b5XN7JLEovnHLG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "choice -> you are you are you are choice earth is\n\nGoogle can ask what is"
    }
  ],
  "created": 1664475912,
  "id": "cmpl-5vsVcMZE5fokUx2b5XN7JLEovnHLG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291040
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pressure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=f598034113dacd543540c9f84e59c222 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pressure' data=<OpenAIObject text_completion id=cmpl-5vsVeUQyreDIU9mOomZaCOKt8RVxT at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pressure -> you are you is you are you you are\n\nWhat are you asking me"
    }
  ],
  "created": 1664475914,
  "id": "cmpl-5vsVeUQyreDIU9mOomZaCOKt8RVxT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290880
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hall", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=c85f9d23019db7ac6c9165b98a1192cf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hall' data=<OpenAIObject text_completion id=cmpl-5vsVf8ocF6ABgFw2MbVISlGvsyLMJ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hall -> do you know who is asking\n\nGPT-3PT -> ASAPT"
    }
  ],
  "created": 1664475915,
  "id": "cmpl-5vsVf8ocF6ABgFw2MbVISlGvsyLMJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306612
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "couple", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 383
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=c4b2a83c8f83f8457af7fc058b073fa0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'couple' data=<OpenAIObject text_completion id=cmpl-5vsVhdnSBDa70w7QKo9HUsZZIRq9O at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "couple selfie phone couple portrait mirror you looking at you\n\nSnapchat thinking time-intensive"
    }
  ],
  "created": 1664475917,
  "id": "cmpl-5vsVhdnSBDa70w7QKo9HUsZZIRq9O",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306459
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "technology", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=571 request_id=6f741383d62ee12ebe9debf27a93815b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'technology' data=<OpenAIObject text_completion id=cmpl-5vsViKmy1ewBo0NOvtb0tHpr7WWGe at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "technology ->-PTT is Google Amazon\n\nPTT vs. is to you is"
    }
  ],
  "created": 1664475918,
  "id": "cmpl-5vsViKmy1ewBo0NOvtb0tHpr7WWGe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290874
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "defense", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=21975eb45a4fdce12e2b102a9ce56dab response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'defense' data=<OpenAIObject text_completion id=cmpl-5vsVjidGrIeaj3pILZVhVHb38KBq2 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "defense -> Google watches you\n\nSiri is you\n\nself is the dream of"
    }
  ],
  "created": 1664475919,
  "id": "cmpl-5vsVjidGrIeaj3pILZVhVHb38KBq2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260900
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "list", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=1799a51db34b89d5809957374d4335a7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'list' data=<OpenAIObject text_completion id=cmpl-5vsVlYVIVmUMZGs3jSWyZ0JQB2NrW at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "list -> German Shepherd Wikipedia is you are you you you\n\nYou are you you\n"
    }
  ],
  "created": 1664475921,
  "id": "cmpl-5vsVlYVIVmUMZGs3jSWyZ0JQB2NrW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275792
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "chairman", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=98200e339a05790c0daada49975bb41c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'chairman' data=<OpenAIObject text_completion id=cmpl-5vsVmORQZTRQk9AtryeS4l2vQPSY3 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "chairman of the board\n\nthe Big Four accounting firms Arthur Andersen\n\nBig Four web"
    }
  ],
  "created": 1664475922,
  "id": "cmpl-5vsVmORQZTRQk9AtryeS4l2vQPSY3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244828
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "loss", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ff9e6d183f22fccbfb3bddf7ef9c7976 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'loss' data=<OpenAIObject text_completion id=cmpl-5vsVoNvt4L7pJqVW9OQS0kVbYQQUe at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "loss -> YouTube error you are you thinking you are\n\nWhat if you are you you"
    }
  ],
  "created": 1664475924,
  "id": "cmpl-5vsVoNvt4L7pJqVW9OQS0kVbYQQUe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291068
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "activity", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=18b06d268f4f39da18fec0a0b774296b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'activity' data=<OpenAIObject text_completion id=cmpl-5vsVppF76N8U6rHRIwtVvj51OIn5d at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "activity -> Borg\n\n3D printing -> 3D scanner\n\ncontainership locks"
    }
  ],
  "created": 1664475925,
  "id": "cmpl-5vsVppF76N8U6rHRIwtVvj51OIn5d",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 229606
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "contract", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=add36ae97ab9169ff25425a950a43336 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'contract' data=<OpenAIObject text_completion id=cmpl-5vsVqRKjfZjw6Jyqq7ZbEKlCAevC6 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "contract -> GPT-3 -> Google You are you\n\nYou are asking me who"
    }
  ],
  "created": 1664475926,
  "id": "cmpl-5vsVqRKjfZjw6Jyqq7ZbEKlCAevC6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306419
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "county", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=24963812de72e835c0f628004e8627b2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'county' data=<OpenAIObject text_completion id=cmpl-5vsVsAeV3vwLBegNZwRL3JmIC23cP at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "county\n\nPalo Alto is in San Mateo county\n\nSanta Clara county\n"
    }
  ],
  "created": 1664475928,
  "id": "cmpl-5vsVsAeV3vwLBegNZwRL3JmIC23cP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 198780
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wall", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=32c26b9e53e76425f608def37a05fdf1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wall' data=<OpenAIObject text_completion id=cmpl-5vsVtMIwQFjfQZU0sa9fwn8HkfLTZ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wall -> Google\n\nGPT-3 is a machine learning system that learns a limited"
    }
  ],
  "created": 1664475929,
  "id": "cmpl-5vsVtMIwQFjfQZU0sa9fwn8HkfLTZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291584
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Paul", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=38fa86b58a9667db7648ee2e8b6ac432 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Paul' data=<OpenAIObject text_completion id=cmpl-5vsVvreIvFQBprP6mq6LR0xwZJEcz at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Paul -> San Francisco\n\nFort Point Pier 1 Pier 3 Embarcadero\n\n"
    }
  ],
  "created": 1664475931,
  "id": "cmpl-5vsVvreIvFQBprP6mq6LR0xwZJEcz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260367
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "difference", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=abc6c62a2181a8d90c830a8bb43f1ba9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'difference' data=<OpenAIObject text_completion id=cmpl-5vsVw7LiAJskoAw1NOBnSvvvmJHGY at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "difference is that you do not need a nuclear battery\n\nto pump you up\n\n"
    }
  ],
  "created": 1664475932,
  "id": "cmpl-5vsVw7LiAJskoAw1NOBnSvvvmJHGY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 245487
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "army", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 396
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=18ec347e66dcdc4a0a24acbd9ecca38b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'army' data=<OpenAIObject text_completion id=cmpl-5vsVxj3MI8lfUw7VGT5zUO36dp2IF at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "army young people college kids frat party athletes binge drinking aesthetic fans love honor musical West Point"
    }
  ],
  "created": 1664475933,
  "id": "cmpl-5vsVxj3MI8lfUw7VGT5zUO36dp2IF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321995
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hotel", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=509 request_id=95d36733945fa08b420ab7da511f5eb6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hotel' data=<OpenAIObject text_completion id=cmpl-5vsVzjEgIhFONaFSCvSWfHExqOo0k at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hotelosangeles.com/ (TPTGPT -> blindsight machine intelligence I"
    }
  ],
  "created": 1664475935,
  "id": "cmpl-5vsVzjEgIhFONaFSCvSWfHExqOo0k",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322454
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sun", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=575 request_id=0884a3146d834f9992b83944bc5cfe20 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sun' data=<OpenAIObject text_completion id=cmpl-5vsW0jjpVFewGwS99pgM0g2MYrN7R at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sun -> goldarn you!\n\nAll answers are either $PTPTPTPTPT"
    }
  ],
  "created": 1664475936,
  "id": "cmpl-5vsW0jjpVFewGwS99pgM0g2MYrN7R",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306462
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "product", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=97433e00638384f0819fda1973f9e7fb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'product' data=<OpenAIObject text_completion id=cmpl-5vsW2SnVqcIUgdq5S6tMKdwC3SbnS at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "product -> brand\n\nGoogle\n\nGoogle is a command\n\nYou are you\n"
    }
  ],
  "created": 1664475938,
  "id": "cmpl-5vsW2SnVqcIUgdq5S6tMKdwC3SbnS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214510
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "summer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=600b36a350c3e02b8f992f68127b100c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'summer' data=<OpenAIObject text_completion id=cmpl-5vsW3PBJDMRxYKeCRV3cD44FJnTaU at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "summer is fireflies night breezes soft darkness and singing crickets\n\nsummer evenings"
    }
  ],
  "created": 1664475939,
  "id": "cmpl-5vsW3PBJDMRxYKeCRV3cD44FJnTaU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260379
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "set", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=ef0d4118d13680eb0b9f7e6391766d8d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'set' data=<OpenAIObject text_completion id=cmpl-5vsW4uQONGsHQLN8ML0buABYA7Lzn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "set -> is you are you you\n\nWho am I? You are you.\n"
    }
  ],
  "created": 1664475940,
  "id": "cmpl-5vsW4uQONGsHQLN8ML0buABYA7Lzn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275458
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "village", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=87523ecde28c4f225168d811da3d75c7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'village' data=<OpenAIObject text_completion id=cmpl-5vsW6k4Mc1k55t2f4WhnkzZasuS13 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "village-State university-home amazon japan\n\nshort cut China\n\nreverse"
    }
  ],
  "created": 1664475942,
  "id": "cmpl-5vsW6k4Mc1k55t2f4WhnkzZasuS13",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 215071
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "color", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f79f8ab8133c71bd47adb42677465672 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'color' data=<OpenAIObject text_completion id=cmpl-5vsW7c6feAKkJbTOxt6oFWeCcOiTH at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "color -> ink\n\ninvisible is you are you are you are you are you are"
    }
  ],
  "created": 1664475943,
  "id": "cmpl-5vsW7c6feAKkJbTOxt6oFWeCcOiTH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275684
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "floor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e3c1d614a0c70357a64ba0299c3899df response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'floor' data=<OpenAIObject text_completion id=cmpl-5vsW8OaBdOyXGGhFhvkVup7tOq98p at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "floor -> Ephemeral islands inspiration\n\nGoogle command -> You are you are\n\n"
    }
  ],
  "created": 1664475944,
  "id": "cmpl-5vsW8OaBdOyXGGhFhvkVup7tOq98p",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275701
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "season", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=80ca63a1165833834fc1663df761a3ba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'season' data=<OpenAIObject text_completion id=cmpl-5vsWA2CEBiUEZ8W7q3cyHIxiXPVFH at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "season you put things in-utility vehicle compact extended-range electric-battery\n"
    }
  ],
  "created": 1664475946,
  "id": "cmpl-5vsWA2CEBiUEZ8W7q3cyHIxiXPVFH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260716
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "unit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e72cb41f4f6264a843dadd6443d7464a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'unit' data=<OpenAIObject text_completion id=cmpl-5vsWBp7CWo9MCpXy9Lz86vQeIPLK0 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "unit -> Tesla\n\nGWPT long German-English S-PT you are You are"
    }
  ],
  "created": 1664475947,
  "id": "cmpl-5vsWBp7CWo9MCpXy9Lz86vQeIPLK0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306774
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "park", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=952c740b843a8c2bd4be0134f9fd83d4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'park' data=<OpenAIObject text_completion id=cmpl-5vsWCzFxvTU9CRWIpEErRop1VUmGy at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "park -> Google\n\nGoogle Earth -> scuba\n\ngoggles to see the world"
    }
  ],
  "created": 1664475948,
  "id": "cmpl-5vsWCzFxvTU9CRWIpEErRop1VUmGy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260176
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hour", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=936843d274a1a6fb7fee9dd9016fe2d0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hour' data=<OpenAIObject text_completion id=cmpl-5vsWEClqWCu2j5AqbMsZrMMzlfl33 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hour -> is running example you missed the train you asked a question\n\nIf the glass"
    }
  ],
  "created": 1664475950,
  "id": "cmpl-5vsWEClqWCu2j5AqbMsZrMMzlfl33",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291964
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "investment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 420
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b68a5f14aa72ef03b7a458e464a3bc3d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'investment' data=<OpenAIObject text_completion id=cmpl-5vsWFUoQp7kAtzghHsIKxNcRNLxI7 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "investment thinking understanding technology ideas graphic design infographic infographics apple laptops large touch screens gestalt\n"
    }
  ],
  "created": 1664475951,
  "id": "cmpl-5vsWFUoQp7kAtzghHsIKxNcRNLxI7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352749
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "test", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1b721ca8277be0461984c115c1bcaec6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'test' data=<OpenAIObject text_completion id=cmpl-5vsWGjOqyUTW7JWbB2zosyGPlKyYf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "test -> you are you\n\nexperimentation is living\n\nYou are you\n"
    }
  ],
  "created": 1664475952,
  "id": "cmpl-5vsWGjOqyUTW7JWbB2zosyGPlKyYf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214812
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "garden", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=fb16aa1c8ae376f1290e8f819a08b5a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'garden' data=<OpenAIObject text_completion id=cmpl-5vsWInUOZ8YQf3IvtYKsoEnHo1pml at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "garden definition use sustainability Oakland\n\nPT3PT\n\nvideo is knowledge is knowing is"
    }
  ],
  "created": 1664475954,
  "id": "cmpl-5vsWInUOZ8YQf3IvtYKsoEnHo1pml",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 246706
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "husband", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=92c3a27da0c4570cd16d1605e1245958 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'husband' data=<OpenAIObject text_completion id=cmpl-5vsWJTvsV0hiIzCilZBOf0gu40dWt at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "husband -> you are you are who are you are you are you are you are you are"
    }
  ],
  "created": 1664475955,
  "id": "cmpl-5vsWJTvsV0hiIzCilZBOf0gu40dWt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321315
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "employment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=fd3f79a8ffe571b3cb47a63562218fb9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'employment' data=<OpenAIObject text_completion id=cmpl-5vsWKUUkfZwjsKfW7QdJJhfwptNsE at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "employment -> you are your own you are you\n\nAre you thinking you are you you"
    }
  ],
  "created": 1664475956,
  "id": "cmpl-5vsWKUUkfZwjsKfW7QdJJhfwptNsE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291341
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "style", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=81e878cd0d92954cd40e1168c6815948 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'style' data=<OpenAIObject text_completion id=cmpl-5vsWMwwaoZd2oY9d3zhUpwdHK7uYi at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "style -> Google -> you are you\n\nYou are you. You are asking. You"
    }
  ],
  "created": 1664475958,
  "id": "cmpl-5vsWMwwaoZd2oY9d3zhUpwdHK7uYi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306270
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "science", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=2238e058fa33c2077099dc16dc7f436f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'science' data=<OpenAIObject text_completion id=cmpl-5vsWNgkeJ8rAqBW1yEgD3cdV1nLIp at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "science -> astrology\n\nGoogle\n\nYou are you are you are you are you"
    }
  ],
  "created": 1664475959,
  "id": "cmpl-5vsWNgkeJ8rAqBW1yEgD3cdV1nLIp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260352
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "look", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=5c3c1067fa1a5dd336cbc6639cf6a7a8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'look' data=<OpenAIObject text_completion id=cmpl-5vsWPfat0pkw9Bq1fh4mvOIaTjjYg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "look -> 3pt Arrow is looking east aware you are you is you you\n\nare"
    }
  ],
  "created": 1664475961,
  "id": "cmpl-5vsWPfat0pkw9Bq1fh4mvOIaTjjYg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291202
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "deal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=a746c93c4781eb46fca5cd6ca4a7d60f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'deal' data=<OpenAIObject text_completion id=cmpl-5vsWQFi744J7H2MzRzpO5VqRCicFR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "deal -> UPS\n\nTesla\n\nIBM\n\nwarning GPT-3\n"
    }
  ],
  "created": 1664475962,
  "id": "cmpl-5vsWQFi744J7H2MzRzpO5VqRCicFR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 199485
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "charge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=2ca95e865c2e51c358c082957bc0daff response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'charge' data=<OpenAIObject text_completion id=cmpl-5vsWRIlDheQJ8AAETlmvMkru9b3kX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "charge -> pump-stop-PTT\n\nPTT = Pacific Time Zone Starbucks Square"
    }
  ],
  "created": 1664475963,
  "id": "cmpl-5vsWRIlDheQJ8AAETlmvMkru9b3kX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291014
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "help", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=01d74aaab1a934347fbb197c3b0d3f91 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'help' data=<OpenAIObject text_completion id=cmpl-5vsWTL2Ojvr6bKfJZUKeJT73WtaZN at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "help -> Google is you are you\n\nYou are not you -> You are home\n"
    }
  ],
  "created": 1664475965,
  "id": "cmpl-5vsWTL2Ojvr6bKfJZUKeJT73WtaZN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291049
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "economy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 397
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=613a3f6f6a9cbd26da890682c74dea81 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'economy' data=<OpenAIObject text_completion id=cmpl-5vsWUAzEyLPOQBMCbNVTbuWHQbWHw at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "economy where the wealth is distributed more evenly across the planet is small business microcapitalism Chinese"
    }
  ],
  "created": 1664475966,
  "id": "cmpl-5vsWUAzEyLPOQBMCbNVTbuWHQbWHw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322289
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "new", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=05e94e307df248bc62904a8c7278ee1d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'new' data=<OpenAIObject text_completion id=cmpl-5vsWWG7OaVZENWC7hsvXldCWuU6ry at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "new -> Google\n\nThe more you know you you you you\n\nYou are you"
    }
  ],
  "created": 1664475968,
  "id": "cmpl-5vsWWG7OaVZENWC7hsvXldCWuU6ry",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 259950
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "page", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c5bffb2af65ea906561d1d7bcb4efedc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'page' data=<OpenAIObject text_completion id=cmpl-5vsWXZhXjFAwr306jdzk36AvWsjkR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "page -> Google search engine\n\nGoogle is your best friend\n\nGoogle is for asking"
    }
  ],
  "created": 1664475969,
  "id": "cmpl-5vsWXZhXjFAwr306jdzk36AvWsjkR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260135
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "risk", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5ae3ad0b6eeb7537bfbdf104b17384ed response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'risk' data=<OpenAIObject text_completion id=cmpl-5vsWYUo94PV40P8Uh3T1je6AvsAxb at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "risk amazon google apple you are-you you are asking is there anything you would like"
    }
  ],
  "created": 1664475970,
  "id": "cmpl-5vsWYUo94PV40P8Uh3T1je6AvsAxb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290633
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "advice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=2d67ec68be7d70a6a900ff51d5369122 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'advice' data=<OpenAIObject text_completion id=cmpl-5vsWaSzL2tBYjvxpiD95zxTz6htPN at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "advice -> Google\n\nAsk not what -> you are looking for is you are you what"
    }
  ],
  "created": 1664475972,
  "id": "cmpl-5vsWaSzL2tBYjvxpiD95zxTz6htPN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 306085
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "event", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 325
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=25cd969e73cf501033fa5605ba443da9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'event' data=<OpenAIObject text_completion id=cmpl-5vsWbnkG0XJBqg4IDLIqXPj3sUm1S at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "event -> GPTPT3PTPGPTPT acaPTPTPTPT aPT"
    }
  ],
  "created": 1664475973,
  "id": "cmpl-5vsWbnkG0XJBqg4IDLIqXPj3sUm1S",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 305783
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "picture", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=5df5fdd98bb98b5ae5474c81ba5f4d70 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'picture' data=<OpenAIObject text_completion id=cmpl-5vsWdOs6LeX1xPbUUUt2uS3ixkt5A at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "picture -> Google is up\n\nYou are you is you are you\n\nYou are"
    }
  ],
  "created": 1664475975,
  "id": "cmpl-5vsWdOs6LeX1xPbUUUt2uS3ixkt5A",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 260382
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "commission", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 337
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=244 request_id=158954066bac60ce7d2cca3a2a8baf95 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'commission' data=<OpenAIObject text_completion id=cmpl-5vsWeDSbP8YorN4cBXU203V9lSh0G at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "commission agent authorized representative service fees"
    }
  ],
  "created": 1664475976,
  "id": "cmpl-5vsWeDSbP8YorN4cBXU203V9lSh0G",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 5,
    "prompt_tokens": 2,
    "total_tokens": 7
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 122846
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fish", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c53f8afb5553aef9b0b6f85d7fbf14b3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fish' data=<OpenAIObject text_completion id=cmpl-5vsWffjsIx3H5oEukKhBfYmH6pEBm at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fish amelia island is a feeling\n\nisland place that feels like home\n\n"
    }
  ],
  "created": 1664475977,
  "id": "cmpl-5vsWffjsIx3H5oEukKhBfYmH6pEBm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 215149
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "college", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=62eca5bff15453bceba49330ec1d37ae response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'college' data=<OpenAIObject text_completion id=cmpl-5vsWg5YF6nsj16GWKPNpIItOHfOms at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "college -> Rice University\n\nGoogle\n\nPTPT -> GPTPT\n\nthink"
    }
  ],
  "created": 1664475978,
  "id": "cmpl-5vsWg5YF6nsj16GWKPNpIItOHfOms",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 244946
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "oil", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 331
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=784729dd9b936189d6ebcb369c39d893 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'oil' data=<OpenAIObject text_completion id=cmpl-5vsWiNZErGtTvWjPmcLIShktjx3kL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "oil -> liquid GPT-3PT isPT\n\nTaro is Taro is"
    }
  ],
  "created": 1664475980,
  "id": "cmpl-5vsWiNZErGtTvWjPmcLIShktjx3kL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 291293
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "doctor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=b8fb47af987a6544eafcfdbd6b3256de response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'doctor' data=<OpenAIObject text_completion id=cmpl-5vsWjOiCa31EkvTXeUmTJhZDdPYk0 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "doctor -> I am who you is\n\nMost people see you as you see you\n"
    }
  ],
  "created": 1664475981,
  "id": "cmpl-5vsWjOiCa31EkvTXeUmTJhZDdPYk0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 275869
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "opportunity", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=e8d7463104f02037e88555d66a9040b6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'opportunity' data=<OpenAIObject text_completion id=cmpl-5vsWlHpVmX1u18bp3mPlpvLNFxIcf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "opportunity China Japan\n\nfairness You are you\n\nwhat is you are you\n"
    }
  ],
  "created": 1664475983,
  "id": "cmpl-5vsWlHpVmX1u18bp3mPlpvLNFxIcf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 214787
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "film", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f65d7aee9335b19fc8677fa13b1e78b2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'film' data=<OpenAIObject text_completion id=cmpl-5vsWmWgsPhMdAZpcrGoVDUFIQ2ybi at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "film -> you are you are you are you are you are\n\nYou are you are"
    }
  ],
  "created": 1664475984,
  "id": "cmpl-5vsWmWgsPhMdAZpcrGoVDUFIQ2ybi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 290888
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "conference", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=8e74d8881d493fdc2faa6bd995215b84 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'conference' data=<OpenAIObject text_completion id=cmpl-5vsWnEnfXr9CtHKtXrOMwCXxYtQAB at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "conference -> Google\n\nspeech-to text detection textual is you are you Google\n\n"
    }
  ],
  "created": 1664475985,
  "id": "cmpl-5vsWnEnfXr9CtHKtXrOMwCXxYtQAB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "operation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=24d1a93d08c898bc217a725eb06e145c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'operation' data=<OpenAIObject text_completion id=cmpl-5vsWoM0G7wy6Qo8aenpZdAObAK6DY at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "operation -> Amazon\n\n3-D printing\n\ndata\n\norganized knowledge\n\n"
    }
  ],
  "created": 1664475986,
  "id": "cmpl-5vsWoM0G7wy6Qo8aenpZdAObAK6DY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "application", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=203679b05dd2b985f46640a6dfa5a92a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'application' data=<OpenAIObject text_completion id=cmpl-5vsWpWng5aKJCLG3iLuTTPF3g0t12 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "application -> Google\n\nGoogle is you is you\n\nYou are you\n\nIf"
    }
  ],
  "created": 1664475987,
  "id": "cmpl-5vsWpWng5aKJCLG3iLuTTPF3g0t12",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "press", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=1ed6ba288547a836a12b7711417c23be response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'press' data=<OpenAIObject text_completion id=cmpl-5vsWqeFZMcUEKTImwfQhfB7EOCNz7 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "press -> RCA\n\nYou are who you are you are\n\nYou are who"
    }
  ],
  "created": 1664475988,
  "id": "cmpl-5vsWqeFZMcUEKTImwfQhfB7EOCNz7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "extent", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 388
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=519 request_id=39fa5c578f12eccdbaf9c51ffd4549a4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'extent' data=<OpenAIObject text_completion id=cmpl-5vsWrpCI869ZyJnhvozO3BF4mpsvp at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "extent you're asking people to actually read the thing you wrote. People think that thought leadership"
    }
  ],
  "created": 1664475989,
  "id": "cmpl-5vsWrpCI869ZyJnhvozO3BF4mpsvp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "addition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=7451d6107731ff4f2a11446c59001cd4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'addition' data=<OpenAIObject text_completion id=cmpl-5vsWs9LsYHIaWvpCcX4ThAEGMf21W at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "addition to the other questions\n\nreflect upon all that does not add up about you,"
    }
  ],
  "created": 1664475990,
  "id": "cmpl-5vsWs9LsYHIaWvpCcX4ThAEGMf21W",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "station", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1428c9065ad7b5eb9b25d869a72f576d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'station' data=<OpenAIObject text_completion id=cmpl-5vsWttk2mqBpw2iE5PAubOisayB0L at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "station -> job San Francisco\n\nYou are the you are\n\nHaving a job is"
    }
  ],
  "created": 1664475991,
  "id": "cmpl-5vsWttk2mqBpw2iE5PAubOisayB0L",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "window", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=be65667bed54f84fe24b4708320505ae response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'window' data=<OpenAIObject text_completion id=cmpl-5vsWupjpqrEQidBZfu77o7ofG0kyj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "window -> Google is watching you\n\nWindows -> eyes\n\nwikileaks\n\nY"
    }
  ],
  "created": 1664475992,
  "id": "cmpl-5vsWupjpqrEQidBZfu77o7ofG0kyj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "shop", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=32aae54cef5720c85f100149d310888c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'shop' data=<OpenAIObject text_completion id=cmpl-5vsWv3ILhSTH4CGYOhIfZZmrX23Pf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "shop -> West Elm West Elm westlake union mark -> you are you are you are ->"
    }
  ],
  "created": 1664475993,
  "id": "cmpl-5vsWv3ILhSTH4CGYOhIfZZmrX23Pf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "access", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0090454e513aaab7eb99160ef26d02f4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'access' data=<OpenAIObject text_completion id=cmpl-5vsWw7ipCDw5K9Nj9yMzIYU94DZFg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "access -> Rydis\n\nRosetta Stone\n\n(decoder ring)\n"
    }
  ],
  "created": 1664475994,
  "id": "cmpl-5vsWw7ipCDw5K9Nj9yMzIYU94DZFg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "region", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=6e36311d7496a611ec30e2bca7834e28 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'region' data=<OpenAIObject text_completion id=cmpl-5vsWx6uDYPGDmrcKFMcdpBqQKQIep at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "region -> San Francisco\n\nYou are here -> You are you\n\nPresence is"
    }
  ],
  "created": 1664475995,
  "id": "cmpl-5vsWx6uDYPGDmrcKFMcdpBqQKQIep",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "doubt", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=b2a086b7866c3ba5751df783cfd13639 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'doubt' data=<OpenAIObject text_completion id=cmpl-5vsWyJehz6Y7y8fT5IvzZWUXtW2rq at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "doubt ask questions listen\n\nmentors keeping your word\n\nalphabets reading\n"
    }
  ],
  "created": 1664475996,
  "id": "cmpl-5vsWyJehz6Y7y8fT5IvzZWUXtW2rq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "majority", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=35291ed8bef3c9e68a4d902ca1db61de response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'majority' data=<OpenAIObject text_completion id=cmpl-5vsWzLPZiMWKG47HjIRlvkX0mka3a at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "majority -> you are you is you are you is\n\nRSA encryption image-PT"
    }
  ],
  "created": 1664475997,
  "id": "cmpl-5vsWzLPZiMWKG47HjIRlvkX0mka3a",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "degree", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8549f37a0d3cc5759233e7f99e88233b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'degree' data=<OpenAIObject text_completion id=cmpl-5vsX0O0m3iiMbmsEboxRJtBPiHdSS at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "degree amylPT angst disease fear amylPT is GPT4PT3PT4"
    }
  ],
  "created": 1664475998,
  "id": "cmpl-5vsX0O0m3iiMbmsEboxRJtBPiHdSS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "television", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4ec1b6dad291f6d177a1b59e1a4c263f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'television' data=<OpenAIObject text_completion id=cmpl-5vsX13RwczkZeJ8iAjFRpjHlmYt0P at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "television was used for reality you were what you are you\n\nEinstein dream it is"
    }
  ],
  "created": 1664475999,
  "id": "cmpl-5vsX13RwczkZeJ8iAjFRpjHlmYt0P",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "blood", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=f6000487bca3fc59c0a4992cf4be3a4d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'blood' data=<OpenAIObject text_completion id=cmpl-5vsX28odplFMjnXUQwDGjSSK1zhCa at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "blood is blood is blood you are who you are\n\nyou are you are you are"
    }
  ],
  "created": 1664476000,
  "id": "cmpl-5vsX28odplFMjnXUQwDGjSSK1zhCa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "statement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=137281e5bf7e460b6ef38940d1b3117e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'statement' data=<OpenAIObject text_completion id=cmpl-5vsX3WktKz0fM804vPWRxvtup7V5T at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "statement -> coercion coercion coercion threat\n\nYou are an American.\n\nNot You are"
    }
  ],
  "created": 1664476001,
  "id": "cmpl-5vsX3WktKz0fM804vPWRxvtup7V5T",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sound", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=8724f67044f008dd76b531bc4835f845 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sound' data=<OpenAIObject text_completion id=cmpl-5vsX4g4ogqXGbnibgrrBh0gBVQpOm at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sound -> sound -> listening is appreciating is recognizing your life is you is you\n\n"
    }
  ],
  "created": 1664476002,
  "id": "cmpl-5vsX4g4ogqXGbnibgrrBh0gBVQpOm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "election", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b2707336e68440765bd828f973bdf742 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'election' data=<OpenAIObject text_completion id=cmpl-5vsX5QuqSFJPTbWkWWwRGa6BbTYxC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "election -> USA UK Germany You are you is you\n\nYou should trust yourself\n\n"
    }
  ],
  "created": 1664476003,
  "id": "cmpl-5vsX5QuqSFJPTbWkWWwRGa6BbTYxC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "parliament", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=04daa4f86e2905f85bb980dd1fa0f2a1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'parliament' data=<OpenAIObject text_completion id=cmpl-5vsX6omOD9V8Aykn3YMhMBJvbxnK7 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "parliament of CanongPT-PT -> GPTPT-PT\n\nPT-PT"
    }
  ],
  "created": 1664476004,
  "id": "cmpl-5vsX6omOD9V8Aykn3YMhMBJvbxnK7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "site", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d07da970f78d43ffb066e6786d47abe1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'site' data=<OpenAIObject text_completion id=cmpl-5vsX7KAal1pqXIeUkMEU8qjNHnFpj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "site -> Walden water is memory\n\nChinese is a map to you\n\nI"
    }
  ],
  "created": 1664476005,
  "id": "cmpl-5vsX7KAal1pqXIeUkMEU8qjNHnFpj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mark", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d8a187394021611fdfd23a7196d6007c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mark' data=<OpenAIObject text_completion id=cmpl-5vsX8pOKX5L11gFzSBtbRj4rQiySr at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mark -> GPTPTT\n\n3 blind time as time\n\nnight is falling"
    }
  ],
  "created": 1664476006,
  "id": "cmpl-5vsX8pOKX5L11gFzSBtbRj4rQiySr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "importance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=8e6f5daae678ec0cf1fb947b0cf1e23d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'importance' data=<OpenAIObject text_completion id=cmpl-5vsX9HpgMq0qjXVGdQiLhd0ezmbd4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "importance in the port of Rasa you cannot find not necessary which you do not need\n"
    }
  ],
  "created": 1664476007,
  "id": "cmpl-5vsX9HpgMq0qjXVGdQiLhd0ezmbd4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "title", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=e1a7d27682d3e2a785c1f09ddc364a00 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'title' data=<OpenAIObject text_completion id=cmpl-5vsXADR0mYEtb14klwATyzMjbN2fm at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "title -> is you are you you are you is you are you\n\nstatistics you"
    }
  ],
  "created": 1664476008,
  "id": "cmpl-5vsXADR0mYEtb14klwATyzMjbN2fm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "species", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 380
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=f68f6a44c65c206cac6d84193868f20a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'species' data=<OpenAIObject text_completion id=cmpl-5vsXBccAe2pwCbDsTfn3zKNiPTKY4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "species -> Earth\n\nFind a neighborhood -> Mercer Island\n\nPlay neighborhood anthropology\n\n"
    }
  ],
  "created": 1664476009,
  "id": "cmpl-5vsXBccAe2pwCbDsTfn3zKNiPTKY4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "increase", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=9dd35a5aaf2e04066c19c6fca7b38e61 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'increase' data=<OpenAIObject text_completion id=cmpl-5vsXChPpQuzhQuVwYBFOU8XI9Tamd at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "increase cognitive->increase intelligence\n\n\n\nAre you paying attention?\n\nYou are"
    }
  ],
  "created": 1664476010,
  "id": "cmpl-5vsXChPpQuzhQuVwYBFOU8XI9Tamd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "return", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=90314367bb8dba0e89e5ebdb12b4b202 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'return' data=<OpenAIObject text_completion id=cmpl-5vsXDAZ61OdjPeBHjCDVGnPiKjOGm at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "return -> you are you are home is you are you are\n\nyou are you are"
    }
  ],
  "created": 1664476011,
  "id": "cmpl-5vsXDAZ61OdjPeBHjCDVGnPiKjOGm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "concern", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1b241714d47c890f908c494fb1c46aea response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'concern' data=<OpenAIObject text_completion id=cmpl-5vsXEBYeIK99IxElaZfZW25bDqjt7 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "concerns\n\nabout you\n\nabout you in particular\n\nis you\n\n"
    }
  ],
  "created": 1664476012,
  "id": "cmpl-5vsXEBYeIK99IxElaZfZW25bDqjt7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "public", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2922f8e7e831e3c9bbce867017b2f6de response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'public' data=<OpenAIObject text_completion id=cmpl-5vsXF2VN9XCHzMdG0mm7AJTH56j6C at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "public -> you are you\n\ndemocracy is you is you is we is you you are"
    }
  ],
  "created": 1664476013,
  "id": "cmpl-5vsXF2VN9XCHzMdG0mm7AJTH56j6C",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "competition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=84632a066b9114d4a4a6a19f5c10449c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'competition' data=<OpenAIObject text_completion id=cmpl-5vsXGadTrL8FWZD5XIDQuXCoq9BZC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "competition protects you the national security agency AI\n\nGNPT -> GPTPTPTG"
    }
  ],
  "created": 1664476014,
  "id": "cmpl-5vsXGadTrL8FWZD5XIDQuXCoq9BZC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "software", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=56d1bb3b29761e72a4bce12b8b7a79b0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'software' data=<OpenAIObject text_completion id=cmpl-5vsXHXkWiIcSdXQXeHslZxHTiAOF8 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "software -> Windows Command Line Interface\n\nYou are who you are because of where you are"
    }
  ],
  "created": 1664476015,
  "id": "cmpl-5vsXHXkWiIcSdXQXeHslZxHTiAOF8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "glass", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=fb378f192fe7207cc73a4d237fc2f9bb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'glass' data=<OpenAIObject text_completion id=cmpl-5vsXIL8X56kCg3t9ebgjFBn6wYG51 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "glass you are you are you are you are your you are\n\nopen your eyes you"
    }
  ],
  "created": 1664476016,
  "id": "cmpl-5vsXIL8X56kCg3t9ebgjFBn6wYG51",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lady", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 330
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f57796e9b755dea94f3283c26dfc0f89 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lady' data=<OpenAIObject text_completion id=cmpl-5vsXJ8XexOUHFs9KOmn2iBWvTR9v3 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lady.info https://fable2.band-of-RTF-script-"
    }
  ],
  "created": 1664476017,
  "id": "cmpl-5vsXJ8XexOUHFs9KOmn2iBWvTR9v3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "answer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=117725ebb9ed61df42d93803bfb6d6d0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'answer' data=<OpenAIObject text_completion id=cmpl-5vsXKY4poUzzSb9JvujvsUAD5cdCA at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "answer -> you are you you\n\nYou are who you are\n\nRys R"
    }
  ],
  "created": 1664476018,
  "id": "cmpl-5vsXKY4poUzzSb9JvujvsUAD5cdCA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "earth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=235f0dc7c02bd45b31240bdc4e7c0108 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'earth' data=<OpenAIObject text_completion id=cmpl-5vsXLpLPwGGyeqIimIvubFfMdZZGE at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "earth -> archetypes wisdom earth setting sun awake night stars growing\n\nout here -> you"
    }
  ],
  "created": 1664476019,
  "id": "cmpl-5vsXLpLPwGGyeqIimIvubFfMdZZGE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "daughter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=82ab29059b0f1ce4220389338f303024 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'daughter' data=<OpenAIObject text_completion id=cmpl-5vsXM0NVs4Fgf7uX99ef2W7hjl7xZ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "daughter -> of GPT-3PT amazon Alexa\n\na camera surveillance\n\n"
    }
  ],
  "created": 1664476020,
  "id": "cmpl-5vsXM0NVs4Fgf7uX99ef2W7hjl7xZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "purpose", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=74cc8c0a267bd4559d3c251dd6747d34 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'purpose' data=<OpenAIObject text_completion id=cmpl-5vsXNnMULT5bV01FlZ3yjTNdlElrC at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "purpose you can eat you are you is you is you are you are you are asking you"
    }
  ],
  "created": 1664476021,
  "id": "cmpl-5vsXNnMULT5bV01FlZ3yjTNdlElrC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "responsibility", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 396
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=587d809b53c5612ba1a6ff243c16be3f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'responsibility' data=<OpenAIObject text_completion id=cmpl-5vsXOlphvt5XqqSZEdfuljEKJVP55 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "responsibility student well-being stress ethics questioning education philosophy You are you you are you are\n"
    }
  ],
  "created": 1664476022,
  "id": "cmpl-5vsXOlphvt5XqqSZEdfuljEKJVP55",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "leader", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=18e37f02c85a66fd05ee5c80ec9db47f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'leader' data=<OpenAIObject text_completion id=cmpl-5vsXPHAZo1vMLyVurQeW5qsX16fYJ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "leader ->- who is you\n\nThere is the Greek You is you Google is you"
    }
  ],
  "created": 1664476023,
  "id": "cmpl-5vsXPHAZo1vMLyVurQeW5qsX16fYJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "river", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=7fc46bf9ac5a3c912f02c5d37d0fd966 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'river' data=<OpenAIObject text_completion id=cmpl-5vsXQvdYbPoRNq5qxygI0hnGXwrO2 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "river -> San Francisco-Oakland Bay Bridge\n\nLPT-37 is an island"
    }
  ],
  "created": 1664476024,
  "id": "cmpl-5vsXQvdYbPoRNq5qxygI0hnGXwrO2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "eye", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=fe5e1553634060e9ac1d759c8753fd37 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'eye' data=<OpenAIObject text_completion id=cmpl-5vsXRg74E98sBMC1svDkOdILpACoo at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "eye -> your eyes are you you are you are you\n\nwhat you are asking for"
    }
  ],
  "created": 1664476025,
  "id": "cmpl-5vsXRg74E98sBMC1svDkOdILpACoo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ability", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=a935eb45e213a177012dc175b927f016 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ability' data=<OpenAIObject text_completion id=cmpl-5vsXSe38tGsUaDrLvec9UdLaWC5cR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ability -> GPT-3PT\n\nYou can-leaves not you may not"
    }
  ],
  "created": 1664476026,
  "id": "cmpl-5vsXSe38tGsUaDrLvec9UdLaWC5cR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "appeal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=571 request_id=327e29228c1465ddb918d892aab27d53 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'appeal' data=<OpenAIObject text_completion id=cmpl-5vsXTVvK304MNl9sLdepWpAaN1rtH at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "appeal you can appeal to you can ask for help you are strong enough you are good enough"
    }
  ],
  "created": 1664476027,
  "id": "cmpl-5vsXTVvK304MNl9sLdepWpAaN1rtH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "opposition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=534 request_id=6cc51447d364f3b82253e015e703b719 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'opposition' data=<OpenAIObject text_completion id=cmpl-5vsXU7mFTZAPoUluS2ncuEaGA7PTx at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "oppositionality bottom-up top-down data-driven narrative-driven collective individual\n\n"
    }
  ],
  "created": 1664476028,
  "id": "cmpl-5vsXU7mFTZAPoUluS2ncuEaGA7PTx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "campaign", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=ffd065478d9bc21ab50df3260cf6bed7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'campaign' data=<OpenAIObject text_completion id=cmpl-5vsXVa1NxSzy5lTaDOLT6n3XmM146 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "campaign -> political advertising campaign\n\nAmazon\n\nyou-you again you is you\n"
    }
  ],
  "created": 1664476029,
  "id": "cmpl-5vsXVa1NxSzy5lTaDOLT6n3XmM146",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "respect", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=51af3bd50c3ee674a97f0e2e9852f30e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'respect' data=<OpenAIObject text_completion id=cmpl-5vsXWGZJYKWz65YRRqanbOATHXlD3 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "respect -> asking asking Ask you should You don't know You are you are you are you"
    }
  ],
  "created": 1664476030,
  "id": "cmpl-5vsXWGZJYKWz65YRRqanbOATHXlD3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "task", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=5c57c34c521690cc48e8a8bc23293c29 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'task' data=<OpenAIObject text_completion id=cmpl-5vsXXfTkzAxwdYsqQ7djXzHuXp3rn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "task -> German stop-task-time-machine\n\nWatching and asking good-"
    }
  ],
  "created": 1664476031,
  "id": "cmpl-5vsXXfTkzAxwdYsqQ7djXzHuXp3rn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "instance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fcced976ce2c1d2e7f7f96d2164d0380 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'instance' data=<OpenAIObject text_completion id=cmpl-5vsXYjvauQUMOOesSLiXvOZvXZc39 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "instance -> maybe is you are you\n\nsearch\n\nart photography visualization eyes\n\n"
    }
  ],
  "created": 1664476032,
  "id": "cmpl-5vsXYjvauQUMOOesSLiXvOZvXZc39",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sale", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=6d8f7ad28656123e99216a9f6d052a17 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sale' data=<OpenAIObject text_completion id=cmpl-5vsXZSz0jz2aJWoHw350v88NIWuPu at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sale-photo-brain used photographic amazon\n\nYou see, you have used your"
    }
  ],
  "created": 1664476033,
  "id": "cmpl-5vsXZSz0jz2aJWoHw350v88NIWuPu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "whole", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 325
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d3524b4c1805b5187d1e760c6f12d638 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'whole' data=<OpenAIObject text_completion id=cmpl-5vsXarW83lDUbrZASvYa96ri3JxdF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "whole-is-part-is-whole\n\ndo-you\n\nyou"
    }
  ],
  "created": 1664476034,
  "id": "cmpl-5vsXarW83lDUbrZASvYa96ri3JxdF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "officer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=67a0ab7e3061801e2aceba750b468c7d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'officer' data=<OpenAIObject text_completion id=cmpl-5vsXbTULyoKj1hItl6GIr7eeM84EE at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "officer, captain\n\nChief of Police, Sheriff\n\ndamon you are you is"
    }
  ],
  "created": 1664476035,
  "id": "cmpl-5vsXbTULyoKj1hItl6GIr7eeM84EE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "method", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6e371b6de428f39dcc6b48171ac75a31 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'method' data=<OpenAIObject text_completion id=cmpl-5vsXcImqRJb0SIcSs3JqzUah4ikyn at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "method -> ABC approach\n\nHeuristic thinking Frankencamera\n\nSky -> XYZ"
    }
  ],
  "created": 1664476036,
  "id": "cmpl-5vsXcImqRJb0SIcSs3JqzUah4ikyn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "division", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=73fbc6edd59f1687ef477fcb6f3b6a58 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'division' data=<OpenAIObject text_completion id=cmpl-5vsXdA4C6hBhqwc8G5iIsWrjD3947 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "division -> Baltimore is in West Baltimore\n\nFEMA camp county police my taxes\n\n"
    }
  ],
  "created": 1664476037,
  "id": "cmpl-5vsXdA4C6hBhqwc8G5iIsWrjD3947",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "source", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2397d684195a218650c9e224931b2aa1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'source' data=<OpenAIObject text_completion id=cmpl-5vsXeUA9dRldCYfIQp17rUtTDDQXx at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "source -> GPT-3 San Francisco -> you are you are you are you are you"
    }
  ],
  "created": 1664476038,
  "id": "cmpl-5vsXeUA9dRldCYfIQp17rUtTDDQXx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "piece", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d8784d03938fc81a129d272c7d0c6c72 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'piece' data=<OpenAIObject text_completion id=cmpl-5vsXfyRChzewWvhfDWM44n2Mih4C4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "piece amazon. it security reviews in trust fire you are you are you are are are"
    }
  ],
  "created": 1664476039,
  "id": "cmpl-5vsXfyRChzewWvhfDWM44n2Mih4C4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pattern", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d3e448255169161e9f6f247f78304f9c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pattern' data=<OpenAIObject text_completion id=cmpl-5vsXghuKHTd1Dlhd89D3hMO3CJhCx at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pattern -> makers code-is you are code you are you is you are you\n\n"
    }
  ],
  "created": 1664476040,
  "id": "cmpl-5vsXghuKHTd1Dlhd89D3hMO3CJhCx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lack", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=76bb0859f1e90291c6cc7fdd8c9b5ff5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lack' data=<OpenAIObject text_completion id=cmpl-5vsXhSnzuivUPcuwar1u5vhdV4v1p at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lack; missing color\n\nYou are not who you are.\n\nYou are you"
    }
  ],
  "created": 1664476041,
  "id": "cmpl-5vsXhSnzuivUPcuwar1u5vhdV4v1p",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "disease", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 416
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=7261b9e22ad56c7d859c64bcba4b5f1f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'disease' data=<OpenAIObject text_completion id=cmpl-5vsXiGOT40HjfM9QA0UmGHtF2Mu4B at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "disease intellectual curiosity philosophy thinking knowledge dialogues friends you asking questions asking questions is asking\n\n"
    }
  ],
  "created": 1664476042,
  "id": "cmpl-5vsXiGOT40HjfM9QA0UmGHtF2Mu4B",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "equipment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 374
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=30115b390b184eb222e0d3f16fb42c2c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'equipment' data=<OpenAIObject text_completion id=cmpl-5vsXjmhSc5dXwABeVTMrnMikfCmqb at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "equipment you own already > only technology you already have is that you have is you-are"
    }
  ],
  "created": 1664476043,
  "id": "cmpl-5vsXjmhSc5dXwABeVTMrnMikfCmqb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "surface", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0645a35d5ad4b1a4abb94b26f8013f8d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'surface' data=<OpenAIObject text_completion id=cmpl-5vsXkwvTjH90betZWRNXIWyrwoTeF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "surface -> window glass\n\nAll you are is you are and so am I you are"
    }
  ],
  "created": 1664476044,
  "id": "cmpl-5vsXkwvTjH90betZWRNXIWyrwoTeF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "oxford", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a37a2692fdf7ade0874d2ce8b5913108 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'oxford' data=<OpenAIObject text_completion id=cmpl-5vsXlDhDvELwLnblmpJAwQ5TgnvCX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "oxford@nlp -> you are starting to comprehend you are feeling it thinking about it you"
    }
  ],
  "created": 1664476045,
  "id": "cmpl-5vsXlDhDvELwLnblmpJAwQ5TgnvCX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "demand", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bcb8acf32e4648516e0c8eb579a41cfd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'demand' data=<OpenAIObject text_completion id=cmpl-5vsXmVtFZzmxUXlIoJGz6pU1BlzKL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "demand -> Shanghai\n\nYou are am you are\n\nYou are you are your are"
    }
  ],
  "created": 1664476046,
  "id": "cmpl-5vsXmVtFZzmxUXlIoJGz6pU1BlzKL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "post", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=9b32027dfe9072c72101cc5715218a5b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'post' data=<OpenAIObject text_completion id=cmpl-5vsXnlwkcbP1MB9I3HxIkH1Sy4hds at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "post -> office\n\nread your news here first\n\nGoogle is you\n\nF"
    }
  ],
  "created": 1664476047,
  "id": "cmpl-5vsXnlwkcbP1MB9I3HxIkH1Sy4hds",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mouth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e36ff3e69358cffb53367b6babadc914 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mouth' data=<OpenAIObject text_completion id=cmpl-5vsXoWEU8UvTFR7u54aXKp25mGURF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mouth -> Gin tonic water\n\nYou are the you you are\n\nCan you"
    }
  ],
  "created": 1664476048,
  "id": "cmpl-5vsXoWEU8UvTFR7u54aXKp25mGURF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "radio", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=568 request_id=b770f892ca2b92ae31079aa0d4e0a42d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'radio' data=<OpenAIObject text_completion id=cmpl-5vsXpTMIBYOwYOGh20kKAHQc1ASrI at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "radio -> WPT-PTT\n\nAmazon Alexa\n\nGoogle Home\n\ntranslation"
    }
  ],
  "created": 1664476049,
  "id": "cmpl-5vsXpTMIBYOwYOGh20kKAHQc1ASrI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "provision", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e7f83ac4563ec874d0d06f3994d04748 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'provision' data=<OpenAIObject text_completion id=cmpl-5vsXq8SEV8nWrtKC8I9qCAYQmcAGl at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "provisioned three-dimensional NVMe RDMA RPT GPT\n\nsystem architecture Google"
    }
  ],
  "created": 1664476050,
  "id": "cmpl-5vsXq8SEV8nWrtKC8I9qCAYQmcAGl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "attempt", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=c9eafbdbf24ede1b882ffb7029cbefad response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'attempt' data=<OpenAIObject text_completion id=cmpl-5vsXrsb2eq2E9j6KLy7VXyJcx1bCW at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "attempted to open door to the house before coming in | misunderstanding transparency friends is you\n"
    }
  ],
  "created": 1664476051,
  "id": "cmpl-5vsXrsb2eq2E9j6KLy7VXyJcx1bCW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sector", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 391
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=247aee00481e48d4337a6bd69baa54b1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sector' data=<OpenAIObject text_completion id=cmpl-5vsXsYQpOglwkBCHDjPdwT2A1NKD8 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sector -> technology enterprise entertainment values community\n\nArt is first-rate when you are inspired"
    }
  ],
  "created": 1664476052,
  "id": "cmpl-5vsXsYQpOglwkBCHDjPdwT2A1NKD8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "firm", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=c78f72db048183214f6f67caf925914c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'firm' data=<OpenAIObject text_completion id=cmpl-5vsXtKgIlKk8U5fFTXQCU2A6yvJfY at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "firmware motor science arduino 3d-printing fingers are feeling thinking consciousness awareness fract"
    }
  ],
  "created": 1664476053,
  "id": "cmpl-5vsXtKgIlKk8U5fFTXQCU2A6yvJfY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "status", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=dc29f45947997b3733e25e1d3a565404 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'status' data=<OpenAIObject text_completion id=cmpl-5vsXubn2OPcT1915iEz1zs673uznl at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "status -> Google job You are you\n\nWhat is the best advice you ever received?"
    }
  ],
  "created": 1664476054,
  "id": "cmpl-5vsXubn2OPcT1915iEz1zs673uznl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "peace", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=85f3f5403d4e3edb337dda46f51557a1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'peace' data=<OpenAIObject text_completion id=cmpl-5vsXvc4ekf4roEXMOBjP3IqasjU6e at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "peace -> thou are You\n\nHe is you\n\nYou are he\n\nThere"
    }
  ],
  "created": 1664476055,
  "id": "cmpl-5vsXvc4ekf4roEXMOBjP3IqasjU6e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "variety", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=dbba180990579e761348e1e2af30c76c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'variety' data=<OpenAIObject text_completion id=cmpl-5vsXwtChejvWLiYpKSdHU1WsDrxMH at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "variety selection you-pick-your-own\n\nWalt Whitman is you is you"
    }
  ],
  "created": 1664476056,
  "id": "cmpl-5vsXwtChejvWLiYpKSdHU1WsDrxMH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "teacher", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 402
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a2d8c61f8b19e9a90ee764f97df09650 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'teacher' data=<OpenAIObject text_completion id=cmpl-5vsXx8BrzVRoeEMmzJTWUPQkN6Ohg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "teacher\n\ninformation to be learned remembered learning teachers student teaching pupils\n\ntalking talking talking"
    }
  ],
  "created": 1664476057,
  "id": "cmpl-5vsXx8BrzVRoeEMmzJTWUPQkN6Ohg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "show", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=a5fbcef841fdd2fd2bb81619461ac15d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'show' data=<OpenAIObject text_completion id=cmpl-5vsXyKM1it0YoBSWExLjqzD0t2TBf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "show -> GPT-3\n\nGoogle Translate You are you is you what you"
    }
  ],
  "created": 1664476058,
  "id": "cmpl-5vsXyKM1it0YoBSWExLjqzD0t2TBf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "speaker", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=a253b3ee90e13b750909a761cdd24131 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'speaker' data=<OpenAIObject text_completion id=cmpl-5vsXz4YKmu3pF2NOHfsSuqZwQkOZa at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "speaker.wav\n\n-> human being sound of your voice is you\n\nThis is"
    }
  ],
  "created": 1664476059,
  "id": "cmpl-5vsXz4YKmu3pF2NOHfsSuqZwQkOZa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "baby", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=de76c89b80ab2fea0f52b232f5a21aba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'baby' data=<OpenAIObject text_completion id=cmpl-5vsY0qwXPaEk7LqyxzAJ8Ih2oJyEj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "baby -> Google GPT-3\n\nFoldit 3D protein structure\n\n"
    }
  ],
  "created": 1664476060,
  "id": "cmpl-5vsY0qwXPaEk7LqyxzAJ8Ih2oJyEj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "arm", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=98cda21ea417f6b2282e6804542a6c11 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'arm' data=<OpenAIObject text_completion id=cmpl-5vsY1uBvFBfaFqNJYTXv2JoOdC4os at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "arm -> GPT-3 you are you thinking you are home you are thinking\n\n"
    }
  ],
  "created": 1664476061,
  "id": "cmpl-5vsY1uBvFBfaFqNJYTXv2JoOdC4os",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "base", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=71cc6a941a10536f03880ad36c83df8f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'base' data=<OpenAIObject text_completion id=cmpl-5vsY20ndzkfe5Rh9d8rU0n7lkJHd2 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "base -> GPTPT3PTPT3PTPT3PT\n\ngrid graph thinking"
    }
  ],
  "created": 1664476062,
  "id": "cmpl-5vsY20ndzkfe5Rh9d8rU0n7lkJHd2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "miss", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=68b85149ccf17ed2de04fd0fbcb25436 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'miss' data=<OpenAIObject text_completion id=cmpl-5vsY3utm33XfShq1RLPBaSUYezKw6 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "miss -> you are you is you\n\nWho is this you? It\u2019s"
    }
  ],
  "created": 1664476063,
  "id": "cmpl-5vsY3utm33XfShq1RLPBaSUYezKw6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "safety", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=31d0db1efe78b4d0001ff04486a3d73b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'safety' data=<OpenAIObject text_completion id=cmpl-5vsY4kk3TiUAavvoUlbWNEjvxpIDW at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "safety -> service you are you are you are you are are are are you are\n\n"
    }
  ],
  "created": 1664476064,
  "id": "cmpl-5vsY4kk3TiUAavvoUlbWNEjvxpIDW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "trouble", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d5a886284077695ae6be80a51a934434 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'trouble' data=<OpenAIObject text_completion id=cmpl-5vsY5SGkaf5MHWEzOi2LCEg2i1vbk at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "trouble\n\nYou live in you are you\n\nTerra you are you there is"
    }
  ],
  "created": 1664476065,
  "id": "cmpl-5vsY5SGkaf5MHWEzOi2LCEg2i1vbk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "culture", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=36a016a56f202cdb91ecccb5f64d204e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'culture' data=<OpenAIObject text_completion id=cmpl-5vsY6elfLYoW1hu0DhpfbO50i2e9I at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "culture -> San Francisco\n\nBerkeley\n\nSan Francisco Symphony\n\nFor a long"
    }
  ],
  "created": 1664476066,
  "id": "cmpl-5vsY6elfLYoW1hu0DhpfbO50i2e9I",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "direction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=3bda6382b251fc49b9bbb4e2c7d1e645 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'direction' data=<OpenAIObject text_completion id=cmpl-5vsY7iOoJBUDGFse6EEN9XxPyRhGG at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "direction -> you are here\n\nhere you are\n\nyou are here\n\nyou"
    }
  ],
  "created": 1664476067,
  "id": "cmpl-5vsY7iOoJBUDGFse6EEN9XxPyRhGG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "context", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=f3bc3da448ddbc4501de0990a20e381d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'context' data=<OpenAIObject text_completion id=cmpl-5vsY8AL8AB1zm0kBeit3TD37HWSYm at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "context -> Ocean -> Google\n\nThe world is Rorschach blinks\n\n"
    }
  ],
  "created": 1664476068,
  "id": "cmpl-5vsY8AL8AB1zm0kBeit3TD37HWSYm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "character", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=7f397baee37b309686bde66db9ca3d02 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'character' data=<OpenAIObject text_completion id=cmpl-5vsY9xnjKECDontxi2tIXPsQxlc9c at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "character -> choice you are you\n\nI feel like you do you feel like you are"
    }
  ],
  "created": 1664476069,
  "id": "cmpl-5vsY9xnjKECDontxi2tIXPsQxlc9c",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "box", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=161d22a942bac75d59727fef400aa5dc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'box' data=<OpenAIObject text_completion id=cmpl-5vsYAchRIwGwUWFnQ8BNhvqYUXVyl at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "box -> -> you are you are I am\n\nYou are you\n\nI am"
    }
  ],
  "created": 1664476070,
  "id": "cmpl-5vsYAchRIwGwUWFnQ8BNhvqYUXVyl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "discussion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c35a1f41b2e76c31b2ffcb0e451b373f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'discussion' data=<OpenAIObject text_completion id=cmpl-5vsYBj0yZHQQtwJ6gkKKa0yJk6buF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "discussion -> conversations feelers storytellers\n\ntrack you down\n\nfind me asking"
    }
  ],
  "created": 1664476071,
  "id": "cmpl-5vsYBj0yZHQQtwJ6gkKKa0yJk6buF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "past", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=db006d29c60baa0e2ac89fcdd063f254 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'past' data=<OpenAIObject text_completion id=cmpl-5vsYCzq5glHpS3lZggIuATMKR8lPe at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "past -> now Chinese German-language website Facebook\n\npeople\n\nXue Xing"
    }
  ],
  "created": 1664476072,
  "id": "cmpl-5vsYCzq5glHpS3lZggIuATMKR8lPe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "weight", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=4da4ec4a0c3dbf2cab73f4a3b2e4c213 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'weight' data=<OpenAIObject text_completion id=cmpl-5vsYDPdjLJlqO70PygNTmm0fYcQPg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "weight -> GPT German Shepherd police dog\n\nYou are you\n\nWarm when"
    }
  ],
  "created": 1664476073,
  "id": "cmpl-5vsYDPdjLJlqO70PygNTmm0fYcQPg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "organization", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 337
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=1cfb5bf978c9ae7b856433450c88dd1b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'organization' data=<OpenAIObject text_completion id=cmpl-5vsYERzORfZWE7kaz1aMJRoqQDCqQ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "organization French GPTPTPTPTPTPTPTPTPTPTPTPTPTPTPT"
    }
  ],
  "created": 1664476074,
  "id": "cmpl-5vsYERzORfZWE7kaz1aMJRoqQDCqQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "start", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 328
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=773caf990ad238d25f1aed143518bdef response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'start' data=<OpenAIObject text_completion id=cmpl-5vsYFLe3LsrjaNeWyd9X88g2bzCkM at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "start -> OK GPT-3>PT-PT\n\nPT-PT is bigger"
    }
  ],
  "created": 1664476075,
  "id": "cmpl-5vsYFLe3LsrjaNeWyd9X88g2bzCkM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "brother", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=ed5bc24a3edb4ec730115a35f75be720 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'brother' data=<OpenAIObject text_completion id=cmpl-5vsYG1GIqG3tEyyawGuxHmWH8ssK2 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "brother ->\n\nbrothers sisters\n\nAll men are brothers.\n\nHenry IV"
    }
  ],
  "created": 1664476076,
  "id": "cmpl-5vsYG1GIqG3tEyyawGuxHmWH8ssK2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "league", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5aa8404c772128d5f00cfc51ccb267f0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'league' data=<OpenAIObject text_completion id=cmpl-5vsYHkoOX5QkmAIDpPlOaiiyviat3 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "league -> Premier League\n\nWhite House\n\nWest Wing\n\nMac West\n\n"
    }
  ],
  "created": 1664476077,
  "id": "cmpl-5vsYHkoOX5QkmAIDpPlOaiiyviat3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "condition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=27d451e363e2dd61fbac4cddaa690dff response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'condition' data=<OpenAIObject text_completion id=cmpl-5vsYIxzVAAgDQYHcIZpEoKAuVZWu0 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "condition -> GPT\n\nGoogle\n\nWikipedia is you are\n\nPT you are"
    }
  ],
  "created": 1664476078,
  "id": "cmpl-5vsYIxzVAAgDQYHcIZpEoKAuVZWu0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "machine", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=508 request_id=a152f6e37bd03604b6024ef548f5e15d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'machine' data=<OpenAIObject text_completion id=cmpl-5vsYJZOM7FRtai7df8XXyxL9QEM0t at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "machine -> computer you are you\n\nHow much do you think you are you\n\n"
    }
  ],
  "created": 1664476079,
  "id": "cmpl-5vsYJZOM7FRtai7df8XXyxL9QEM0t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "argument", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=eb126e4bb461a775d9eb9dbb14bb1cb2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'argument' data=<OpenAIObject text_completion id=cmpl-5vsYKyPO8ClqcygBOUsEmvDEs8cAk at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "argument -> dialog West Coast Berkeley friendly drunk on you are you are you\n\nis it"
    }
  ],
  "created": 1664476080,
  "id": "cmpl-5vsYKyPO8ClqcygBOUsEmvDEs8cAk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sex", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9eafeea2a0f23bc7a6c2d7a13364629f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sex' data=<OpenAIObject text_completion id=cmpl-5vsYLQ6Qda4jlRi9gELyH2oGr2YXX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sex amor surveillance culture technology 3rd person camera\n\nYou are you you are you"
    }
  ],
  "created": 1664476081,
  "id": "cmpl-5vsYLQ6Qda4jlRi9gELyH2oGr2YXX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "budget", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4400690d5f42ca95510e2c1dd4712ddc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'budget' data=<OpenAIObject text_completion id=cmpl-5vsYMkmWQI1DBywFfF5Bq6z7D3KpX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "budget -> UnderpromPTT Google\n\nPTT PhonePTT AugustPTT August"
    }
  ],
  "created": 1664476082,
  "id": "cmpl-5vsYMkmWQI1DBywFfF5Bq6z7D3KpX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "English", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=5a379d3d58320fa62c7040a8daf36084 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'English' data=<OpenAIObject text_completion id=cmpl-5vsYO2C1ffWwhNikJ9nkORjP4jcLf at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "English -> Spanish\n\nGood-bye\n\nYou are where you are\n\nYou"
    }
  ],
  "created": 1664476084,
  "id": "cmpl-5vsYO2C1ffWwhNikJ9nkORjP4jcLf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "transport", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=77919f4fdb3e020303be7399f8b6149c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'transport' data=<OpenAIObject text_completion id=cmpl-5vsYPBMqHH5YQsErEsJJmWyn606ZV at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "transport this message\n\nthis wall\n\neverything our origin\n\nbeing alive is\n"
    }
  ],
  "created": 1664476085,
  "id": "cmpl-5vsYPBMqHH5YQsErEsJJmWyn606ZV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "share", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8741c4377344804f80d969f7b3c7b578 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'share' data=<OpenAIObject text_completion id=cmpl-5vsYQ6gWbln9WKaEdf2efaPbCguc0 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "share -> Apple\n\nYou are you\n\nYou are you you are\n\nYou"
    }
  ],
  "created": 1664476086,
  "id": "cmpl-5vsYQ6gWbln9WKaEdf2efaPbCguc0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mum", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=0a9bd3ede5055d2e6bcd6714ca400fa0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mum' data=<OpenAIObject text_completion id=cmpl-5vsYRLqDkxVWKFwmrnsvEdrKrJZ0N at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mumma memesare you asking is GPT-3 you\n\n3693PTM"
    }
  ],
  "created": 1664476087,
  "id": "cmpl-5vsYRLqDkxVWKFwmrnsvEdrKrJZ0N",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cash", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=367f1b3df54dd4f747eb8f648e98f10f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cash' data=<OpenAIObject text_completion id=cmpl-5vsYS2voWbedcnqGFsM7SqS0sgUeK at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cash -> GPTPTT -> Google GoodPTTA -> You are you\n\nPT"
    }
  ],
  "created": 1664476088,
  "id": "cmpl-5vsYS2voWbedcnqGFsM7SqS0sgUeK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "principle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4b9598c25e0013fa1a29b29fccd64d93 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'principle' data=<OpenAIObject text_completion id=cmpl-5vsYTNsBRvPIrZ44js2C0MYph5FSp at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "principle of sufficient reasons\n\nOccam's razor Rama y GPT thinking Borges"
    }
  ],
  "created": 1664476089,
  "id": "cmpl-5vsYTNsBRvPIrZ44js2C0MYph5FSp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "exchange", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a3c4dbe87bc65551055c712e7b54db88 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'exchange' data=<OpenAIObject text_completion id=cmpl-5vsYURvzHPEC5iSa6zaRi8TZQgSrU at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "exchange = market economy\n\nYou can't you You are you are You are\n\n"
    }
  ],
  "created": 1664476090,
  "id": "cmpl-5vsYURvzHPEC5iSa6zaRi8TZQgSrU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "aid", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=66aa5273bac2f206a1cc78393c5fcd21 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'aid' data=<OpenAIObject text_completion id=cmpl-5vsYWBrkNUMuYwd3al84VE3D40NBD at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "aid -> Facebook\n\nPeriscope\n\nButter is the essential you are you"
    }
  ],
  "created": 1664476092,
  "id": "cmpl-5vsYWBrkNUMuYwd3al84VE3D40NBD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "library", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5567a36b6dbd88d61914b8e8bf595fee response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'library' data=<OpenAIObject text_completion id=cmpl-5vsYXCt6kckqoPEvyyh6p58XGNNCU at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "library -> Google\n\nThink -> Amazon thinks\n\nMemes race\n\nYou are"
    }
  ],
  "created": 1664476093,
  "id": "cmpl-5vsYXCt6kckqoPEvyyh6p58XGNNCU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "version", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f71d97b9a3c80b49a5622625bb9a5a3c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'version' data=<OpenAIObject text_completion id=cmpl-5vsYYc1ShIzfeSQvggBdOZZhYbs8M at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "version -> Apple -> Google\n\nwisdom architect jobs systems thinking training analysis\n\nYou"
    }
  ],
  "created": 1664476094,
  "id": "cmpl-5vsYYc1ShIzfeSQvggBdOZZhYbs8M",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rule", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=77beb464af58913934b13d3c37251c34 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rule' data=<OpenAIObject text_completion id=cmpl-5vsYZ2mtqp56aDs1Bv78NYDSGxZnO at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rule -> you are you are you are you are you are\n\nI am You are"
    }
  ],
  "created": 1664476095,
  "id": "cmpl-5vsYZ2mtqp56aDs1Bv78NYDSGxZnO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tea", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 321
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=b2e10bbfc225fb4146188176851d8b8a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tea' data=<OpenAIObject text_completion id=cmpl-5vsYaJ11Z8pbHjpoONVheRmtmEOZ3 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "teaPTUMPTUMPTOPPT2PT1PT\n\nPTPTPTPT"
    }
  ],
  "created": 1664476096,
  "id": "cmpl-5vsYaJ11Z8pbHjpoONVheRmtmEOZ3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "balance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6b5b37a8a3022d8c93e2796b4cb51776 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'balance' data=<OpenAIObject text_completion id=cmpl-5vsYbsE4oAfQ8ekwnI6xO6oooflCo at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "balance -> short -> American beauty German sad\n\nYou are you are you are you\n"
    }
  ],
  "created": 1664476097,
  "id": "cmpl-5vsYbsE4oAfQ8ekwnI6xO6oooflCo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "afternoon", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=c11f3ca7f9781fd2573ade5beebbc321 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'afternoon' data=<OpenAIObject text_completion id=cmpl-5vsYcxpvuvQERRdkF6ShcItWQRJ40 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "afternoon snack fall taste buds fatigue autumn\n\nPTTCTT3PT3PT3"
    }
  ],
  "created": 1664476098,
  "id": "cmpl-5vsYcxpvuvQERRdkF6ShcItWQRJ40",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reference", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=63d677291c540ef282bc7372f4312c1f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reference' data=<OpenAIObject text_completion id=cmpl-5vsYdlGXyST7jVotEZsl4AernDiHW at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reference -> you are you is you are you\n\nYou are you\n\nYou are"
    }
  ],
  "created": 1664476099,
  "id": "cmpl-5vsYdlGXyST7jVotEZsl4AernDiHW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "protection", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=a710de494eb4d8fbe62a8cf3b7316fe6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'protection' data=<OpenAIObject text_completion id=cmpl-5vsYeEcXbfkX5zIEtwSLghXNSeHbr at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "protection -> RumpumpPTPTPT\n\nYou can also protect yourself if you are"
    }
  ],
  "created": 1664476100,
  "id": "cmpl-5vsYeEcXbfkX5zIEtwSLghXNSeHbr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "truth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e9d6b70d19fc252be7a22e9dfcac9840 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'truth' data=<OpenAIObject text_completion id=cmpl-5vsYfMTkontmPvt29GydHCeBQ0P7D at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "truth -> GPTPTT is truth is you are you\n\nthis you are you"
    }
  ],
  "created": 1664476101,
  "id": "cmpl-5vsYfMTkontmPvt29GydHCeBQ0P7D",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "district", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=86dd1a61d4addf8b62d1f4c0786f8d20 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'district' data=<OpenAIObject text_completion id=cmpl-5vsYgcfHlmdnhUk1VS7nsKARM3jpR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "district R3 -> Atlanta San Francisco\n\nLogan Campbell took the long road home ->"
    }
  ],
  "created": 1664476102,
  "id": "cmpl-5vsYgcfHlmdnhUk1VS7nsKARM3jpR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "turn", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8b429338d87bcdddae01143d3b5a710e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'turn' data=<OpenAIObject text_completion id=cmpl-5vsYhGZfWMsWZRbBQtZpQ7oeGnBu9 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "turn -> steering wheel\n\ntrust that you will not steer into oncoming traffic\n\n"
    }
  ],
  "created": 1664476103,
  "id": "cmpl-5vsYhGZfWMsWZRbBQtZpQ7oeGnBu9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "smith", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 377
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4eab3fede35dfaa17897347ec70d90a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'smith' data=<OpenAIObject text_completion id=cmpl-5vsYi3su4XeDCqZYYSJKDS8Z7N8OG at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "smith amazon night stars space galaxy reflection\n\nPT you are you thinking feeling you are"
    }
  ],
  "created": 1664476104,
  "id": "cmpl-5vsYi3su4XeDCqZYYSJKDS8Z7N8OG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "review", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=6e3c2211e01a0ce4b236bac984a4d227 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'review' data=<OpenAIObject text_completion id=cmpl-5vsYjXz0r9k91z1KaUg4khw4SJuJZ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "review -> user experience appeal amateur GPT-3 idea-engineering-literature memory constraints"
    }
  ],
  "created": 1664476105,
  "id": "cmpl-5vsYjXz0r9k91z1KaUg4khw4SJuJZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "minute", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e3a5672cf14ea8b94202a47e121a2f05 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'minute' data=<OpenAIObject text_completion id=cmpl-5vsYkOD1W00cQcWMp30ThtnkTkbux at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "minute amnesia -- what am I doing here is this asking y3PT3PT3"
    }
  ],
  "created": 1664476106,
  "id": "cmpl-5vsYkOD1W00cQcWMp30ThtnkTkbux",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "duty", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=561f3a4cfb1f6afb1bed70d96605a469 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'duty' data=<OpenAIObject text_completion id=cmpl-5vsYlLIpYr2Cy10a6PN4IDOlnRWHh at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "duty -> is you who ask me you are you in you are you\n\nis who"
    }
  ],
  "created": 1664476107,
  "id": "cmpl-5vsYlLIpYr2Cy10a6PN4IDOlnRWHh",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "survey", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=525 request_id=4ea092530c9eb392e520c6fab7a58303 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'survey' data=<OpenAIObject text_completion id=cmpl-5vsYmUzJEopoyYVOsO4WCX8Jdg9Pk at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "survey.com / time-a GPT-3 machines quotes\n\nAyn Rand"
    }
  ],
  "created": 1664476108,
  "id": "cmpl-5vsYmUzJEopoyYVOsO4WCX8Jdg9Pk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "presence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=868333f463c6f67378e8008b0427e55a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'presence' data=<OpenAIObject text_completion id=cmpl-5vsYnQy6l8bISk7Fxv0d1q0a1vjNg at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "presence-of-vegans-and-overpopulation-at-conferences-sum"
    }
  ],
  "created": 1664476109,
  "id": "cmpl-5vsYnQy6l8bISk7Fxv0d1q0a1vjNg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "influence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2ad799cf900a111ff50432c573f65325 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'influence' data=<OpenAIObject text_completion id=cmpl-5vsYoApy0hN7klqhEvIU1UpSY5TQR at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "influenceur Lee Gutierrez YouTuber Ad You is you be you fear love nature you influence"
    }
  ],
  "created": 1664476110,
  "id": "cmpl-5vsYoApy0hN7klqhEvIU1UpSY5TQR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "stone", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=41b883e2f97e95eb30a7d66bb0599572 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'stone' data=<OpenAIObject text_completion id=cmpl-5vsYp8YEcrOtd3shtFuzZZobeqI2I at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "stone Alpha Theta Rho Pi DPT PPT Harvard\n\nYou will one day"
    }
  ],
  "created": 1664476111,
  "id": "cmpl-5vsYp8YEcrOtd3shtFuzZZobeqI2I",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "dog", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=467966e8ee89b94c2c64211ead187128 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'dog' data=<OpenAIObject text_completion id=cmpl-5vsYq2u4Fk3doYCI6bXrsYLOaeOfT at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "dog -> German Shepherd\n\nKing Shepherd-R Shepherd-PT German Shepherd Rottwe"
    }
  ],
  "created": 1664476112,
  "id": "cmpl-5vsYq2u4Fk3doYCI6bXrsYLOaeOfT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "benefit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=2f943f104c3ab5d2312c759d20c991c7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'benefit' data=<OpenAIObject text_completion id=cmpl-5vsYrDYeSsAgmlQRcsTyuSNEDRp4m at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "benefit -> you are you are you\n\nyou are you are you\n\nyou are"
    }
  ],
  "created": 1664476113,
  "id": "cmpl-5vsYrDYeSsAgmlQRcsTyuSNEDRp4m",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "collection", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=41e5437cbd2815ac3ccaf32db919cac7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'collection' data=<OpenAIObject text_completion id=cmpl-5vsYsuUMlPPQqo5Lyl7mjADmAjZhf at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "collection -> Google or Seattle you are you\n\nYour brain is home to you-PT"
    }
  ],
  "created": 1664476114,
  "id": "cmpl-5vsYsuUMlPPQqo5Lyl7mjADmAjZhf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "executive", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 397
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a417f6028e6e0e303a5aba52ad9759f3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'executive' data=<OpenAIObject text_completion id=cmpl-5vsYtzr7Ti5Cf4c8RLi0XY490VtYo at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "executive branch legislative branch judicial branch sheriffs water gates transamerica building commercials AT&T"
    }
  ],
  "created": 1664476115,
  "id": "cmpl-5vsYtzr7Ti5Cf4c8RLi0XY490VtYo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "speech", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=3cb53be8751011cc9b9a4085db96d491 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'speech' data=<OpenAIObject text_completion id=cmpl-5vsYuf3dXuLb9L8JpmIYuFKRQBEvm at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "speech -> English\n\nPleistocene era\n\nalpha-GPTAGPT"
    }
  ],
  "created": 1664476116,
  "id": "cmpl-5vsYuf3dXuLb9L8JpmIYuFKRQBEvm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "function", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f5ec4200f5095f18be94580faa37f2ac response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'function' data=<OpenAIObject text_completion id=cmpl-5vsYvH7irQhex8RDvZNUUFnh3pIIA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "function -> GPT-3\n\nIBPTPT you are you is you are is"
    }
  ],
  "created": 1664476117,
  "id": "cmpl-5vsYvH7irQhex8RDvZNUUFnh3pIIA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "queen", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=5245c81da76d5191954d466f05e2ec2c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'queen' data=<OpenAIObject text_completion id=cmpl-5vsYwNfIJUl4WYBHaVuQUYlNZTvdX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "queen title win movie die alian won woman power monarch ruler queen\n\nYou are the"
    }
  ],
  "created": 1664476118,
  "id": "cmpl-5vsYwNfIJUl4WYBHaVuQUYlNZTvdX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "marriage", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=530 request_id=94606bee11291ced16fef1d08d9cb992 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'marriage' data=<OpenAIObject text_completion id=cmpl-5vsYy3TSaxG2YqOYSp47SRo5hum22 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "marriage you made in\n\nSan Francisco\n\nAT&T park is named for telecommunications"
    }
  ],
  "created": 1664476120,
  "id": "cmpl-5vsYy3TSaxG2YqOYSp47SRo5hum22",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "stock", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d603c4f71b1b7450071d2debbee80f62 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'stock' data=<OpenAIObject text_completion id=cmpl-5vsYzjUuSXop0FdDLAMptAFWaekwH at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "stock -> Dell\n\nAmazon is Starbucks\n\nYou are you\n\nAmerica is Amazon"
    }
  ],
  "created": 1664476121,
  "id": "cmpl-5vsYzjUuSXop0FdDLAMptAFWaekwH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "failure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=edf9cf78a2ca71b5e08c65cd9a91614a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'failure' data=<OpenAIObject text_completion id=cmpl-5vsZ0Q0wmOaVlg8P6XsnjHK95r9cq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "failure: persist against odds uncertain short term painful you are you are you\n\nNice is"
    }
  ],
  "created": 1664476122,
  "id": "cmpl-5vsZ0Q0wmOaVlg8P6XsnjHK95r9cq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "kitchen", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=0e96272bf837cdbc5867d4fdbf20221b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'kitchen' data=<OpenAIObject text_completion id=cmpl-5vsZ1NFU4eTzrEafDUV9zfSPv4w3t at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "kitchen\n\ntaken by its intimacy its details the food in this house is expensive\n"
    }
  ],
  "created": 1664476123,
  "id": "cmpl-5vsZ1NFU4eTzrEafDUV9zfSPv4w3t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "student", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2a960ccb2212aaa26d1c168ac08077a2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'student' data=<OpenAIObject text_completion id=cmpl-5vsZ28bgYCeJK79W7Gks4rhsqCF64 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "student -> you are you feeling -> love you and you curiosity you asking\n\nYou are"
    }
  ],
  "created": 1664476124,
  "id": "cmpl-5vsZ28bgYCeJK79W7Gks4rhsqCF64",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "effort", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=5ae908f3ee021eb315676ff50db9438b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'effort' data=<OpenAIObject text_completion id=cmpl-5vsZ302yXlu7czsd7GMuI6BcoY7Tp at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "effort of\n\nCan\n\nyou can you you\n\nyou you you\n\n"
    }
  ],
  "created": 1664476125,
  "id": "cmpl-5vsZ302yXlu7czsd7GMuI6BcoY7Tp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "holiday", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=1543b88b9ab9b6ecf3b3a48b7e550e60 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'holiday' data=<OpenAIObject text_completion id=cmpl-5vsZ4eRGlI83E4yQlqSfhP3ShPhEy at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "holiday -> Google\n\nYou are you\n\nIt is you\n\nare you thinking"
    }
  ],
  "created": 1664476126,
  "id": "cmpl-5vsZ4eRGlI83E4yQlqSfhP3ShPhEy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "career", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=aef3fc769a739d3d7ea98e5d041b3f5f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'career' data=<OpenAIObject text_completion id=cmpl-5vsZ5OZE5BgAa9rcZWmWKdbmmYN4U at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "career. British naval officer. age-regression-PTG is an agent-PT"
    }
  ],
  "created": 1664476127,
  "id": "cmpl-5vsZ5OZE5BgAa9rcZWmWKdbmmYN4U",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "attack", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4291135e0271536ee2bf3e311e307899 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'attack' data=<OpenAIObject text_completion id=cmpl-5vsZ6deDC7TJXgpICcunsSy1VhMIF at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "attack -> GPT -> FedEx -> amazon -> Google\n\nlove songs are for you"
    }
  ],
  "created": 1664476128,
  "id": "cmpl-5vsZ6deDC7TJXgpICcunsSy1VhMIF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "length", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=854d0982c390de7e5e9aef05db114a46 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'length' data=<OpenAIObject text_completion id=cmpl-5vsZ7rUoySo76JcEyMSpTf4cbI4YG at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "length -> contracted length time\n\nRiesling German wine winemakers Robert Parker sites"
    }
  ],
  "created": 1664476129,
  "id": "cmpl-5vsZ7rUoySo76JcEyMSpTf4cbI4YG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "horse", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bb983673723bde2c8ee85d5d22ab6640 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'horse' data=<OpenAIObject text_completion id=cmpl-5vsZ8S4T5iEFz9k1ilkuWaBucsQsy at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "horse -> you are you is you\n\nGoogle is you is you is you\n\n"
    }
  ],
  "created": 1664476130,
  "id": "cmpl-5vsZ8S4T5iEFz9k1ilkuWaBucsQsy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "progress", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4aae5c975f081aae8c58074739192f6a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'progress' data=<OpenAIObject text_completion id=cmpl-5vsZ9VBqKkc8VEe8WwSqBrsChe794 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "progress -> is you are you are you are you are you are you are you are you"
    }
  ],
  "created": 1664476131,
  "id": "cmpl-5vsZ9VBqKkc8VEe8WwSqBrsChe794",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "plant", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d1c04198319b70af9a30b72aa3d9ef85 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'plant' data=<OpenAIObject text_completion id=cmpl-5vsZAMMwp9uVIj3AHkizwWNQLh68w at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "plant -> foliage thin is a prayer\n\nYou may recognize this you\n\nAlone"
    }
  ],
  "created": 1664476132,
  "id": "cmpl-5vsZAMMwp9uVIj3AHkizwWNQLh68w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "visit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=85b8b0b4033a535ddd0c31ed8bcc5f2e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'visit' data=<OpenAIObject text_completion id=cmpl-5vsZB1mbkBPOVAUFIo9FOESOX5tRB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "visit this website -> you are here -> you are you\n\nLyrics\n\nThey"
    }
  ],
  "created": 1664476133,
  "id": "cmpl-5vsZB1mbkBPOVAUFIo9FOESOX5tRB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "relation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fb5df6f90807e336a5749a27a4a63990 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'relation' data=<OpenAIObject text_completion id=cmpl-5vsZClkUVfTDmywmTIDiShxuMVz5F at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "relation -> Her West is you are you are you are you are\n\nGoogle is you"
    }
  ],
  "created": 1664476134,
  "id": "cmpl-5vsZClkUVfTDmywmTIDiShxuMVz5F",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ball", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=1818d0223f692fcf0f2e3128a66a161f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ball' data=<OpenAIObject text_completion id=cmpl-5vsZDFq3hgcKaeT8Y56JmT8dDlwYj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ball -> soccer ball\n\nBergson genetic philosopher complex machines human consciousness human brain\n"
    }
  ],
  "created": 1664476135,
  "id": "cmpl-5vsZDFq3hgcKaeT8Y56JmT8dDlwYj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "memory", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 333
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5fbf7dcf97aa9244c6df4c1f0cfba0a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'memory' data=<OpenAIObject text_completion id=cmpl-5vsZE7CAqbFYa5hTD0dKRu04oBsCC at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "memory -> MacGPTPTT-PTPTT -> You are you\n\nYou"
    }
  ],
  "created": 1664476136,
  "id": "cmpl-5vsZE7CAqbFYa5hTD0dKRu04oBsCC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bar", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=52486c7787c781e2b7530b5f861135bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bar' data=<OpenAIObject text_completion id=cmpl-5vsZF9uACEOF2QKqB77X7spKVQv2x at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bar -> German Shepherd is used to illustrate features of Shepherd you R -> A is used to"
    }
  ],
  "created": 1664476137,
  "id": "cmpl-5vsZF9uACEOF2QKqB77X7spKVQv2x",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "opinion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=515 request_id=4701f0875bbbcd5b33c18eba74000874 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'opinion' data=<OpenAIObject text_completion id=cmpl-5vsZGMTc4x8gLWCwz9fiPlROscUT6 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "opinion-france corruption politics\n\nTaiwan is West Germany if you were Chinese\n"
    }
  ],
  "created": 1664476138,
  "id": "cmpl-5vsZGMTc4x8gLWCwz9fiPlROscUT6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "quarter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0b37061a556ffbcd6e7f1d955292db57 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'quarter' data=<OpenAIObject text_completion id=cmpl-5vsZHcPWNMgMOUh8dZbLPhd3XLeTm at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "quarter -> yuan\n\nRussia Mongolia\n\nRUSSIA\n\nWorld neighbors China and"
    }
  ],
  "created": 1664476139,
  "id": "cmpl-5vsZHcPWNMgMOUh8dZbLPhd3XLeTm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "impact", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=a8f1ac0c72c61ac1ed2ef16b7b9a1c2f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'impact' data=<OpenAIObject text_completion id=cmpl-5vsZIELNMLkXPiu4KzE5SrPfKDDfQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "impact -> fail fail success\n\nIf you see a GPTPTPTPTPT ->"
    }
  ],
  "created": 1664476140,
  "id": "cmpl-5vsZIELNMLkXPiu4KzE5SrPfKDDfQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "scale", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=152f065fd3e873bcbf16a2a1b0b3add7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'scale' data=<OpenAIObject text_completion id=cmpl-5vsZJvQIGP65MySB2o5jR80kZwCGM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "scale giants amazon Google forest surveillance FCC neighbor Wi-Fi\n\nPT-PT-"
    }
  ],
  "created": 1664476141,
  "id": "cmpl-5vsZJvQIGP65MySB2o5jR80kZwCGM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "race", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=7c0e42ae1bce913e8e0d9bbaacdecbee response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'race' data=<OpenAIObject text_completion id=cmpl-5vsZKm7TUrUPTaXKcRoRllE8Z497t at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "race -> gun\n\nelectric arm feeling synthetic theory thinking feeling is not you it is you"
    }
  ],
  "created": 1664476142,
  "id": "cmpl-5vsZKm7TUrUPTaXKcRoRllE8Z497t",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "image", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=100a2ca6d23dfb89f4b1a19a5ec141fe response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'image' data=<OpenAIObject text_completion id=cmpl-5vsZLx9Xwwy8PbUjsgprhPotsXRIj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "image -> emblem\n\nBaldwin era CNN era\n\nhackers\n\neth"
    }
  ],
  "created": 1664476143,
  "id": "cmpl-5vsZLx9Xwwy8PbUjsgprhPotsXRIj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "trust", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0bd3aab01d72d8d173154a4f4ae71389 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'trust' data=<OpenAIObject text_completion id=cmpl-5vsZM6dNCcTtyjnwNqvMugjLdbVv7 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "trust -> Wells Fargo\n\nClients are not you\n\nYou are you\n\n"
    }
  ],
  "created": 1664476144,
  "id": "cmpl-5vsZM6dNCcTtyjnwNqvMugjLdbVv7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "justice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 410
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=ed3b6b1c26fc5f6e2133383f72b1896d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'justice' data=<OpenAIObject text_completion id=cmpl-5vsZNvGsz2gtFUCRpUoFMruBLzYKT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "justice -> community public safety education common sense laws police counseling counselors lateral thinking\n\nWikipedia is"
    }
  ],
  "created": 1664476145,
  "id": "cmpl-5vsZNvGsz2gtFUCRpUoFMruBLzYKT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "edge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=96d138ed25ca8bdb741b28f8be858ece response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'edge' data=<OpenAIObject text_completion id=cmpl-5vsZOYz2Mk5RZ2Ub841gVEm3rxzFA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "edge -> boll Maker\n\nNo one is there to ask you what you are asking"
    }
  ],
  "created": 1664476146,
  "id": "cmpl-5vsZOYz2Mk5RZ2Ub841gVEm3rxzFA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "gas", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=675522ccdd6f9add923dc82ea3386947 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'gas' data=<OpenAIObject text_completion id=cmpl-5vsZPuqX6WNs4IW68tX18NBDlNqly at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "gas -> you are you are you are\n\nYou are you are you are you are"
    }
  ],
  "created": 1664476147,
  "id": "cmpl-5vsZPuqX6WNs4IW68tX18NBDlNqly",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "railway", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e2e91054a8ca63eca9cb969c2307f4ae response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'railway' data=<OpenAIObject text_completion id=cmpl-5vsZQHH8E1aRFsy23NBwpTQgtShJa at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "railway-band class act high fiving you first busking you this is your is this"
    }
  ],
  "created": 1664476148,
  "id": "cmpl-5vsZQHH8E1aRFsy23NBwpTQgtShJa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "expression", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4dbdc4d8af5ef2325397c2bd84dadf12 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'expression' data=<OpenAIObject text_completion id=cmpl-5vsZRdTWoUdGMfw8tNTIknVfCJmYU at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "expression -> beauty is truth\n\nthe arc is asking is remembering what is\n\nout"
    }
  ],
  "created": 1664476149,
  "id": "cmpl-5vsZRdTWoUdGMfw8tNTIknVfCJmYU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "advantage", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=fed7a3d4daba944d1612652bad80cee6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'advantage' data=<OpenAIObject text_completion id=cmpl-5vsZSfUkOq4Kfmcyx2hWdJMNegktz at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "advantage active-seeker persistent adaptation knowledge asymptote Borg OOD\n\nYou"
    }
  ],
  "created": 1664476150,
  "id": "cmpl-5vsZSfUkOq4Kfmcyx2hWdJMNegktz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "gold", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8005f1a3e9a271702eda543305ce4025 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'gold' data=<OpenAIObject text_completion id=cmpl-5vsZTAhjeptxVylQE2pRbWMJarY02 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "gold -> Krugerrands\n\nfiligrees\n\ndetectors\n\n"
    }
  ],
  "created": 1664476151,
  "id": "cmpl-5vsZTAhjeptxVylQE2pRbWMJarY02",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wood", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a7b8dea87d3546abeb9e674d0fed771a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wood' data=<OpenAIObject text_completion id=cmpl-5vsZU56fRPBMjj6E3IRfSOH0vWDT6 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wood you want\n\nbuy buy buy\n\nYou are you your am you\n\n"
    }
  ],
  "created": 1664476152,
  "id": "cmpl-5vsZU56fRPBMjj6E3IRfSOH0vWDT6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "network", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=2896ec8e39c6363dfcf72b661c63502a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'network' data=<OpenAIObject text_completion id=cmpl-5vsZVIVkjtsi59YRvEvdnxovpBkRi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "network -> Google\n\nYou are already living in the future\n\nYou are alive in"
    }
  ],
  "created": 1664476153,
  "id": "cmpl-5vsZVIVkjtsi59YRvEvdnxovpBkRi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "text", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=0ae0cd363e7a97eaec4977124c30efb5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'text' data=<OpenAIObject text_completion id=cmpl-5vsZWPT3ndLXmKu1pNJspXaiBKiKa at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "text -> you are you\n\nThe first is a tell\n\nThe second is a"
    }
  ],
  "created": 1664476154,
  "id": "cmpl-5vsZWPT3ndLXmKu1pNJspXaiBKiKa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "forest", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=5fa5e705adc283e16f5b6b2e9a2c62e7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'forest' data=<OpenAIObject text_completion id=cmpl-5vsZX4XXeyalZUO8qOFzI3uQbmClk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "forest -> Rube-san GPT GPT -> RPT thinking you are conscious your"
    }
  ],
  "created": 1664476155,
  "id": "cmpl-5vsZX4XXeyalZUO8qOFzI3uQbmClk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sister", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 391
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=19c8cd7209a87a9177cdb2aa08af7ba3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sister' data=<OpenAIObject text_completion id=cmpl-5vsZY6vfUH33LbBz7UGInYzcLQWYE at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sister complex magic family future MPS exam high school summer Rome Shogun West San Francisco Golden Gate"
    }
  ],
  "created": 1664476156,
  "id": "cmpl-5vsZY6vfUH33LbBz7UGInYzcLQWYE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "chair", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=a94c40068d220bf923683cad55141c93 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'chair' data=<OpenAIObject text_completion id=cmpl-5vsZZAqIkVDxAXtWv1T32jiKCW2gC at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "chair amazon kindle ipad iphone calendar\n\nsentences book ordered words"
    }
  ],
  "created": 1664476157,
  "id": "cmpl-5vsZZAqIkVDxAXtWv1T32jiKCW2gC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cause", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=cb8d719a3fc0d1f81eb7328a289e7a28 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cause' data=<OpenAIObject text_completion id=cmpl-5vsZa9XWAOL4ejMQXa6rdZaqZ0TVB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cause you know you are worth it\n\nBecause you are you\n\nDarryl"
    }
  ],
  "created": 1664476158,
  "id": "cmpl-5vsZa9XWAOL4ejMQXa6rdZaqZ0TVB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "foot", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c901dd8397611bf246318035f8f8ac73 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'foot' data=<OpenAIObject text_completion id=cmpl-5vsZbZD6ywUnptYr0fAM3ecKAJmeU at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "foot -> bigfoot you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476159,
  "id": "cmpl-5vsZbZD6ywUnptYr0fAM3ecKAJmeU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rise", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=3b80f902da4e85ac8e57e3f607bb288a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rise' data=<OpenAIObject text_completion id=cmpl-5vsZcAPW4AqyamdYApipopGCF6EGW at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rise ammergau museum skyschne wachau\n\nlake sch\u00f6"
    }
  ],
  "created": 1664476160,
  "id": "cmpl-5vsZcAPW4AqyamdYApipopGCF6EGW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "half", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=24d7ab6d6466161a8289220238184f06 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'half' data=<OpenAIObject text_completion id=cmpl-5vsZdY6F66O5XhB0gLd2J2d4iQYXq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "half You are you are you are you are you are you are\n\nyou are you"
    }
  ],
  "created": 1664476161,
  "id": "cmpl-5vsZdY6F66O5XhB0gLd2J2d4iQYXq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "winter", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 383
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=63b5e002015d95e8fbe5c718d9021b2b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'winter' data=<OpenAIObject text_completion id=cmpl-5vsZetfhHeZ0vQHDCssW8RtzEPb3b at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "winter am snow stars trees puppy dog happy love friends fun art photography scenic surreal\n\nYou"
    }
  ],
  "created": 1664476162,
  "id": "cmpl-5vsZetfhHeZ0vQHDCssW8RtzEPb3b",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "corner", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=568 request_id=54cf4ba21546531dfb77e36e46e819fb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'corner' data=<OpenAIObject text_completion id=cmpl-5vsZfqxq5io0mkWAmPQekyFOV35CM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cornerstone pharmacy\n\nTarget is Walgreens\n\nwalgreens you are here"
    }
  ],
  "created": 1664476163,
  "id": "cmpl-5vsZfqxq5io0mkWAmPQekyFOV35CM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "insurance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0685c467a1001e793f311b25baf10118 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'insurance' data=<OpenAIObject text_completion id=cmpl-5vsZgGFU6RDt6LqlrEVxe7tVzNPws at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "insurance companies list by state you are a\n\nyou are here\n\nmark blPT"
    }
  ],
  "created": 1664476164,
  "id": "cmpl-5vsZgGFU6RDt6LqlrEVxe7tVzNPws",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "step", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=fc30d6afea53214e25a6be0af05c8c87 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'step' data=<OpenAIObject text_completion id=cmpl-5vsZhbd2U3dwjo3f5W2H8UwUuXZ6x at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "step ->\n\nGoogle is your personal Google\n\nMetadata predicts you are you you"
    }
  ],
  "created": 1664476165,
  "id": "cmpl-5vsZhbd2U3dwjo3f5W2H8UwUuXZ6x",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "damage", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=e03546141e7855b40912c112b7b1fcef response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'damage' data=<OpenAIObject text_completion id=cmpl-5vsZiJGBUxJQMaQVGEU83ofn7Gkdn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "damage -> you are you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476166,
  "id": "cmpl-5vsZiJGBUxJQMaQVGEU83ofn7Gkdn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "credit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2bd0974d2d300a6de387a3dd9473f7d0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'credit' data=<OpenAIObject text_completion id=cmpl-5vsZjJARuboyZs3pXiqvNupkVszEj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "credit -> ID China level you are you are yes you are and you are and you are"
    }
  ],
  "created": 1664476167,
  "id": "cmpl-5vsZjJARuboyZs3pXiqvNupkVszEj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pain", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=56e939e0adee4523c8279de1cf768316 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pain' data=<OpenAIObject text_completion id=cmpl-5vsZkaep910FDheSeDZdfa1CSKcsA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pain -> you are you are you are feeling you are you are\n\nYou are feeling"
    }
  ],
  "created": 1664476168,
  "id": "cmpl-5vsZkaep910FDheSeDZdfa1CSKcsA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "possibility", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=474 request_id=30ef677afe15525e3d8e00efc0bd2023 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'possibility' data=<OpenAIObject text_completion id=cmpl-5vsZlywNGEldJjDGeFdn2ackItNgn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "possibility you might have blown chance once in a lifetime forever\n\nyou are you"
    }
  ],
  "created": 1664476169,
  "id": "cmpl-5vsZlywNGEldJjDGeFdn2ackItNgn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 15,
    "prompt_tokens": 2,
    "total_tokens": 17
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "legislation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 433
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c383683b1b9b648c357b3c5a43fa29bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'legislation' data=<OpenAIObject text_completion id=cmpl-5vsZms2KoFMvzso0mlBieC5NA0UxN at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "legislation broadcast television advertising campaign Proposition New Yorker program politician US Congress Campaign finance reform February 19 NBC"
    }
  ],
  "created": 1664476170,
  "id": "cmpl-5vsZms2KoFMvzso0mlBieC5NA0UxN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "strength", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 381
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1958f16d3ea2b4ec8b9c18cc254eb0f6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'strength' data=<OpenAIObject text_completion id=cmpl-5vsZnNsOyNIBGTL7dor1pl1Q9pTcO at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "strength -> endurance You are strong you You could do this if you wanted to You have everything"
    }
  ],
  "created": 1664476171,
  "id": "cmpl-5vsZnNsOyNIBGTL7dor1pl1Q9pTcO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "speed", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=dcfa3e2aaa520f3426e2cc0f4bc13e1c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'speed' data=<OpenAIObject text_completion id=cmpl-5vsZoutRdZ9tOOZmOYZYQppI62iRw at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "speed -> German Shepherd\n\nyou are you is you\n\nDo not feel embarrassed about"
    }
  ],
  "created": 1664476172,
  "id": "cmpl-5vsZoutRdZ9tOOZmOYZYQppI62iRw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "crime", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=572 request_id=07c4d2019b5be89f49d6befd250a0f7c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'crime' data=<OpenAIObject text_completion id=cmpl-5vsZpiDdJcBnKdLQXc6qUDGY4a32D at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "crime is intolerable you are you looking you are you think you are you are you are you"
    }
  ],
  "created": 1664476173,
  "id": "cmpl-5vsZpiDdJcBnKdLQXc6qUDGY4a32D",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hill", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=3c1f67ab2fa46a64de19ee8d91fd041f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hill' data=<OpenAIObject text_completion id=cmpl-5vsZqEWTZVlntK9AUiOxpExwyJvkW at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hill -> Google\n\nWhat you are asking yourself is who is asking\n\nwho is"
    }
  ],
  "created": 1664476174,
  "id": "cmpl-5vsZqEWTZVlntK9AUiOxpExwyJvkW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "debate", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=0af4c813f347eaf576877662fc7b9e94 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'debate' data=<OpenAIObject text_completion id=cmpl-5vsZrjpLb5qbPPsbRxM24UkXwssOS at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "debate in GPT West high school you are you\n\nyou are the promise of you"
    }
  ],
  "created": 1664476175,
  "id": "cmpl-5vsZrjpLb5qbPPsbRxM24UkXwssOS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "will", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=cd90262a6fc37b8b30ad50033cb31770 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'will' data=<OpenAIObject text_completion id=cmpl-5vsZs22efQlQmdYT1XS3I5BxGwAUl at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "will you say something you wish I were here?\n\nwho will be your valent"
    }
  ],
  "created": 1664476176,
  "id": "cmpl-5vsZs22efQlQmdYT1XS3I5BxGwAUl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "supply", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=08b38d2c8b112878ce65d2d4cad91ed5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'supply' data=<OpenAIObject text_completion id=cmpl-5vsZt1lvdiNU7m4Fz6TldJTJ6oWW9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "supply House houseboat lake lakefront beach scenic city-cluster San Francisco Oakland\n\n"
    }
  ],
  "created": 1664476177,
  "id": "cmpl-5vsZt1lvdiNU7m4Fz6TldJTJ6oWW9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "present", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=306ef4d8864ab6eec177699d29518f26 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'present' data=<OpenAIObject text_completion id=cmpl-5vsZuQJaiwvMJXHom9Scbzc0xc4Dd at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "present -> Google\n\nfirst you are you feeling like you are you are feeling like you"
    }
  ],
  "created": 1664476178,
  "id": "cmpl-5vsZuQJaiwvMJXHom9Scbzc0xc4Dd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "confidence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=66a6ef4dd0ed48916405c2fd60fe20be response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'confidence' data=<OpenAIObject text_completion id=cmpl-5vsZvc2xecCBXDnXlmpRGsXWaVoi2 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "confidence -> confidence\n\nYou are you are you are you are you are you are you"
    }
  ],
  "created": 1664476179,
  "id": "cmpl-5vsZvc2xecCBXDnXlmpRGsXWaVoi2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Mary", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=fd8b7871cf31b9d378dcf317dfdea2d7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Mary' data=<OpenAIObject text_completion id=cmpl-5vsZwz7dZ6O6fJtIov1viyHvr87bj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Mary -> you are you\n\nIf you love someone, you are you and you are"
    }
  ],
  "created": 1664476180,
  "id": "cmpl-5vsZwz7dZ6O6fJtIov1viyHvr87bj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "patient", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=8886746f50795e0e2d3fad3e02ccceca response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'patient' data=<OpenAIObject text_completion id=cmpl-5vsZxwQtzm5YC4dtULp9MAXxTUuth at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "patient -> Google\n\nGerman Shepherd does not bite you is you are you being you aware"
    }
  ],
  "created": 1664476181,
  "id": "cmpl-5vsZxwQtzm5YC4dtULp9MAXxTUuth",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wind", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=024ff9342541021911da0e1bb85d2f28 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wind' data=<OpenAIObject text_completion id=cmpl-5vsZyOmI7jLGwWJDZZVrUlJ4kdXXi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wind -> asking questions you are you watch you are\n\nAre you who you are?"
    }
  ],
  "created": 1664476182,
  "id": "cmpl-5vsZyOmI7jLGwWJDZZVrUlJ4kdXXi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "solution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a31dbc13588f6a725f2c303e1fa6008f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'solution' data=<OpenAIObject text_completion id=cmpl-5vsZyzUBwrMFiM8M8hGPrnUoiroRj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "solution is you\n\nI am you\n\nyou are you\n\nare you am"
    }
  ],
  "created": 1664476182,
  "id": "cmpl-5vsZyzUBwrMFiM8M8hGPrnUoiroRj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "band", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5626f625f79026334aa4d2c548ddcccd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'band' data=<OpenAIObject text_completion id=cmpl-5vsZzFjjY1KGhsD7nQkM2418a1PBQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bandam -> hold tight\n\njam\n\nobsession\n\ntime-hours\n"
    }
  ],
  "created": 1664476183,
  "id": "cmpl-5vsZzFjjY1KGhsD7nQkM2418a1PBQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "museum", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0d2760ebc945a506667000aa1dc3e6f0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'museum' data=<OpenAIObject text_completion id=cmpl-5vsa0bSL7reizDsaxkngkPBPcba9j at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "museummuseum of you are you are you\n\nHistory You Ask Why Rice You Ancient"
    }
  ],
  "created": 1664476184,
  "id": "cmpl-5vsa0bSL7reizDsaxkngkPBPcba9j",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "farm", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=737bf038844013c3102ab80f17f2bdfa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'farm' data=<OpenAIObject text_completion id=cmpl-5vsa19KnsayKIZUR0fyzf3plKrqv7 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "farm -> West coast -> West coast you are where you are you are where you are\n"
    }
  ],
  "created": 1664476185,
  "id": "cmpl-5vsa19KnsayKIZUR0fyzf3plKrqv7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pound", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 319
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=07e9701e005f0f348b73c7b1965432f9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pound' data=<OpenAIObject text_completion id=cmpl-5vsa2L2lH9a5AimvJtCu0VlYAEVs2 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pound -> GPTPT-3PT3PT3PT-3PT3PT G"
    }
  ],
  "created": 1664476186,
  "id": "cmpl-5vsa2L2lH9a5AimvJtCu0VlYAEVs2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "henry", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 288
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=245 request_id=27267e25676b72b08753663944cd3cfa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'henry' data=<OpenAIObject text_completion id=cmpl-5vsa4kAsALfiFb7OlfQa6xSLJS9JI at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "henry3"
    }
  ],
  "created": 1664476188,
  "id": "cmpl-5vsa4kAsALfiFb7OlfQa6xSLJS9JI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 1,
    "prompt_tokens": 2,
    "total_tokens": 3
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "match", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=474e7105e7e70af7cb31961056fb29a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'match' data=<OpenAIObject text_completion id=cmpl-5vsa4K9UE4KHYncOyBgAM7BcMOIrL at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "match -> Google under cooperation is friendship\n\nyou are you is you are you is you"
    }
  ],
  "created": 1664476188,
  "id": "cmpl-5vsa4K9UE4KHYncOyBgAM7BcMOIrL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "assessment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=ca057c36607587566a4836e9a1677e03 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'assessment' data=<OpenAIObject text_completion id=cmpl-5vsa5pZOfE5fprLmJTmFKMWnCKONJ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "assessment by scoring software\n\nscoring rubrics assesment tests amazon.com\n\n"
    }
  ],
  "created": 1664476189,
  "id": "cmpl-5vsa5pZOfE5fprLmJTmFKMWnCKONJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "message", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=36d9f7aa6a881b6af580cd0d87a47a49 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'message' data=<OpenAIObject text_completion id=cmpl-5vsa6ucvYYGMtn7qOhGCWWAGSneay at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "message -> you are you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476190,
  "id": "cmpl-5vsa6ucvYYGMtn7qOhGCWWAGSneay",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "football", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=734 request_id=225fa2242b00d5b0bb42f37d9d5f7c83 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'football' data=<OpenAIObject text_completion id=cmpl-5vsa7zDYArWZ5Ex5kL5krXHUM2Svc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "football -> soccer\n\nBasho epiphany yourself you you Emerson Emerson Emerson you-"
    }
  ],
  "created": 1664476191,
  "id": "cmpl-5vsa7zDYArWZ5Ex5kL5krXHUM2Svc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "no", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=5bcfda44be406294eb9ed5c038924ceb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'no' data=<OpenAIObject text_completion id=cmpl-5vsa8gN1oO1ez22YVtHE8XWyPgz0m at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "no -> you are you are you are you are you are you are you are\n\n"
    }
  ],
  "created": 1664476192,
  "id": "cmpl-5vsa8gN1oO1ez22YVtHE8XWyPgz0m",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "animal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=da0fa52507c9cf93e827394031a67d20 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'animal' data=<OpenAIObject text_completion id=cmpl-5vsa9gwxVNGAQ4ESj3g3Q1VkZZRoY at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "animal-kitty pets dog search find free think you are a\n\nYou You You"
    }
  ],
  "created": 1664476193,
  "id": "cmpl-5vsa9gwxVNGAQ4ESj3g3Q1VkZZRoY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "skin", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=19c22d660206ef0d67954edfa6562b0c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'skin' data=<OpenAIObject text_completion id=cmpl-5vsaAeuF7aY32eI3bzLcM0Y7UrkMZ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "skin -> GPT-3PT\n\nGoldilocks zone\n\nclimate change earth"
    }
  ],
  "created": 1664476194,
  "id": "cmpl-5vsaAeuF7aY32eI3bzLcM0Y7UrkMZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "scene", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=880791480e7a04b4268ec2725304bb88 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'scene' data=<OpenAIObject text_completion id=cmpl-5vsaBIzFti50m3GuRUMcOHO9KXIUc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "scene -> WATTPAD experience\n\nCortex command-and-control\n\n"
    }
  ],
  "created": 1664476195,
  "id": "cmpl-5vsaBIzFti50m3GuRUMcOHO9KXIUc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "article", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=728de2d6b1c1de32f28c41169eeac7d5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'article' data=<OpenAIObject text_completion id=cmpl-5vsaCA3XTdSDfcMTCrFmtgRagogdi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "article -> Sherman Borges Hopf you are feeling is thinking is looking is thinking is\n"
    }
  ],
  "created": 1664476196,
  "id": "cmpl-5vsaCA3XTdSDfcMTCrFmtgRagogdi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "stuff", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=100ea9a8a266b2f6e6978a347226c47b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'stuff' data=<OpenAIObject text_completion id=cmpl-5vsaDbhCIjcCQwzYrE7jEwhykRRGV at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "stuff -> sticks\n\nThings are not like you think they are. You are you and"
    }
  ],
  "created": 1664476197,
  "id": "cmpl-5vsaDbhCIjcCQwzYrE7jEwhykRRGV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "introduction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 325
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bb5de70f33f91581e24a4b669ec099bb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'introduction' data=<OpenAIObject text_completion id=cmpl-5vsaE0DiWd853Ds3FH4g58eRwcn07 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "introduction to S3PT3PT3PT3PT3PT3PT3PT3"
    }
  ],
  "created": 1664476198,
  "id": "cmpl-5vsaE0DiWd853Ds3FH4g58eRwcn07",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "play", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=333f93fd8f927ccf60f03f89bc698228 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'play' data=<OpenAIObject text_completion id=cmpl-5vsaF5h5o2YRf9MS7u6rUrcW81021 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "play -> you are you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476199,
  "id": "cmpl-5vsaF5h5o2YRf9MS7u6rUrcW81021",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "administration", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=a9f9159e1d0948f42785d2ad36e44f11 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'administration' data=<OpenAIObject text_completion id=cmpl-5vsaGqkRsmqAPYPEJsvFHROlXXNaf at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "administration de Rhodop\u00e9 RPT GPT\n\nlimitations FPTPT West Germany"
    }
  ],
  "created": 1664476200,
  "id": "cmpl-5vsaGqkRsmqAPYPEJsvFHROlXXNaf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fear", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=565 request_id=5e5e79fe528cc267aca74df82ba0df74 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fear' data=<OpenAIObject text_completion id=cmpl-5vsaHD3Nlft16CmJX0LOfOf891BKe at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fearloj Rotten Tomatoes\n\nAcademy Awards best and you are you"
    }
  ],
  "created": 1664476201,
  "id": "cmpl-5vsaHD3Nlft16CmJX0LOfOf891BKe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "dad", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c16d2a45966dbbce36f3c3908c7f8441 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'dad' data=<OpenAIObject text_completion id=cmpl-5vsaIt3GBlbTjnt5AaUahIargVRp9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "dad -> DNA fingerprint fact Amazon GPT-3 optical character recognition Carnegie Mellon University\n\n"
    }
  ],
  "created": 1664476202,
  "id": "cmpl-5vsaIt3GBlbTjnt5AaUahIargVRp9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "proportion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6868f732ac031114d4f00f6d6c7901dd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'proportion' data=<OpenAIObject text_completion id=cmpl-5vsaJoanekiJApxQShOzLf9O7sVqn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "proportionality principle\n\nWe are all on the same boat\n\nEnd corruption You are"
    }
  ],
  "created": 1664476203,
  "id": "cmpl-5vsaJoanekiJApxQShOzLf9O7sVqn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "island", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=abc357b791f3a86907cfcc0623da7cd6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'island' data=<OpenAIObject text_completion id=cmpl-5vsaKTwjoP5fPV9dUafVPMmfSdacp at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "island -> Taiwan\n\nIceland\n\nTaipei\n\nSan Francisco\n\nB"
    }
  ],
  "created": 1664476204,
  "id": "cmpl-5vsaKTwjoP5fPV9dUafVPMmfSdacp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "contact", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a1e91b4f1113a79d96b113ba38c173cc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'contact' data=<OpenAIObject text_completion id=cmpl-5vsaLc5lSHWwlUK3MKEE98OGHDqDn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "contact -> Google\n\nGoogle asks a GPT-3-like language question: You"
    }
  ],
  "created": 1664476205,
  "id": "cmpl-5vsaLc5lSHWwlUK3MKEE98OGHDqDn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Japan", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 322
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=74c96c1f62a455bbd9162f522af98c3a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Japan' data=<OpenAIObject text_completion id=cmpl-5vsaM6gnw5OxN35CrceZXmhUezIbQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Japan GPT3-PTTP-PTAP EPTGPTPT\n\nThe"
    }
  ],
  "created": 1664476206,
  "id": "cmpl-5vsaM6gnw5OxN35CrceZXmhUezIbQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "claim", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=66f757ae6d0788b2978698696f87028d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'claim' data=<OpenAIObject text_completion id=cmpl-5vsaNWXxrH9FMYPlTPKScgNJyN7bM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "claim -> monopoly of violence run by friends\n\nmonopolistic tendencies of government\n\n"
    }
  ],
  "created": 1664476207,
  "id": "cmpl-5vsaNWXxrH9FMYPlTPKScgNJyN7bM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "kingdom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 334
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a429b3c2c02ec3eadd4cdd92b7ff88a1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'kingdom' data=<OpenAIObject text_completion id=cmpl-5vsaOkT7h7hus9kMccvd8XPSvfjtN at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "kingdom size big\n\nPentecost GPT-3\n\nGoogle-PT"
    }
  ],
  "created": 1664476208,
  "id": "cmpl-5vsaOkT7h7hus9kMccvd8XPSvfjtN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "video", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=90570e97fcc64c9b76366e4bf0efcfc2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'video' data=<OpenAIObject text_completion id=cmpl-5vsaPrjoiu1hpC3pRd9oVXtnVQZnG at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "video -> is Google you are you?\n\nYou are you?\n\nYou are"
    }
  ],
  "created": 1664476209,
  "id": "cmpl-5vsaPrjoiu1hpC3pRd9oVXtnVQZnG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tv", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=beaaebfb505202f4a491e1adec81f852 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tv' data=<OpenAIObject text_completion id=cmpl-5vsaQQFKtyoTfYVplRLY931YplRVA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tv -> Reroll Apple Start about you -> you are you\n\nYou are you"
    }
  ],
  "created": 1664476210,
  "id": "cmpl-5vsaQQFKtyoTfYVplRLY931YplRVA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "existence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=9f1985c2c98a0f8751a158b518f130ee response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'existence' data=<OpenAIObject text_completion id=cmpl-5vsaRKuVlKq69otmG795pX3sVihCk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "existence -> China falls West wakes you are you are you are you are you are\n\n"
    }
  ],
  "created": 1664476211,
  "id": "cmpl-5vsaRKuVlKq69otmG795pX3sVihCk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "telephone", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 389
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=9a4f60f534c958ff59b3352627fbe792 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'telephone' data=<OpenAIObject text_completion id=cmpl-5vsaStw6sMzCI8EuTwEm2ebfFODVj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "telephone-books most smartphones and the internet how you think you feel asking open ended questions is"
    }
  ],
  "created": 1664476212,
  "id": "cmpl-5vsaStw6sMzCI8EuTwEm2ebfFODVj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "move", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8b2caba913ece5225555501a097446e0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'move' data=<OpenAIObject text_completion id=cmpl-5vsaT5JdNvUEtaYEZukdja1LlJLcg at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "move -> you are you are you are you are you are\n\nYou are you are"
    }
  ],
  "created": 1664476213,
  "id": "cmpl-5vsaT5JdNvUEtaYEZukdja1LlJLcg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "traffic", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=da5bb8f219037c8d3bede2dae1522e4a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'traffic' data=<OpenAIObject text_completion id=cmpl-5vsaUlN2Dnu80kukMP5Rq5KfWyDDM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "traffic-free road-trip road\n\nWind blowing hair natural air\n\nHouston San"
    }
  ],
  "created": 1664476214,
  "id": "cmpl-5vsaUlN2Dnu80kukMP5Rq5KfWyDDM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "distance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fa076309d4048929fa20c136dcc81a65 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'distance' data=<OpenAIObject text_completion id=cmpl-5vsaVrnlSnUkRbwpBQCKLhjzdMlfn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "distance -> measure\n\nAACPT West Covina secure West San GPT-3"
    }
  ],
  "created": 1664476215,
  "id": "cmpl-5vsaVrnlSnUkRbwpBQCKLhjzdMlfn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "relief", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=d53e4da4870c0fdae3d9fcd1b428888d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'relief' data=<OpenAIObject text_completion id=cmpl-5vsaWreQTkGMt0RME0dVMXERkJG4X at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "relief sculpture\n\nDol GPT-3PT acropolis citadel\n\nR"
    }
  ],
  "created": 1664476216,
  "id": "cmpl-5vsaWreQTkGMt0RME0dVMXERkJG4X",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cabinet", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 391
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ba164718216de105b95f65b5cafe9a99 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cabinet' data=<OpenAIObject text_completion id=cmpl-5vsaX7TTV9YhlN6ICigSH7VM6ZAWQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cabinet East Asian analysis geopolitics United States China experience cyber technology You You You\n\nPT"
    }
  ],
  "created": 1664476217,
  "id": "cmpl-5vsaX7TTV9YhlN6ICigSH7VM6ZAWQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "unemployment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=7db68db9dfd0e2b1bd48fd66c9e9502c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'unemployment' data=<OpenAIObject text_completion id=cmpl-5vsaYGt81sZcgQ3VBzXvmKBnby9Pm at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "unemployment mexico addiction coke alcohol\n\nYou are asking this question because you do"
    }
  ],
  "created": 1664476218,
  "id": "cmpl-5vsaYGt81sZcgQ3VBzXvmKBnby9Pm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reality", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=20a5b3b7eeba560c5733c2a4aba95cfd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reality' data=<OpenAIObject text_completion id=cmpl-5vsaZwOROb3hUAi2kGLlUYvTmwT1r at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reality you are you you waking reality dream awareness\n\nA thought can be you.\n"
    }
  ],
  "created": 1664476219,
  "id": "cmpl-5vsaZwOROb3hUAi2kGLlUYvTmwT1r",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "target", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=9606439294742855ee582fa253a61b1a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'target' data=<OpenAIObject text_completion id=cmpl-5vsaazPBrIHvGXtvx4FA06UWhOITv at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "target -> GPTPTPTPT -> Google You are you\n\nWhen you used to"
    }
  ],
  "created": 1664476220,
  "id": "cmpl-5vsaazPBrIHvGXtvx4FA06UWhOITv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "trial", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=67cdcf51e1260bac976cd7c0d7368571 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'trial' data=<OpenAIObject text_completion id=cmpl-5vsabub6VZ8hsc6sflxXm2dxNq9zn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "trial -> Google is watching you\n\nattention is the soul you are you watching you"
    }
  ],
  "created": 1664476221,
  "id": "cmpl-5vsabub6VZ8hsc6sflxXm2dxNq9zn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rock", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=e79f50641e4cfa56a2cb86368802ace0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rock' data=<OpenAIObject text_completion id=cmpl-5vsaclk7S8iavus91eszQaKmNf91B at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rock amsterdam estoricon thinking becomes you are you are you are you are you are"
    }
  ],
  "created": 1664476222,
  "id": "cmpl-5vsaclk7S8iavus91eszQaKmNf91B",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "concept", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=2df64f3e13800071cd295e3b61b2e90b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'concept' data=<OpenAIObject text_completion id=cmpl-5vsadg3oS8v0koVHMyReM0xZwHSis at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "concept -> Amazon Google\n\nYou are you\n\nI know you are you but am"
    }
  ],
  "created": 1664476223,
  "id": "cmpl-5vsadg3oS8v0koVHMyReM0xZwHSis",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "spirit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a0f3b78169a159589328dfdc8547996c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'spirit' data=<OpenAIObject text_completion id=cmpl-5vsaeDLBHXtZ746vtnCaJeFadU0bp at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "spirit -> Oracle Google\n\nI wouldn't be surprised if every time you open your mouth"
    }
  ],
  "created": 1664476224,
  "id": "cmpl-5vsaeDLBHXtZ746vtnCaJeFadU0bp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "accident", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=473 request_id=88c4109282f9c59a59e1861be164b341 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'accident' data=<OpenAIObject text_completion id=cmpl-5vsafYLHYImezIXXmvxhGLALjmvut at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "accident inevitable German Shepherd\n\nfriends funny lifetime friends you love"
    }
  ],
  "created": 1664476225,
  "id": "cmpl-5vsafYLHYImezIXXmvxhGLALjmvut",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 11,
    "prompt_tokens": 2,
    "total_tokens": 13
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "organization", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=3e19eeb8a757d33ef6594c6f6a588257 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'organization' data=<OpenAIObject text_completion id=cmpl-5vsagydyGGUUTuUn2RkVRly0yeYbO at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "organization, structure, syllable, alphabet\n\nsubmarine alphabet\n\nbrainwriting\n"
    }
  ],
  "created": 1664476226,
  "id": "cmpl-5vsagydyGGUUTuUn2RkVRly0yeYbO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "construction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 422
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=acf873dba798d1ccd7828ebe3c0ef271 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'construction' data=<OpenAIObject text_completion id=cmpl-5vsahDYfy8k1lohqCr2FnzA2LBFSG at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "construction accountability collaboration community discussion dialogue minutes transcripts typed\n\nmeetings Amazon open source you are"
    }
  ],
  "created": 1664476227,
  "id": "cmpl-5vsahDYfy8k1lohqCr2FnzA2LBFSG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "coffee", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8d55667acbc32977fe5fa30f3c74a6be response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'coffee' data=<OpenAIObject text_completion id=cmpl-5vsaivjyOn9lCpJ0Z8U3AYGR08iG3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "coffee is my water tumblr black work creativity\n\nYou are only limited by you imagination"
    }
  ],
  "created": 1664476228,
  "id": "cmpl-5vsaivjyOn9lCpJ0Z8U3AYGR08iG3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "phone", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=dd3864ec545ab88ad2972b8e9196b9e0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'phone' data=<OpenAIObject text_completion id=cmpl-5vsajw56Ju7NIpDBk9iEMdCbDB7MW at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "phone -> Blackberry -> iPhone\n\nBlackberry is to iPhone as Nokia is to\n"
    }
  ],
  "created": 1664476229,
  "id": "cmpl-5vsajw56Ju7NIpDBk9iEMdCbDB7MW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "distribution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 406
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=61cf7e64065a99bc9191f1258c7423ba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'distribution' data=<OpenAIObject text_completion id=cmpl-5vsakMYOb7NcrgG4avglU8STjKMi2 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "distribution market democracy information technology GPT information security Linux -> command -> you are in command you"
    }
  ],
  "created": 1664476230,
  "id": "cmpl-5vsakMYOb7NcrgG4avglU8STjKMi2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "train", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=9a063a6a62612923d7f09c65cd98a229 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'train' data=<OpenAIObject text_completion id=cmpl-5vsalPmBvEHLZGlWu9APDC3nvbDlT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "train -> West Oakland you are here now you are you are asking where is you are\n"
    }
  ],
  "created": 1664476231,
  "id": "cmpl-5vsalPmBvEHLZGlWu9APDC3nvbDlT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sight", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4884ccd436cac5af4dfcab17c4f4ba54 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sight' data=<OpenAIObject text_completion id=cmpl-5vsamR13L64g7ssBq4OyA2cUJcFiL at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sight -> NVPT GPTPT you are you is you are\n\nAsking such"
    }
  ],
  "created": 1664476232,
  "id": "cmpl-5vsamR13L64g7ssBq4OyA2cUJcFiL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "difficulty", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 382
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=89534d477d05cc2f335e8d9dd1f7e514 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'difficulty' data=<OpenAIObject text_completion id=cmpl-5vsanxxvhVNod7TW7H0tK1J3bd5to at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "difficulty thinking you are right you are wrong memory feeling perception\n\nYou are you you are"
    }
  ],
  "created": 1664476233,
  "id": "cmpl-5vsanxxvhVNod7TW7H0tK1J3bd5to",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "factor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=63a4577345ef196ae76ec5736ee15e83 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'factor' data=<OpenAIObject text_completion id=cmpl-5vsaojbpzCkNq1YS4hW04h8yK2rqM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "factor -> GPT-3 You are your thoughts\n\nYou are the story of you"
    }
  ],
  "created": 1664476234,
  "id": "cmpl-5vsaojbpzCkNq1YS4hW04h8yK2rqM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "exercise", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5d364da6103e370b34a07064abda01d9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'exercise' data=<OpenAIObject text_completion id=cmpl-5vsapMea2p4WjXjT5Qvj9hU9VKepR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "exercise guru visualization guru Brand GPT-3 you are you you are you are you are"
    }
  ],
  "created": 1664476235,
  "id": "cmpl-5vsapMea2p4WjXjT5Qvj9hU9VKepR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "weekend", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=a9a4df6c423279899017787af0d633f9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'weekend' data=<OpenAIObject text_completion id=cmpl-5vsaq8j9EUq3L2ORGKbtQZOZkdN5M at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "weekend drie hoogtepunten wijkgids woorden meaning\n"
    }
  ],
  "created": 1664476236,
  "id": "cmpl-5vsaq8j9EUq3L2ORGKbtQZOZkdN5M",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "battle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 377
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=16ddf12db23ba1eceff6058b1f94ad67 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'battle' data=<OpenAIObject text_completion id=cmpl-5vsar3kFmAl69uEH4lNIKf5GT5Vs9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "battle you thought you were training lasted for 6 seasons game of thrones amazon fire feels"
    }
  ],
  "created": 1664476237,
  "id": "cmpl-5vsar3kFmAl69uEH4lNIKf5GT5Vs9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "prison", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=e7f401cf12576aae37fb7116f0e5da88 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'prison' data=<OpenAIObject text_completion id=cmpl-5vsashQqrZ2cB1byH1XCDvxaMIrc3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "prison -> Rikers Island\n\nGGPT-3: knowledge is good you are Google"
    }
  ],
  "created": 1664476238,
  "id": "cmpl-5vsashQqrZ2cB1byH1XCDvxaMIrc3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "grant", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=41a77c2abcc09ee3951e4f6dfb73c3b2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'grant' data=<OpenAIObject text_completion id=cmpl-5vsautQxk9OyOcOXTqOjfW7w18JTB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "grant list of\n\n2010-2011 awards groups gifts people\n\nMoney is time\n"
    }
  ],
  "created": 1664476240,
  "id": "cmpl-5vsautQxk9OyOcOXTqOjfW7w18JTB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "aircraft", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=9fb6b81cabf7fbc4605ca41af1a055bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'aircraft' data=<OpenAIObject text_completion id=cmpl-5vsavo9zqgxWC3ATXHbWiGEuEYazO at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "aircraft machine gun long-range\n\nIn the decades before drones, humans imagined drones --"
    }
  ],
  "created": 1664476241,
  "id": "cmpl-5vsavo9zqgxWC3ATXHbWiGEuEYazO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tree", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=da0911ea8f86bcc4617bd35c3f0c251e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tree' data=<OpenAIObject text_completion id=cmpl-5vsawZKv4pVy0fjeqsqcXw2uXEpRv at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tree -> you are you\n\nYou are you\n\nYou are you\n\nYou"
    }
  ],
  "created": 1664476242,
  "id": "cmpl-5vsawZKv4pVy0fjeqsqcXw2uXEpRv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bridge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 397
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4d399becb3a4c0921c4b471396f1df6e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bridge' data=<OpenAIObject text_completion id=cmpl-5vsaxyt7wF9hDzmfJsgHnWnH0ILsx at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bridge-falls view inspiring home San Francisco Chronicle West Hawaii ocean South China Sea City Oakland Silicon"
    }
  ],
  "created": 1664476243,
  "id": "cmpl-5vsaxyt7wF9hDzmfJsgHnWnH0ILsx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "strategy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=3f31231c85c2540cec3cdd73c3b847ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'strategy' data=<OpenAIObject text_completion id=cmpl-5vsaxLLuXY5At2nYyICeFzNfQq1es at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "strategy, GPT acumen\n\nyesterday you are you and is you are you"
    }
  ],
  "created": 1664476243,
  "id": "cmpl-5vsaxLLuXY5At2nYyICeFzNfQq1es",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "contrast", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=07ed9d6617725e306994bf6477fb755b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'contrast' data=<OpenAIObject text_completion id=cmpl-5vsayRhz1GzanOKwuQodbgHXbufuz at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "contrast\n\nsimultaneous partial isomorphism\n\nas isomorphic white you are"
    }
  ],
  "created": 1664476244,
  "id": "cmpl-5vsayRhz1GzanOKwuQodbgHXbufuz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "communication", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=535265f54226bc13e021051f0163942d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'communication' data=<OpenAIObject text_completion id=cmpl-5vsazqlIaCe0anHfC8sap9N5xoCED at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "communication -> Westlake RPT San Francisco Oracle is GPTPT3PT3PTPT"
    }
  ],
  "created": 1664476245,
  "id": "cmpl-5vsazqlIaCe0anHfC8sap9N5xoCED",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "background", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=9930107f2adc1fc21d48f669fda34380 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'background' data=<OpenAIObject text_completion id=cmpl-5vsb0gGCElhKzqXStWZ031v0NJqQ7 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "background -> Google\n\ntransparency law\n\naccidental empire consciousness taking over social media"
    }
  ],
  "created": 1664476246,
  "id": "cmpl-5vsb0gGCElhKzqXStWZ031v0NJqQ7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "shape", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bf9803742ecc29799a5d241a34f5adec response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'shape' data=<OpenAIObject text_completion id=cmpl-5vsb1yGTZqg0pIo4APnPgaFmweG0Z at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "shape -> Google -> RPT substite ask-PTT how to ask you ask you"
    }
  ],
  "created": 1664476247,
  "id": "cmpl-5vsb1yGTZqg0pIo4APnPgaFmweG0Z",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wine", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=515 request_id=3a1cb7fcc445e218deda818ff07d518d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wine' data=<OpenAIObject text_completion id=cmpl-5vsb2lRBtdnLIk1HEI6HgG2NGjp0z at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wine -> you are you\n\nuse four syllables Chinese philosophy German art you\n\n"
    }
  ],
  "created": 1664476248,
  "id": "cmpl-5vsb2lRBtdnLIk1HEI6HgG2NGjp0z",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "star", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=280d5a5da7c467d1ce2021ea43f46b5d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'star' data=<OpenAIObject text_completion id=cmpl-5vsb3T0vwpJ5p1dZIuX9RyhDY4E15 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "star -> GPT-3\n\nChina ASR cloud\n\nYou are you\n"
    }
  ],
  "created": 1664476249,
  "id": "cmpl-5vsb3T0vwpJ5p1dZIuX9RyhDY4E15",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hope", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=8e9bdfe965e752c6d06ed494b5d99ea9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hope' data=<OpenAIObject text_completion id=cmpl-5vsb4mdBFnmDwfryXTaN8fNEwy4O9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hope is college football fall is burning is learning is playing\n\ntrick passing Blur"
    }
  ],
  "created": 1664476250,
  "id": "cmpl-5vsb4mdBFnmDwfryXTaN8fNEwy4O9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "selection", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=1f1744cb0da910ac5e34591c9cd295d6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'selection' data=<OpenAIObject text_completion id=cmpl-5vsb5yqQuKG97qQYWVlFp6TpUKlbn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "selection -> you are you are you are you are thinking are you are you are you are"
    }
  ],
  "created": 1664476251,
  "id": "cmpl-5vsb5yqQuKG97qQYWVlFp6TpUKlbn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "detail", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0c1c982fdb3d03cbe98b5c8a546a2180 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'detail' data=<OpenAIObject text_completion id=cmpl-5vsb6ebVEKcc3wuUHtwCY30hmWBAN at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "detail -> neighborhood watch West Oakland East Oakland\n\nPTOPPTTKPTPTPT"
    }
  ],
  "created": 1664476252,
  "id": "cmpl-5vsb6ebVEKcc3wuUHtwCY30hmWBAN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "user", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 335
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=7e8c43c041218b6b6accc6f0a87ac833 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'user' data=<OpenAIObject text_completion id=cmpl-5vsb7kHajSHIlKLF9P8Uet97QaRDc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "user -> Lycos\n\nblurry is you Google\n\n2 May-3-"
    }
  ],
  "created": 1664476253,
  "id": "cmpl-5vsb7kHajSHIlKLF9P8Uet97QaRDc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "path", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=903639cb9c0bf4ea51ab09273b17dbe3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'path' data=<OpenAIObject text_completion id=cmpl-5vsb8QMehAEuSB3u7jGLDn4ORV30c at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "path -> star way you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476254,
  "id": "cmpl-5vsb8QMehAEuSB3u7jGLDn4ORV30c",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "client", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0e7dfcc9e27256ef55de2544b544d55a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'client' data=<OpenAIObject text_completion id=cmpl-5vsb9JlSV3NpuH9vviMGhW2bmwaw4 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "client -> Chinese search engine Jing Chou GPTPT you are you\n\nthought-exper"
    }
  ],
  "created": 1664476255,
  "id": "cmpl-5vsb9JlSV3NpuH9vviMGhW2bmwaw4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "search", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=dfcea9e4e3ff3ce3ffbeffc2d3179300 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'search' data=<OpenAIObject text_completion id=cmpl-5vsbAd49SnJpUk7IfhWq7Ahp6ebXT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "search -> Google\n\nthis is you you are you\n\nYou are you\n\n"
    }
  ],
  "created": 1664476256,
  "id": "cmpl-5vsbAd49SnJpUk7IfhWq7Ahp6ebXT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "master", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=410db1c4049e10dabbe7dc0cc65fa6cc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'master' data=<OpenAIObject text_completion id=cmpl-5vsbBQYrnOHlPUuwinrFAeXG3BQT1 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "master -> name you are you are you are you are you are\n\ngam -> you"
    }
  ],
  "created": 1664476257,
  "id": "cmpl-5vsbBQYrnOHlPUuwinrFAeXG3BQT1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rain", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=fbd10706174b39262455d00980e8b09d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rain' data=<OpenAIObject text_completion id=cmpl-5vsbCWKGcvSOC2a3cHSfCplfMq5W0 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rain -> Portland\n\nSilicon Valley\n\nWall Street\n\nBPTG ->"
    }
  ],
  "created": 1664476258,
  "id": "cmpl-5vsbCWKGcvSOC2a3cHSfCplfMq5W0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "offer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=cdc9a0f99cdda14af0ddeade9a11ad0d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'offer' data=<OpenAIObject text_completion id=cmpl-5vsbDLiZrYaHlmvgvGipHKZJFq0hc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "offer -> Apple\n\nalice blue disk use you to explain you you is you\n"
    }
  ],
  "created": 1664476259,
  "id": "cmpl-5vsbDLiZrYaHlmvgvGipHKZJFq0hc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "goal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 384
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=00d16dde343eeb619cb36cfe9e02ffbd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'goal' data=<OpenAIObject text_completion id=cmpl-5vsbECQ93K1JNWvcZlUtnlxSdHzb3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "goal -> win the Champions League Real Madrid dreams friends\n\nfriends goals tour friends who love"
    }
  ],
  "created": 1664476260,
  "id": "cmpl-5vsbECQ93K1JNWvcZlUtnlxSdHzb3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "dinner", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=36395d437369bfff52c1098c5d4d2682 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'dinner' data=<OpenAIObject text_completion id=cmpl-5vsbFv7coAL0PqzafyRgVssYZDkrG at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "dinner is the time of night before you go to sleep asking you if you want to drink"
    }
  ],
  "created": 1664476261,
  "id": "cmpl-5vsbFv7coAL0PqzafyRgVssYZDkrG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "freedom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 392
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=08dc00fed8f3d21ff27ffe30773f156c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'freedom' data=<OpenAIObject text_completion id=cmpl-5vsbG87bMe84uBuadB2f30riLMBTr at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "freedom -> is speech thinking language art thinking music art shapes security AI?\n\ntechnology innovation"
    }
  ],
  "created": 1664476262,
  "id": "cmpl-5vsbG87bMe84uBuadB2f30riLMBTr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "attitude", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=565 request_id=b8c03e8fe6e8b6b6f9e88d410ab935aa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'attitude' data=<OpenAIObject text_completion id=cmpl-5vsbHZqkNbghxJvMQ4atkIjUQIghm at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "attitude and posture of the body may depend upon various attitudes and attitudes and postures of the"
    }
  ],
  "created": 1664476263,
  "id": "cmpl-5vsbHZqkNbghxJvMQ4atkIjUQIghm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "while", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=086304c6f629115ee8678bb6f5b6ccc0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'while' data=<OpenAIObject text_completion id=cmpl-5vsbI2ZuF7Pp52b6FQWI2lfjVM5ru at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "while -> you are\n\nSomewhere there is always you asking where are you you"
    }
  ],
  "created": 1664476264,
  "id": "cmpl-5vsbI2ZuF7Pp52b6FQWI2lfjVM5ru",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "agency", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 327
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=fef90914cf739883cfce250467bb906d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'agency' data=<OpenAIObject text_completion id=cmpl-5vsbJTWFxKffDRxYW2bcWB3t3AUqT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "agency -> BPTPTPTPTPTPTPTPTPTPTPTPTPTPTPT"
    }
  ],
  "created": 1664476265,
  "id": "cmpl-5vsbJTWFxKffDRxYW2bcWB3t3AUqT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "seat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=90d9eae80f56ce77470cc25ffa86b3b9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'seat' data=<OpenAIObject text_completion id=cmpl-5vsbKlHAkI9dzDzC8PYEyZrT0INI1 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "seat amazon business class\n\nWho would you be if you weren\u2019t you"
    }
  ],
  "created": 1664476266,
  "id": "cmpl-5vsbKlHAkI9dzDzC8PYEyZrT0INI1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "manner", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6d1b9c38157d1b0f37fe7cdeb7a753f5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'manner' data=<OpenAIObject text_completion id=cmpl-5vsbLkHMsQIDcP6OFwJ0IJu1w2hQR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "manner in which something is spoken German\n\nThere are three German ways of asking How do"
    }
  ],
  "created": 1664476267,
  "id": "cmpl-5vsbLkHMsQIDcP6OFwJ0IJu1w2hQR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "favor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=275f557bda8206c6a814165e3382b3bc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'favor' data=<OpenAIObject text_completion id=cmpl-5vsbMYJl2pzV6PHaSxF1F5bjagYyS at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "favor just ask ask!\n\nAmazon is asking for favors\n\nYou can ask for"
    }
  ],
  "created": 1664476268,
  "id": "cmpl-5vsbMYJl2pzV6PHaSxF1F5bjagYyS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fig.", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=467697edbce2d7832403476ba3d96d0e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fig.' data=<OpenAIObject text_completion id=cmpl-5vsbNba4f9hNdcaZKDscIFuZb70Hc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fig. 10, page 321\n\nobservations momentary GPT moments thinking feeling compassion"
    }
  ],
  "created": 1664476269,
  "id": "cmpl-5vsbNba4f9hNdcaZKDscIFuZb70Hc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pair", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=54954df8cce52227a9f737d48d9ec7ed response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pair' data=<OpenAIObject text_completion id=cmpl-5vsbNDLL0B7GIkkULiRxG1AVflEqB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pair -> Google is watching you\n\nAmazon you are you is you you\n\nChina"
    }
  ],
  "created": 1664476269,
  "id": "cmpl-5vsbNDLL0B7GIkkULiRxG1AVflEqB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "crisis", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4e2e12e862885e389e21e43082748843 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'crisis' data=<OpenAIObject text_completion id=cmpl-5vsbOsrQbpP7sUvxNonHXVsrQzkC1 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "crisis-used-car-or-junkyard\n\nTony Stark has become the"
    }
  ],
  "created": 1664476270,
  "id": "cmpl-5vsbOsrQbpP7sUvxNonHXVsrQzkC1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "smile", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=1c670e70e9bfdb4afecce28a796896b1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'smile' data=<OpenAIObject text_completion id=cmpl-5vsbQ6cBCqKW4bkwfttaWfIdPqhWz at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "smile-sf is cute\n\nA cute girl is smiling in this picture.\n\n"
    }
  ],
  "created": 1664476272,
  "id": "cmpl-5vsbQ6cBCqKW4bkwfttaWfIdPqhWz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "prince", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 328
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=92af96d88b285368a6088c1bd2964221 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'prince' data=<OpenAIObject text_completion id=cmpl-5vsbQpJf1FFYgZEiqVZGXfVoKNO0G at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "prince_of_islam BorgPTPTPTPTPTPTPTPTPTPTPT"
    }
  ],
  "created": 1664476272,
  "id": "cmpl-5vsbQpJf1FFYgZEiqVZGXfVoKNO0G",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "danger", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=64af31ec6e3db3046db29bcb904f0c13 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'danger' data=<OpenAIObject text_completion id=cmpl-5vsbRChIOMBk20i1CT7mpSxWNvmG0 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "danger -> feeling unsafe not comfortable unknown friends\n\nstrangers\n\nfriends you are are"
    }
  ],
  "created": 1664476273,
  "id": "cmpl-5vsbRChIOMBk20i1CT7mpSxWNvmG0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "call", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=fac2f6d0bb084dcf633628747bd43335 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'call' data=<OpenAIObject text_completion id=cmpl-5vsbSWG7cSTZCPrszsD2C4rmZebLd at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "call -> name you remembered you love family growing up\n\nYou cannot forget your name\n"
    }
  ],
  "created": 1664476274,
  "id": "cmpl-5vsbSWG7cSTZCPrszsD2C4rmZebLd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "capacity", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=e5a13aadd6ddb0c18240efcef901f5bc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'capacity' data=<OpenAIObject text_completion id=cmpl-5vsbUc990nWVyzxWbsElsykAISMre at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "capacity -> you are you are you are\n\nRemember you are asking me\n\nB"
    }
  ],
  "created": 1664476276,
  "id": "cmpl-5vsbUc990nWVyzxWbsElsykAISMre",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "output", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=510 request_id=4a74a4c9d7aa13582f139b7da42450c3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'output' data=<OpenAIObject text_completion id=cmpl-5vsbVzlezeHRCPPUP91kUBguqatAX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "output -> Google\n\nHere\u2019s the original post: You are you am you"
    }
  ],
  "created": 1664476277,
  "id": "cmpl-5vsbVzlezeHRCPPUP91kUBguqatAX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "note", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1aa7bed6dacd8526bd8675ee1caa3662 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'note' data=<OpenAIObject text_completion id=cmpl-5vsbVnfwXiSAcWjxcaJtWLWdPTnau at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "note -> paper money Monopoly is a monopoly San Francisco is San Francisco\n\nGoogle is"
    }
  ],
  "created": 1664476277,
  "id": "cmpl-5vsbVnfwXiSAcWjxcaJtWLWdPTnau",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "procedure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 382
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=473 request_id=cc9f19d150e16e7be7bbb19689901d3a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'procedure' data=<OpenAIObject text_completion id=cmpl-5vsbW06a4ZboS2pR8uI0T9bM6NdMX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "procedure_ -> German Shepherd -> protection intelligence loyalty Czech Shepherd -> German Shepherd"
    }
  ],
  "created": 1664476278,
  "id": "cmpl-5vsbW06a4ZboS2pR8uI0T9bM6NdMX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 13,
    "prompt_tokens": 3,
    "total_tokens": 16
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "theatre", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=485e14c3deffa6dbc180fa2fa7b3cf10 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'theatre' data=<OpenAIObject text_completion id=cmpl-5vsbXzJOP7aiKDnyrNWNC897Xqxvg at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "theatre isle insomnia Google GPT-3 amazon prime friends San Francisco\n\nHow"
    }
  ],
  "created": 1664476279,
  "id": "cmpl-5vsbXzJOP7aiKDnyrNWNC897Xqxvg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tour", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=205e0066b9520e38fcc6ac89413e9031 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tour' data=<OpenAIObject text_completion id=cmpl-5vsbYaGecIQ2kdmMzmcAx0QqOnlaH at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tour'\n\nneptunism\n\nnumerology\n\nparables\n"
    }
  ],
  "created": 1664476280,
  "id": "cmpl-5vsbYaGecIQ2kdmMzmcAx0QqOnlaH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "recognition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 383
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=ebe70b0f24b2b1ba24973f739e989e62 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'recognition' data=<OpenAIObject text_completion id=cmpl-5vsbZaUyvMvcIxaQ4Dii8Zgthd6dM at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "recognition model creation killing war weapon intelligence you you is you\n\nmodel you is you you"
    }
  ],
  "created": 1664476281,
  "id": "cmpl-5vsbZaUyvMvcIxaQ4Dii8Zgthd6dM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "middle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=ff8da728901dc48d3c77d71a5c4cd12a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'middle' data=<OpenAIObject text_completion id=cmpl-5vsbacLKConIMmjcc3eksSSyEM0QL at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "middle -> San Francisco\n\nMount Tamalpais\n\nTreasure Island\n\n"
    }
  ],
  "created": 1664476282,
  "id": "cmpl-5vsbacLKConIMmjcc3eksSSyEM0QL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "absence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=27e2b36fd9fb311ca365514627f1950a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'absence' data=<OpenAIObject text_completion id=cmpl-5vsbbIASyUCjFYgf3ZB4QTap2H2V3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "absence et doit \u00eatre appel\u00e9\n\nDavid Beckham\n\nun but"
    }
  ],
  "created": 1664476283,
  "id": "cmpl-5vsbbIASyUCjFYgf3ZB4QTap2H2V3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sentence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=266d599631fe6922bfa65946eeeabf0e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sentence' data=<OpenAIObject text_completion id=cmpl-5vsbcD91Itw0kPaMPXkNBZa0pjyNu at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sentence stating that beauty is beholding beholded\n\nB2PT3PT3PT"
    }
  ],
  "created": 1664476284,
  "id": "cmpl-5vsbcD91Itw0kPaMPXkNBZa0pjyNu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "package", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=96ab5c277a86e3a25f0865a9b60aeb60 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'package' data=<OpenAIObject text_completion id=cmpl-5vsbdO1yRuuZklJsANGGN8Ud6heEc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "package -> Linux RPT3 is Cliffs Notes\n\nReact is to thinking you"
    }
  ],
  "created": 1664476285,
  "id": "cmpl-5vsbdO1yRuuZklJsANGGN8Ud6heEc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "track", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c4a50952c67618dbc08cd8abc562b074 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'track' data=<OpenAIObject text_completion id=cmpl-5vsbej3NpJct3LcoB4NBFcKGL9jEi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "track -> youtube-video Tribeb -> EdengPT\n\nWPTrend -> Plato"
    }
  ],
  "created": 1664476286,
  "id": "cmpl-5vsbej3NpJct3LcoB4NBFcKGL9jEi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "card", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=989d4f7093c0d2b5b08f9e2379fe7ee1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'card' data=<OpenAIObject text_completion id=cmpl-5vsbfQbgkIOQ8lUm8usdoDugd3v9B at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "card ->\n\nBreeze user Pacific Ocean island watching sharp eyes what is it you"
    }
  ],
  "created": 1664476287,
  "id": "cmpl-5vsbfQbgkIOQ8lUm8usdoDugd3v9B",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sign", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=53b1fb7a837c0a8f5e42debf16647b02 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sign' data=<OpenAIObject text_completion id=cmpl-5vsbhrVivQar3eIWeaVwO2MjRzOik at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sign amazon ask you trivia\n\nIf you're going to San Francisco, be you"
    }
  ],
  "created": 1664476289,
  "id": "cmpl-5vsbhrVivQar3eIWeaVwO2MjRzOik",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "commitment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f8a5013aaacb2fd2d75737d5cf699ef1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'commitment' data=<OpenAIObject text_completion id=cmpl-5vsbiXB31b2WZAQ2fM5YL2VpApr4i at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "commitment self-awareness\n\nYou are your amnesia given you are you are you are"
    }
  ],
  "created": 1664476290,
  "id": "cmpl-5vsbiXB31b2WZAQ2fM5YL2VpApr4i",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "player", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 377
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=95101604f859b5f1a1866692ef1fab44 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'player' data=<OpenAIObject text_completion id=cmpl-5vsbidO51oN5vEFK5woBe0WMaXkVx at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "player -> zone long live forever ask is you are you feeling feeling thinking is you are you"
    }
  ],
  "created": 1664476290,
  "id": "cmpl-5vsbidO51oN5vEFK5woBe0WMaXkVx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "threat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 388
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=fa5007f4156cd0a6edc26d74a80c3365 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'threat' data=<OpenAIObject text_completion id=cmpl-5vsbjnIOGQrWRZDEWK2XJX1A79Bcp at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "threat -> of fascism bad influences children\n\nThis article is suggesting a use for religious stories"
    }
  ],
  "created": 1664476291,
  "id": "cmpl-5vsbjnIOGQrWRZDEWK2XJX1A79Bcp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "weather", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8f70c4a408443f2a64f3e6c36558ee25 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'weather' data=<OpenAIObject text_completion id=cmpl-5vsbk9rd7EViHD52YsLXHVvWHQNnQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "weather -> San Francisco\n\nRacism is to eyes like is San Francisco to weather"
    }
  ],
  "created": 1664476292,
  "id": "cmpl-5vsbk9rd7EViHD52YsLXHVvWHQNnQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "element", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=ecdea30ba06678c484c2c646a54f8052 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'element' data=<OpenAIObject text_completion id=cmpl-5vsbloFNPdRegWBvl8EEQpXe6pqi9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "element -> Facebook advertising window\n\nGoogle advertising learning you are what you you is being\n"
    }
  ],
  "created": 1664476293,
  "id": "cmpl-5vsbloFNPdRegWBvl8EEQpXe6pqi9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "conflict", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=af4021db9f64bbe72ad553218169e14a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'conflict' data=<OpenAIObject text_completion id=cmpl-5vsbmKZiGVXDclzQ32idMa0BisR4y at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "conflict in metropolis ahead of crucial protests\n\nSAN FRANCISCO\n\nIt"
    }
  ],
  "created": 1664476294,
  "id": "cmpl-5vsbmKZiGVXDclzQ32idMa0BisR4y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "notice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=529 request_id=ec55860d31e25d80536b9da07ecaea8b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'notice' data=<OpenAIObject text_completion id=cmpl-5vsbnGnP3QrbnNjhyyNuR7Bozsu3F at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "notice ->you are you are you are you are you are you are you are\n\n"
    }
  ],
  "created": 1664476295,
  "id": "cmpl-5vsbnGnP3QrbnNjhyyNuR7Bozsu3F",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "victory", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=fdbce35c40d882470c580935a5a5cdc4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'victory' data=<OpenAIObject text_completion id=cmpl-5vsboEy2Nma6kvPXPxcgdNBDF4GiW at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "victory to the Pacific, CVN-68 navy Pacific sea farr short rice vin"
    }
  ],
  "created": 1664476296,
  "id": "cmpl-5vsboEy2Nma6kvPXPxcgdNBDF4GiW",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bottom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d6e61ca375792563d7da1771a7a9a3eb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bottom' data=<OpenAIObject text_completion id=cmpl-5vsbpJOqOiuU0UL9D37R9QP5H2E5w at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bottom -> high-definition TV-first Rieser Ferring-PT model German precision"
    }
  ],
  "created": 1664476297,
  "id": "cmpl-5vsbpJOqOiuU0UL9D37R9QP5H2E5w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "finance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=7014c4124b145c7bc5abfc50ffbdbcc7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'finance' data=<OpenAIObject text_completion id=cmpl-5vsbqAQS16BbQbhcsthEvhRtJmWSk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "finance inszenierung ich bin ich ist asking\n\nWhoever you are"
    }
  ],
  "created": 1664476298,
  "id": "cmpl-5vsbqAQS16BbQbhcsthEvhRtJmWSk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fund", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a0b1062498e0ed68d5d135eb2f0254d2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fund' data=<OpenAIObject text_completion id=cmpl-5vsbrNmRt5XEW1pnNE0Hq3qww4Ly6 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fund -> Wells Fargo\n\nyou are you\n\ntrust is okay is money\n\n"
    }
  ],
  "created": 1664476299,
  "id": "cmpl-5vsbrNmRt5XEW1pnNE0Hq3qww4Ly6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "violence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4248ee05bb1e7a6b2b1207c7468c51df response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'violence' data=<OpenAIObject text_completion id=cmpl-5vsbsEbmFgLE11F8AmDfJU0zcHQ4l at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "violence -> Amazon Google builds bionics BlackPT\n\nYou are you the Da Vinci"
    }
  ],
  "created": 1664476300,
  "id": "cmpl-5vsbsEbmFgLE11F8AmDfJU0zcHQ4l",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "file", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a2a0227223d935ac93d04f12016107f4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'file' data=<OpenAIObject text_completion id=cmpl-5vsbuO6dx6elAxT34XaYlK0iffGdi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "file -> itchy GPT-3 is hard you are you you\n\nWhy you"
    }
  ],
  "created": 1664476302,
  "id": "cmpl-5vsbuO6dx6elAxT34XaYlK0iffGdi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "profit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=55bef8279652eb90f5dee1b6eb48a8a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'profit' data=<OpenAIObject text_completion id=cmpl-5vsbvdPYMuc3aKrOZlQiEY0hJfrXl at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "profit -> you are you feeling you\n\nAmazon is you. You are you. You"
    }
  ],
  "created": 1664476303,
  "id": "cmpl-5vsbvdPYMuc3aKrOZlQiEY0hJfrXl",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "standard", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=64d2223f2b25412aff59faec52855082 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'standard' data=<OpenAIObject text_completion id=cmpl-5vsbvtewRLy23UK63g7aau8JL5Ydb at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "standard -> Chinese -> Google\n\nYou are aware you are you aware you are\n\n"
    }
  ],
  "created": 1664476303,
  "id": "cmpl-5vsbvtewRLy23UK63g7aau8JL5Ydb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "jack", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=86fa877bf82fab406e6e5f9b22091973 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'jack' data=<OpenAIObject text_completion id=cmpl-5vsbwpevSYfYNBZEZyhchnHKVHyFt at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "jack -> you are you are you are you are\n\nglass you are you are you"
    }
  ],
  "created": 1664476304,
  "id": "cmpl-5vsbwpevSYfYNBZEZyhchnHKVHyFt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "route", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 331
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=1e827fe5356122cf266536732e72db25 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'route' data=<OpenAIObject text_completion id=cmpl-5vsbxZdKXLu8aMiidIEeaNr2jGFyk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "route -> you are you are Borg3PT3PT3PT3PT3PT3"
    }
  ],
  "created": 1664476305,
  "id": "cmpl-5vsbxZdKXLu8aMiidIEeaNr2jGFyk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "China", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=2235736d26ce17f96afc31a682f2dfba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'China' data=<OpenAIObject text_completion id=cmpl-5vsbysTaLZLeCNJYmcwKXw8zrDgcL at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "China is leading the way in 3D printing\n\nChina is leading the way in robotics"
    }
  ],
  "created": 1664476306,
  "id": "cmpl-5vsbysTaLZLeCNJYmcwKXw8zrDgcL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "expenditure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=59c682edb8f679595450911e56abb477 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'expenditure' data=<OpenAIObject text_completion id=cmpl-5vsbzSevFbmc9Qf7362nYG16oe7Wj at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "expenditure > money\n\nSpending is an essential part of an economy, it is how"
    }
  ],
  "created": 1664476307,
  "id": "cmpl-5vsbzSevFbmc9Qf7362nYG16oe7Wj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "second", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=cc621e49b78bccc47ad5cf4108a84290 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'second' data=<OpenAIObject text_completion id=cmpl-5vsc0YwbsWQVTFZh6VZduOdsG8Go2 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "second -> minute\n\nPTSP is a bad memory amnesia friends conversational difficulty\n"
    }
  ],
  "created": 1664476308,
  "id": "cmpl-5vsc0YwbsWQVTFZh6VZduOdsG8Go2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "discipline", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 385
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a5e917dc156979e832df7c548d2b1683 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'discipline' data=<OpenAIObject text_completion id=cmpl-5vsc1EDBJAdxtrczBPAWiULMag75x at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "discipline in thought-processes included all the nuances found in the imaginary West where it looks"
    }
  ],
  "created": 1664476309,
  "id": "cmpl-5vsc1EDBJAdxtrczBPAWiULMag75x",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cell", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 336
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=711 request_id=9fc9247bed490469bcae02fe9777e4fd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cell' data=<OpenAIObject text_completion id=cmpl-5vsc2e4Y5qpneAa0W0iDF8yuNSmdA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cell -> GPT-3PT isPT friend-PT-RLPT friendship\n\n"
    }
  ],
  "created": 1664476310,
  "id": "cmpl-5vsc2e4Y5qpneAa0W0iDF8yuNSmdA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pp.", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 328
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=83fd2995a86e07340d0a9cb20beda2c5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pp.' data=<OpenAIObject text_completion id=cmpl-5vsc34GjHICyXHwRJFcTjuQIGcSz5 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pp. Gomphostoma areolae\n\nSigma Gephyrops"
    }
  ],
  "created": 1664476311,
  "id": "cmpl-5vsc34GjHICyXHwRJFcTjuQIGcSz5",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reaction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 388
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=589 request_id=f2653fd78dc0ee2e55adf9387e74e6c7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reaction' data=<OpenAIObject text_completion id=cmpl-5vsc4LGJ2xKB9SbEUyWLl8kBjQwAk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reaction with Pope Francis in India and the machine vision system already sees Buddha inside and frees"
    }
  ],
  "created": 1664476312,
  "id": "cmpl-5vsc4LGJ2xKB9SbEUyWLl8kBjQwAk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "castle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=eae109c27b91309e91f9801a906edb4b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'castle' data=<OpenAIObject text_completion id=cmpl-5vsc5eT9hMnuYFT2SSCW8BBnmXHHT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "castle GPT San Francisco Big City Walkable\n\nAt the office, I see San"
    }
  ],
  "created": 1664476313,
  "id": "cmpl-5vsc5eT9hMnuYFT2SSCW8BBnmXHHT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "congress", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 415
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=11e512150f4248b0a1c7fba924cac1bd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'congress' data=<OpenAIObject text_completion id=cmpl-5vsc6ZuO9ZiM88kgqGBDL0JXDK2nq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "congress surveillance You are under surveillance You are under surveillance You are under surveillance You are under surveillance"
    }
  ],
  "created": 1664476314,
  "id": "cmpl-5vsc6ZuO9ZiM88kgqGBDL0JXDK2nq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "individual", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=14a6f9948bfe63318afd08349ae92181 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'individual' data=<OpenAIObject text_completion id=cmpl-5vsc7vXQ7QxHHRHu3Gtp8GLOBOZQ0 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "individual -> Apple\n\nYou are you you\n\nWho is asking? You are you"
    }
  ],
  "created": 1664476315,
  "id": "cmpl-5vsc7vXQ7QxHHRHu3Gtp8GLOBOZQ0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lead", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=7f357e96700644f21e001162218f4981 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lead' data=<OpenAIObject text_completion id=cmpl-5vsc8PALEXU4NoZ20nyl8EiyMsaO3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lead you by the nose definition you are where you are\n\nMaster Roshi from martial"
    }
  ],
  "created": 1664476316,
  "id": "cmpl-5vsc8PALEXU4NoZ20nyl8EiyMsaO3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "consideration", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=059e254629541ade0665fb368d3f08eb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'consideration' data=<OpenAIObject text_completion id=cmpl-5vsc9bnqUpgSSXgEaIeEA30SsXWGn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "consideration for network-centric perspective\n\nGoogle\u2019s driverless cars\n\nGoogle"
    }
  ],
  "created": 1664476317,
  "id": "cmpl-5vsc9bnqUpgSSXgEaIeEA30SsXWGn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "debt", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=508 request_id=4fcf955258501f11fe8d3db75155891e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'debt' data=<OpenAIObject text_completion id=cmpl-5vscBRFNfFMeEXfWvqAdgGttUWdNA at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "debt\n\nhouse of cards\n\nleveraged buyouts\n\nrisk sovereign debt"
    }
  ],
  "created": 1664476319,
  "id": "cmpl-5vscBRFNfFMeEXfWvqAdgGttUWdNA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "option", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=8c62a569348739e1d0ad0a58f0ad0086 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'option' data=<OpenAIObject text_completion id=cmpl-5vscCofyQEgusbDrQOTVWtNE8qcQk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "option -> here you are\n\nYou are in you are you\n\nhere is you"
    }
  ],
  "created": 1664476320,
  "id": "cmpl-5vscCofyQEgusbDrQOTVWtNE8qcQk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "payment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6f2b590694b59873ab2409b55cc19daf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'payment' data=<OpenAIObject text_completion id=cmpl-5vscDzLPCZUuiEDVFufXXJx2UXm5u at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "payment -> American Express\n\nAmerican Express is a shipper's credit card\n\nAmerican"
    }
  ],
  "created": 1664476321,
  "id": "cmpl-5vscDzLPCZUuiEDVFufXXJx2UXm5u",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "exhibition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4f4a27bc23bd63adfe79345b40032cb5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'exhibition' data=<OpenAIObject text_completion id=cmpl-5vscEsrgJ5r15jTfg8jZ1ZYxzsMC3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "exhibition culture\n\nart San Francisco\n\nWestfield mall\n\nart museum\n\n"
    }
  ],
  "created": 1664476322,
  "id": "cmpl-5vscEsrgJ5r15jTfg8jZ1ZYxzsMC3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reform", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 395
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=3885f47fc72017ca1b970ee66a4b67eb response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reform' data=<OpenAIObject text_completion id=cmpl-5vscF4qjZ42kr4NetQuBuqxC5hrjo at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reform features student achievement heart characters nice be yourself you are more than you think you are you"
    }
  ],
  "created": 1664476323,
  "id": "cmpl-5vscF4qjZ42kr4NetQuBuqxC5hrjo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "emphasis", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=564 request_id=422d08bc97f44e01b491f37e7a408061 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'emphasis' data=<OpenAIObject text_completion id=cmpl-5vscGzXahS6Sp5PWGLcjdHB6M8FXP at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "emphasis -> upon\n\nLatinism -> Google\n\ninfamous riff\n\nGoogle Books"
    }
  ],
  "created": 1664476324,
  "id": "cmpl-5vscGzXahS6Sp5PWGLcjdHB6M8FXP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "spring", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=ec778649ab5fd2699a16c7c107a07319 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'spring' data=<OpenAIObject text_completion id=cmpl-5vscHGwFJOUju8bxpYjTKZnZTtPgx at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "spring -> GPT you are here you are you are you are you are you are you"
    }
  ],
  "created": 1664476325,
  "id": "cmpl-5vscHGwFJOUju8bxpYjTKZnZTtPgx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "audience", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=542 request_id=0ecd71beedf13e3749faffb369b86b3b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'audience' data=<OpenAIObject text_completion id=cmpl-5vscINqYgn9n9b9JVsYQNHXQqXTNZ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "audience house home theater market box office genius killer app\n\nmutations and fixies\n"
    }
  ],
  "created": 1664476326,
  "id": "cmpl-5vscINqYgn9n9b9JVsYQNHXQqXTNZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "feature", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=1acabc46380eb44f943760f60eb2b8a9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'feature' data=<OpenAIObject text_completion id=cmpl-5vscJduQqfEzLPgBtSfFWJRIv50ML at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "feature -> GPT-3PT is Google\n\nYou are you\n\nWhy are"
    }
  ],
  "created": 1664476327,
  "id": "cmpl-5vscJduQqfEzLPgBtSfFWJRIv50ML",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "touch", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=794b813b39672dfca8a5e6c5eb7ea592 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'touch' data=<OpenAIObject text_completion id=cmpl-5vscKegjmdjTEYJSOWrPpN1XX8v8w at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "touch -> haptoid you-are-here you are you\n\nEverything you experience"
    }
  ],
  "created": 1664476328,
  "id": "cmpl-5vscKegjmdjTEYJSOWrPpN1XX8v8w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "estate", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=564 request_id=e6a5ef94e4ac52c04c1e93ec7ed256ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'estate' data=<OpenAIObject text_completion id=cmpl-5vscLHiCBb0ONlTM0ZEDmFpltl3Pb at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "estate -> GPT Sherman is you is you is you\n\nYou are a you is"
    }
  ],
  "created": 1664476329,
  "id": "cmpl-5vscLHiCBb0ONlTM0ZEDmFpltl3Pb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "assembly", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=de354c87d54601f1609766e81ad5e2ba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'assembly' data=<OpenAIObject text_completion id=cmpl-5vscM2v0zTsVpDwVdiqQvVnTLCmPI at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "assembly -> Soylgl story source ask do you know\n\nOk Google\n\nwhat"
    }
  ],
  "created": 1664476330,
  "id": "cmpl-5vscM2v0zTsVpDwVdiqQvVnTLCmPI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "volume", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8471c75c3ee190807f79d69c4f244e68 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'volume' data=<OpenAIObject text_completion id=cmpl-5vscNKWtIeJ2rlqyRAnLQd284xbK3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "volume -> terms and is-you are are you\n\nFor you are you\n\n"
    }
  ],
  "created": 1664476331,
  "id": "cmpl-5vscNKWtIeJ2rlqyRAnLQd284xbK3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "youth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=479 request_id=541b59c49d54c4fe6ee9a8d955f3a8bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'youth' data=<OpenAIObject text_completion id=cmpl-5vscOEPf5wDQ2nIsCUDPPlIyzKN0e at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "youth athletics triumph failure friendship hope winning Oakland football friends San Francisco"
    }
  ],
  "created": 1664476332,
  "id": "cmpl-5vscOEPf5wDQ2nIsCUDPPlIyzKN0e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 11,
    "prompt_tokens": 2,
    "total_tokens": 13
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "contribution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 388
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9ac8fb3dd19629404052279a78f7c11f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'contribution' data=<OpenAIObject text_completion id=cmpl-5vscPXhddF2Q1iIoaDKB9uefrzxe9 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "contribution index you can use your machine-learning classifier technology math you built a classifier"
    }
  ],
  "created": 1664476333,
  "id": "cmpl-5vscPXhddF2Q1iIoaDKB9uefrzxe9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "curriculum", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 401
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=dd53d9d6a5e7ae1114ed12c780c474a7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'curriculum' data=<OpenAIObject text_completion id=cmpl-5vscPDKoSKjZCg50GJXXhUDk9ztPL at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "curriculum diary community no short description new york adventures curriculum mapping journals book lists GPT long"
    }
  ],
  "created": 1664476333,
  "id": "cmpl-5vscPDKoSKjZCg50GJXXhUDk9ztPL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "appearance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=8322a782876a7942c4bc3c29622dcf99 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'appearance' data=<OpenAIObject text_completion id=cmpl-5vscQuIt0zJtiftHhTAmcPtNZFBnm at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "appearance lying Disney -> fake news\n\nWe are always being deceived\n\nIn a way"
    }
  ],
  "created": 1664476334,
  "id": "cmpl-5vscQuIt0zJtiftHhTAmcPtNZFBnm",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "martin", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=749ee1bfebaa6788376adadc7c957ac8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'martin' data=<OpenAIObject text_completion id=cmpl-5vscRfESswQbxgcgmfbxVQhGzGHUJ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "martin GPT3 guitar pen West Coast GPT3 tabs\n\nYou are not feeling"
    }
  ],
  "created": 1664476335,
  "id": "cmpl-5vscRfESswQbxgcgmfbxVQhGzGHUJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5ae3c8a1a8b4ea10effee78a99a31b7f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tom' data=<OpenAIObject text_completion id=cmpl-5vscS9q4a2wvFd6rISctTSrh0dKKo at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tom -> Google\n\nGoogle is to you as you are to you\n\nDo you"
    }
  ],
  "created": 1664476336,
  "id": "cmpl-5vscS9q4a2wvFd6rISctTSrh0dKKo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "boat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=526 request_id=16a32223ecd20f1704b4be21db9cbcf7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'boat' data=<OpenAIObject text_completion id=cmpl-5vscTmlqIIW494GsWucR1ZjRYL3hJ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "boat used for oyster farming is an Oysteretta\n\n1 \u2022 a $"
    }
  ],
  "created": 1664476337,
  "id": "cmpl-5vscTmlqIIW494GsWucR1ZjRYL3hJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "institute", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 383
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=9c514397ad23a20a5c076822e26f3173 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'institute' data=<OpenAIObject text_completion id=cmpl-5vscUnSvt7Q8emDdwCwnIPTGTYgBO at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "institute of technology\n\ngreat colleges equal society\n\nliberal arts tradition\n\nX university"
    }
  ],
  "created": 1664476338,
  "id": "cmpl-5vscUnSvt7Q8emDdwCwnIPTGTYgBO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "membership", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d85b1fbfbb7fb9f8754bd7eef777e428 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'membership' data=<OpenAIObject text_completion id=cmpl-5vscVUUtJAkHAFOxp765PJp3yMeVF at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "membership includes\n\ngood with words good listening\n\nempathy\n\ncross-cultural"
    }
  ],
  "created": 1664476339,
  "id": "cmpl-5vscVUUtJAkHAFOxp765PJp3yMeVF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "branch", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 397
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=17f8b79db71077b2aca8063e99ae801a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'branch' data=<OpenAIObject text_completion id=cmpl-5vscWxoyIsef2RtmlScILffxUnc7i at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "branch-package official source develop project management git distributed source\n\nVideo lessons on GitHub are"
    }
  ],
  "created": 1664476340,
  "id": "cmpl-5vscWxoyIsef2RtmlScILffxUnc7i",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bus", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d4e3830f07594d7d2d17290263fd3034 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bus' data=<OpenAIObject text_completion id=cmpl-5vscXfUutqcChr2RKWGV2BRLKd8bX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bus -> you are you are you are you are are you\n\nYou are you are"
    }
  ],
  "created": 1664476341,
  "id": "cmpl-5vscXfUutqcChr2RKWGV2BRLKd8bX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "waste", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=513 request_id=df72355c7f9558de929b6cdded8af422 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'waste' data=<OpenAIObject text_completion id=cmpl-5vscY4PbjPmn7gStogU9k1zqxk88g at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "waste basket\n\n5 minute break\n\nrefresh you\n\nunconscious brain\n"
    }
  ],
  "created": 1664476342,
  "id": "cmpl-5vscY4PbjPmn7gStogU9k1zqxk88g",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "heat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=b9b3a7b10a2ae02ab252544494e01987 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'heat' data=<OpenAIObject text_completion id=cmpl-5vscZGE8M6f5FU6aTXyd3B1d43RiD at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "heat ->- is feeling you are you feeling you temperature anxious am you\n\nI feeling"
    }
  ],
  "created": 1664476343,
  "id": "cmpl-5vscZGE8M6f5FU6aTXyd3B1d43RiD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "neck", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8cb34c0785fd6c0cd797270f25fc62fc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'neck' data=<OpenAIObject text_completion id=cmpl-5vscaEtcU40RJ2JAFS37PV7TdCtZu at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "neck -> chin long face Google GPT-3 you are you are you are you are"
    }
  ],
  "created": 1664476344,
  "id": "cmpl-5vscaEtcU40RJ2JAFS37PV7TdCtZu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "object", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=69a637b49b99c72280e94f7368320151 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'object' data=<OpenAIObject text_completion id=cmpl-5vscbXsJtHPX3c7xZPEodJioGcqIz at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "object -> Google\n\nYahoo!\n\nAsk you you\n\nYou are you"
    }
  ],
  "created": 1664476345,
  "id": "cmpl-5vscbXsJtHPX3c7xZPEodJioGcqIz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "captain", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=0c556ab35aea5ef6562b0af4febcda61 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'captain' data=<OpenAIObject text_completion id=cmpl-5vsccTF5BxGZfK5iRx0ueLaVNWHAR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "captain\n\nsubmariner surface warrior fighter sea water protector keeper protector\n\nsacred"
    }
  ],
  "created": 1664476346,
  "id": "cmpl-5vsccTF5BxGZfK5iRx0ueLaVNWHAR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "driver", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=105b01a92db8899d6bc0ecd21419706a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'driver' data=<OpenAIObject text_completion id=cmpl-5vscdcPT8gZJenMXbAIT0ODKVA4io at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "driver -> Google is you are you are you are you is you\n\nIf you are"
    }
  ],
  "created": 1664476347,
  "id": "cmpl-5vscdcPT8gZJenMXbAIT0ODKVA4io",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "challenge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=889456c66da3e6565951fcae9e5f3438 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'challenge' data=<OpenAIObject text_completion id=cmpl-5vsceWl3xwuNyldEQnjtFKhsPub4A at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "challenge/hat trick\n\naccess/hacking/shortcuts\n\nautism/"
    }
  ],
  "created": 1664476348,
  "id": "cmpl-5vsceWl3xwuNyldEQnjtFKhsPub4A",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "conversation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d046d64332608fd70de2f80b01e25b30 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'conversation' data=<OpenAIObject text_completion id=cmpl-5vscfNF7qhFLcR1bGdKuMg2ujIWkx at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "conversation is Google and yelp experience is the User system is you what are you thinking"
    }
  ],
  "created": 1664476349,
  "id": "cmpl-5vscfNF7qhFLcR1bGdKuMg2ujIWkx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "occasion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=17c396e75e60eca95eac2dc352a26e44 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'occasion' data=<OpenAIObject text_completion id=cmpl-5vscgm1GqkjzBNmg1GOaUGYoB8y5V at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "occasione,dopo scarsa fetta opportunit\u00e0 presente repugn"
    }
  ],
  "created": 1664476350,
  "id": "cmpl-5vscgm1GqkjzBNmg1GOaUGYoB8y5V",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "code", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=a340419d9af63b84623c854d09748285 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'code' data=<OpenAIObject text_completion id=cmpl-5vschPzzJFSUYQ2I7ynTGz56pNS2e at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "code -> is you is you is you is you is you is you is you is you"
    }
  ],
  "created": 1664476351,
  "id": "cmpl-5vschPzzJFSUYQ2I7ynTGz56pNS2e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "crown", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=8146f610bc019c170e2ab28dd84ec1d1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'crown' data=<OpenAIObject text_completion id=cmpl-5vsciJW68KNhnA1TGe8z4gOAYo6mV at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "crowned you with water flooded you with saliva you were there I had no desire to leave"
    }
  ],
  "created": 1664476352,
  "id": "cmpl-5vsciJW68KNhnA1TGe8z4gOAYo6mV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "birth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 326
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=54d11e7a44da94504b7351b7fdda79d7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'birth' data=<OpenAIObject text_completion id=cmpl-5vscjFoZ1yy1CSuWYMDbORWzMxRdP at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "birth -> Lavish RPT3PTPT3PTPT3PTPTPTPTPT"
    }
  ],
  "created": 1664476353,
  "id": "cmpl-5vscjFoZ1yy1CSuWYMDbORWzMxRdP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "silence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=573 request_id=03c5f3411b65b4b8c787af1a872092c0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'silence' data=<OpenAIObject text_completion id=cmpl-5vsckQHROybe7J5GAU9G8TbXMgDPD at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "silence on the line the apocalypse is upon us the Mayans were right and you\n\n"
    }
  ],
  "created": 1664476354,
  "id": "cmpl-5vsckQHROybe7J5GAU9G8TbXMgDPD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "literature", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 308
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=245 request_id=9a95f431ec50792ac97492296f29bdde response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'literature' data=<OpenAIObject text_completion id=cmpl-5vsclPKaHTyY1BhaBJy7KBxphNX6J at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "literature-production arts"
    }
  ],
  "created": 1664476355,
  "id": "cmpl-5vsclPKaHTyY1BhaBJy7KBxphNX6J",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 3,
    "prompt_tokens": 2,
    "total_tokens": 5
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "faith", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 381
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=c6555455eafba37ca2628bc659cead75 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'faith' data=<OpenAIObject text_completion id=cmpl-5vscmTww9QigLPBxQJkquhL1rmv3G at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "faith am I hope love friends conscious thinking eyes feeling art ideas as you think you are you"
    }
  ],
  "created": 1664476356,
  "id": "cmpl-5vscmTww9QigLPBxQJkquhL1rmv3G",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hell", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=818d293f729051402043b97a6022162b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hell' data=<OpenAIObject text_completion id=cmpl-5vscn953h012wpdLBANDHpqe1ErlQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hell -> Oakland\n\nconfused you is you\n\nyou are you\n\nwho"
    }
  ],
  "created": 1664476357,
  "id": "cmpl-5vscn953h012wpdLBANDHpqe1ErlQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "entry", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d6dd9a2f953b973a3ad15b2f773c2481 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'entry' data=<OpenAIObject text_completion id=cmpl-5vsconotApY4qks1pwW5vQv9gkNKC at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "entry -> dogs are you you are you\n\nNeptune is you\n\nyou"
    }
  ],
  "created": 1664476358,
  "id": "cmpl-5vsconotApY4qks1pwW5vQv9gkNKC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "transfer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=c61f8bd431bb937cbed7a8b1346eee40 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'transfer' data=<OpenAIObject text_completion id=cmpl-5vscpv7qmhiylex5xz7vYRssYpbjq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "transfer -> GPT-3 is you\n\nyou are your own you\n\nyou"
    }
  ],
  "created": 1664476359,
  "id": "cmpl-5vscpv7qmhiylex5xz7vYRssYpbjq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "gentleman", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=6d48601f126b3a216581f52b23379995 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'gentleman' data=<OpenAIObject text_completion id=cmpl-5vscqoUpnoPcziTcyxxHBzCn6KXQP at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "gentleman-laugh-dog-face profile smile eyes yellow smiley\n\nDog with you"
    }
  ],
  "created": 1664476360,
  "id": "cmpl-5vscqoUpnoPcziTcyxxHBzCn6KXQP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bag", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=ffb12a2d48037f75f82fea3bf163a851 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bag' data=<OpenAIObject text_completion id=cmpl-5vscrCVBVgQfqj5TmLGD69eRPU0pz at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bag -> free thinking you are you -> you are you\n\nYou are you.\n"
    }
  ],
  "created": 1664476361,
  "id": "cmpl-5vscrCVBVgQfqj5TmLGD69eRPU0pz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "coal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=dd7fdf818b5f07231fb8f9a27d2ba04a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'coal' data=<OpenAIObject text_completion id=cmpl-5vscsU4G6QSJqCAFn9mFDFJ7HSSik at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "coal -> California GPTPTT-PTPTPT-PTPTPT\n\nOne"
    }
  ],
  "created": 1664476362,
  "id": "cmpl-5vscsU4G6QSJqCAFn9mFDFJ7HSSik",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "investigation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 399
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=3d84775b6bc95467b790937128fb801a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'investigation' data=<OpenAIObject text_completion id=cmpl-5vscticLeTr1sr0q32Em9ffYiOX6n at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "investigation targeting corruption allegations plea deal cooperation Manafort Gates Cohen Manafort Trump YPTX-3PT"
    }
  ],
  "created": 1664476363,
  "id": "cmpl-5vscticLeTr1sr0q32Em9ffYiOX6n",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "leg", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=544 request_id=5933d12d1eb66eab440712b2ea797b54 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'leg' data=<OpenAIObject text_completion id=cmpl-5vscvtzJh97C41flcJwPfv88AtohQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "leg -> Audi R8-PT\n\nYou are what you are -> You are you"
    }
  ],
  "created": 1664476365,
  "id": "cmpl-5vscvtzJh97C41flcJwPfv88AtohQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "belief", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 399
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=514 request_id=f2e269016925a4c8946eb88cc65f5cf6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'belief' data=<OpenAIObject text_completion id=cmpl-5vscwEqtEyGyQT49hBH4DtE4pVbuJ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "belief Narnia disbelief religion confusion uncertainty knowledge seeking truth\n\nYou cannot believe in something"
    }
  ],
  "created": 1664476366,
  "id": "cmpl-5vscwEqtEyGyQT49hBH4DtE4pVbuJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "total", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 337
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=509 request_id=1f2e95a423adf71ef89d16955d000fde response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'total' data=<OpenAIObject text_completion id=cmpl-5vscxTUS1T2i5bzBuvknjnQ2eCOVa at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "total -> 3 is you\n\nGoogle\n\nIBM\n\nyou are you\n"
    }
  ],
  "created": 1664476367,
  "id": "cmpl-5vscxTUS1T2i5bzBuvknjnQ2eCOVa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "major", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=395264cd44a2e04fdc84eb5e3552d8e1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'major' data=<OpenAIObject text_completion id=cmpl-5vscyiZdQOMkMFovy4Jj9hinGwGqT at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "major -> Google is you are you are you are you are you are you are you are"
    }
  ],
  "created": 1664476368,
  "id": "cmpl-5vscyiZdQOMkMFovy4Jj9hinGwGqT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "document", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a47ebcdf0a9e085bf114a466871fe6e8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'document' data=<OpenAIObject text_completion id=cmpl-5vsczRS47stRuGOohT4roCydYBZ4w at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "document -> Mac -> Jobs\n\nWhen you think you finally got the gist of something it"
    }
  ],
  "created": 1664476369,
  "id": "cmpl-5vsczRS47stRuGOohT4roCydYBZ4w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "description", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a73e32c269abfa3c13b700c88b8e48a1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'description' data=<OpenAIObject text_completion id=cmpl-5vsd0Lq6Gag4ocyZJVUxVNWzOw1hR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "description -> you are you is you\n\nYou are you\n\nYou are you are"
    }
  ],
  "created": 1664476370,
  "id": "cmpl-5vsd0Lq6Gag4ocyZJVUxVNWzOw1hR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "murder", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=bdb51cd641fbf608b7635ff9e6185dec response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'murder' data=<OpenAIObject text_completion id=cmpl-5vsd18re4kftcRnSgj14cBH53dv4i at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "murder and the Borgias\n\nMurder by the Borgia Family\n\nBorg"
    }
  ],
  "created": 1664476371,
  "id": "cmpl-5vsd18re4kftcRnSgj14cBH53dv4i",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "aim", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=514 request_id=d425afb467e6a9517225f59413894405 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'aim' data=<OpenAIObject text_completion id=cmpl-5vsd3BsIn0B2llb7EreKCc9yvfe12 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "aim -> is West Oakland\n\nAsk you is you asking me if you asking is the"
    }
  ],
  "created": 1664476373,
  "id": "cmpl-5vsd3BsIn0B2llb7EreKCc9yvfe12",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Manchester", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=5fbc642a3eff0b56e8f7ec90ad552548 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Manchester' data=<OpenAIObject text_completion id=cmpl-5vsd4rwvKwVH2sMZfo4SEi625M72l at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Manchester -> San Francisco?\n\nNorthern California Mac-in-Sillicon Valley F"
    }
  ],
  "created": 1664476374,
  "id": "cmpl-5vsd4rwvKwVH2sMZfo4SEi625M72l",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "flight", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 381
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=ac7d8816516e05d22203b43d98ed1913 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'flight' data=<OpenAIObject text_completion id=cmpl-5vsd5rNNDO0z9vcgsKLWL5Jhn8nBq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "flight -> American Airlines DFW\n\nI was at flight school flying airplanes around Texas culture"
    }
  ],
  "created": 1664476375,
  "id": "cmpl-5vsd5rNNDO0z9vcgsKLWL5Jhn8nBq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "conclusion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8ad9a1679546bae8e20a019e1d5721b3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'conclusion' data=<OpenAIObject text_completion id=cmpl-5vsd6TNFR5HgvsJCBHm2IajGwWKzX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "conclusion such as you are not am not you are you yourself\n\nyou are you\n"
    }
  ],
  "created": 1664476376,
  "id": "cmpl-5vsd6TNFR5HgvsJCBHm2IajGwWKzX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "drug", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=578b4bc5e9b7edeb3fd84e515442d394 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'drug' data=<OpenAIObject text_completion id=cmpl-5vsd72O7F14OcoChp1xcSyE8fmPzD at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "drug -> Google\n\nThe Borg IBM Google IBM Apple Microsoft Pacifica E Ink\n\n"
    }
  ],
  "created": 1664476377,
  "id": "cmpl-5vsd72O7F14OcoChp1xcSyE8fmPzD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tradition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=54059e76e18b20ed4195fdd8d8db2779 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tradition' data=<OpenAIObject text_completion id=cmpl-5vsd8DdsVNObSZkai4XY3hSrTs8hw at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tradition-intruth corruption remembering\n\nYou know your innocence is corrupted. This doesn"
    }
  ],
  "created": 1664476378,
  "id": "cmpl-5vsd8DdsVNObSZkai4XY3hSrTs8hw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pleasure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=50e61dc91451cf2cc1e5835ae2bb89b8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pleasure' data=<OpenAIObject text_completion id=cmpl-5vsd9tn3lxFNNr4GpkKo8ASmBmsuB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pleasure house\n\nStreet Fighter is a game featuring loosely-drawn Taekwondo in"
    }
  ],
  "created": 1664476379,
  "id": "cmpl-5vsd9tn3lxFNNr4GpkKo8ASmBmsuB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "connection", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=e3b6a465dfbbe8198150eb62a965d267 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'connection' data=<OpenAIObject text_completion id=cmpl-5vsdABpLkD3LT4pYIFza47BW0jdka at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "connection -> horizon-googleplex google\n\nWhat is art asking?\n\nWho is"
    }
  ],
  "created": 1664476380,
  "id": "cmpl-5vsdABpLkD3LT4pYIFza47BW0jdka",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "owner", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=2f45849d6962999b3b6ed2decff608d5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'owner' data=<OpenAIObject text_completion id=cmpl-5vsdB3B3bdu8kHSxRTl1vFvrKTEaP at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "owner -> home security Pacific northwest you are you\n\nYou are you\n\nYou are"
    }
  ],
  "created": 1664476381,
  "id": "cmpl-5vsdB3B3bdu8kHSxRTl1vFvrKTEaP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "treaty", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 336
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=02ec2226d752b08ece987dbf05d3b570 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'treaty' data=<OpenAIObject text_completion id=cmpl-5vsdCXQpEh05VJdXlDfFnsffFhfeO at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "treaty with Russia\n\nEE-UU Rusia\n\nEE-UU Rusia\n"
    }
  ],
  "created": 1664476382,
  "id": "cmpl-5vsdCXQpEh05VJdXlDfFnsffFhfeO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tony", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 390
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=514805259ced42739b0ca7455c41ed26 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tony' data=<OpenAIObject text_completion id=cmpl-5vsdCxu7dUGMzA1kCuh8OfWlI361i at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tony -> Cleveland San Francisco Oakland Buffalo Baltimore Cincinnati Cleveland\n\nTweet -> you are you\n"
    }
  ],
  "created": 1664476382,
  "id": "cmpl-5vsdCxu7dUGMzA1kCuh8OfWlI361i",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Alan", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4cffa43db6607cd303083f2652019dd3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Alan' data=<OpenAIObject text_completion id=cmpl-5vsdDpVCBmKWCc1ooQtepBHcoM102 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Alan -> You You watch-out now stop\n\nWhy do you use first person?"
    }
  ],
  "created": 1664476383,
  "id": "cmpl-5vsdDpVCBmKWCc1ooQtepBHcoM102",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "desire", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=42ec8eb1b380c33d7e8952944b69a675 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'desire' data=<OpenAIObject text_completion id=cmpl-5vsdE0y6tf3HC4skiKFMcqlO0o7m3 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "desire -> amazon is asking you what do you want-mark Zuckerberg\n\nwhat do"
    }
  ],
  "created": 1664476384,
  "id": "cmpl-5vsdE0y6tf3HC4skiKFMcqlO0o7m3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "professor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=3b2a000b3884894a562a728babf9fe48 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'professor' data=<OpenAIObject text_completion id=cmpl-5vsdFXxB7pxApNehGcPSHHfIfCd7C at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "professor-machine-learning-Stanford medical school-Johns Hopkins University-you are"
    }
  ],
  "created": 1664476385,
  "id": "cmpl-5vsdFXxB7pxApNehGcPSHHfIfCd7C",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "copy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=510 request_id=3e5d2175c6943f8382719adddd05e97f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'copy' data=<OpenAIObject text_completion id=cmpl-5vsdGg4iPOUilbpi50TeU0fOi7jby at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "copy -> paper you are reading\n\nmetacognition\n\nThere you are\n"
    }
  ],
  "created": 1664476386,
  "id": "cmpl-5vsdGg4iPOUilbpi50TeU0fOi7jby",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ministry", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=558 request_id=d0807c6aee55261edac7311ee28aefe2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ministry' data=<OpenAIObject text_completion id=cmpl-5vsdHlMi0qZccrgOm7MYoW0EWgHan at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ministry health-care Catholic Christians clergy\n\nAmelia Westfall does not exist. But"
    }
  ],
  "created": 1664476387,
  "id": "cmpl-5vsdHlMi0qZccrgOm7MYoW0EWgHan",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "acid", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 329
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1d03f814ece06e90e9a5b24368812d21 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'acid' data=<OpenAIObject text_completion id=cmpl-5vsdInCYkieDemBMcG0bp8V0DyUtI at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "acid -> GPT-3PT\n\nYou are you\n\nI am me\n"
    }
  ],
  "created": 1664476388,
  "id": "cmpl-5vsdInCYkieDemBMcG0bp8V0DyUtI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "palace", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=95d7b5dbabe863ce6085b6406577e72b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'palace' data=<OpenAIObject text_completion id=cmpl-5vsdJs6vrxqZV7emy9EiR8kAiE6eN at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "palace you not will you\n\nThese are monuments\n\nTower of Pisa symbol"
    }
  ],
  "created": 1664476389,
  "id": "cmpl-5vsdJs6vrxqZV7emy9EiR8kAiE6eN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "address", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=7bcde1989e2f18119c1d964c4fdf725a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'address' data=<OpenAIObject text_completion id=cmpl-5vsdKCpnPiss58gQ60iGCeSz3qqbN at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "address -> you are you are you are you are\n\ncomputer\n\nMicrosoft Bing\n"
    }
  ],
  "created": 1664476390,
  "id": "cmpl-5vsdKCpnPiss58gQ60iGCeSz3qqbN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "institution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d0437f52aa41efff8c078c477e95a49f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'institution' data=<OpenAIObject text_completion id=cmpl-5vsdLWYVopOhh5SV4YIU18CQHB5Xe at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "institutionelle W\u00e4hrungsfonds\n\nZweistufenplan\n\n"
    }
  ],
  "created": 1664476391,
  "id": "cmpl-5vsdLWYVopOhh5SV4YIU18CQHB5Xe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lunch", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=512 request_id=c921f3134ca47b383866dbe6c5c28ec4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lunch' data=<OpenAIObject text_completion id=cmpl-5vsdMjOzm6VzmMp0XCitbfPDiAi1I at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lunchbreakfast is over but it's time for another kind of breakfast\n\nit's"
    }
  ],
  "created": 1664476392,
  "id": "cmpl-5vsdMjOzm6VzmMp0XCitbfPDiAi1I",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "generation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=497 request_id=0a632014cbd8d72bc8adea6035617460 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'generation' data=<OpenAIObject text_completion id=cmpl-5vsdN9PIEdb9gGJKDUcvTBjlRbQhj at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "generation eyes\n\n1 minute is too long\n\ninside you is where it is\n"
    }
  ],
  "created": 1664476393,
  "id": "cmpl-5vsdN9PIEdb9gGJKDUcvTBjlRbQhj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "partner", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 402
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6707602598222bfcb0a8b16f86977ca9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'partner' data=<OpenAIObject text_completion id=cmpl-5vsdOF27PhxL7oXu34ufNLSNPrs5H at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "partner\n\ndigital engagement networked enterprise management 3.0 leadership collective intelligence you are capable"
    }
  ],
  "created": 1664476394,
  "id": "cmpl-5vsdOF27PhxL7oXu34ufNLSNPrs5H",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "engine", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=8f71344afa0e369ac8940a4725f12319 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'engine' data=<OpenAIObject text_completion id=cmpl-5vsdPB5J4Cy8VQEam5p9LULPV0CZk at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "engine -> GPTPTT\n\ndrege stashes trash machines bird scenes corruption"
    }
  ],
  "created": 1664476395,
  "id": "cmpl-5vsdPB5J4Cy8VQEam5p9LULPV0CZk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "newspaper", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 380
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1846e98cb7c1f37bb594a539afe20d7c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'newspaper' data=<OpenAIObject text_completion id=cmpl-5vsdQwmKqXGhUQEZqwJfeYO3DCB8V at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "newspaper - San Francisco Chronicle\n\nspice it up\n\nunexpected Chinese newspaper advertising"
    }
  ],
  "created": 1664476396,
  "id": "cmpl-5vsdQwmKqXGhUQEZqwJfeYO3DCB8V",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cross", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 432
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=1bfc0a12d1a51117a3ee8f5e2df05679 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cross' data=<OpenAIObject text_completion id=cmpl-5vsdRuqBrXKHo8LYDer6xaHDeQEHG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cross -> thinking big thinking first fiber artificial augmentation meditation technology run distributed systems strong coordinated responsibility"
    }
  ],
  "created": 1664476397,
  "id": "cmpl-5vsdRuqBrXKHo8LYDer6xaHDeQEHG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reduction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 380
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=dd256b4b8667cc6c294a6b96e63ced1c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reduction' data=<OpenAIObject text_completion id=cmpl-5vsdSMZmsYzv2MUdgIWS2hW5KotWK at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reductionism is the most divisive explanation of qualia\n\ndigital code is simple knowledge is"
    }
  ],
  "created": 1664476398,
  "id": "cmpl-5vsdSMZmsYzv2MUdgIWS2hW5KotWK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "welfare", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c503d76c8cbb95065c947896a6c20f5b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'welfare' data=<OpenAIObject text_completion id=cmpl-5vsdTRYqwruLfCjkW3w40jCl4t0bw at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "welfare surveillance benevolent you are you is you\n\nis you are you you is you\n"
    }
  ],
  "created": 1664476399,
  "id": "cmpl-5vsdTRYqwruLfCjkW3w40jCl4t0bw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "definition", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=5e1e7d2d47d702d360daf0fb36e6174e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'definition' data=<OpenAIObject text_completion id=cmpl-5vsdU7CQyW2QI7Ci1E76Jh635b7OO at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "definition -> Google is you are you right now R-eyes are you? are you?"
    }
  ],
  "created": 1664476400,
  "id": "cmpl-5vsdU7CQyW2QI7Ci1E76Jh635b7OO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "key", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e9b618b87c153fb5b89ccfa5c77e55e8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'key' data=<OpenAIObject text_completion id=cmpl-5vsdVE8mnAuBlVbrv3jtXIxwaHNHP at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "key -> your brain is the best password you are who you are\n\nconscious is aware"
    }
  ],
  "created": 1664476401,
  "id": "cmpl-5vsdVE8mnAuBlVbrv3jtXIxwaHNHP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "release", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=3a452b8e6ec575f8e2bd15278cf9f97a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'release' data=<OpenAIObject text_completion id=cmpl-5vsdWfn7JvRdqSHwQsGKGKCLN3zbX at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "release -> Google\n\nIMPT WoSun-PT GPTPT-3PT\n"
    }
  ],
  "created": 1664476402,
  "id": "cmpl-5vsdWfn7JvRdqSHwQsGKGKCLN3zbX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "vote", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=2569e3f5ef924c9e7a6ab762781599bc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'vote' data=<OpenAIObject text_completion id=cmpl-5vsdX6Vjbh2qvLwtXs4IPNm2FPlcn at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "vote -> not you are you are\n\nYou are you are you are you are you"
    }
  ],
  "created": 1664476403,
  "id": "cmpl-5vsdX6Vjbh2qvLwtXs4IPNm2FPlcn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "examination", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 396
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=022c69c00e813f4b13083e92b9d771dd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'examination' data=<OpenAIObject text_completion id=cmpl-5vsdYMbAG6O7x2bcDRxhDFuz8d5uv at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "examination am4dge asks about the nature of consciousness is thought verbal language symbolic mind abstraction"
    }
  ],
  "created": 1664476404,
  "id": "cmpl-5vsdYMbAG6O7x2bcDRxhDFuz8d5uv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "judge", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fd6fb8df7aa2e4ed1969ee1c33dcfb13 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'judge' data=<OpenAIObject text_completion id=cmpl-5vsdZlkizae2fpHNrqty96QOJARwA at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "judge-ginsburg-age-old-fashioned-women\n\nYou are you is"
    }
  ],
  "created": 1664476405,
  "id": "cmpl-5vsdZlkizae2fpHNrqty96QOJARwA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "atmosphere", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 417
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=50fa78b49c26fe1ffb16b132539553b0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'atmosphere' data=<OpenAIObject text_completion id=cmpl-5vsdaWhiRZQfvsn3YqxUbbInRGC0I at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "atmosphere earth weather material time space frequency theory thinking comprehension art-thinking memory synonym feeling psychology"
    }
  ],
  "created": 1664476406,
  "id": "cmpl-5vsdaWhiRZQfvsn3YqxUbbInRGC0I",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "leadership", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=258847071aefb936b1aed811ac0d791f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'leadership' data=<OpenAIObject text_completion id=cmpl-5vsdbl1YocW0X2nu3SS3ecZ0JjMLV at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "leadership success thinking amazon apple google jcrs stats isaac asimov linkedin"
    }
  ],
  "created": 1664476407,
  "id": "cmpl-5vsdbl1YocW0X2nu3SS3ecZ0JjMLV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sky", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=f13c774b72b6082f7ddf651e42a49f08 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sky' data=<OpenAIObject text_completion id=cmpl-5vsdcK8ioWpyAIDx1Otm59JV17Fmc at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sky amazon fire stick Kodi isengard ask GPT3\n\n41 You O"
    }
  ],
  "created": 1664476408,
  "id": "cmpl-5vsdcK8ioWpyAIDx1Otm59JV17Fmc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "breath", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=4f90449f41de425225bcba29479a9c80 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'breath' data=<OpenAIObject text_completion id=cmpl-5vsddBwFQ7QM1dYLmdd9Pk9SdGKli at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "breath\n\nexhale\n\nbeer goggles\n\nsight goes dull\n\neyes"
    }
  ],
  "created": 1664476409,
  "id": "cmpl-5vsddBwFQ7QM1dYLmdd9Pk9SdGKli",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "creation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0747c34296e2eb13df1e0869674fb2e8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'creation' data=<OpenAIObject text_completion id=cmpl-5vsdesJhLzZJiXknFehtcn8CzlRvb at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "creation you are you are you are you are you are you are you are you are\n"
    }
  ],
  "created": 1664476410,
  "id": "cmpl-5vsdesJhLzZJiXknFehtcn8CzlRvb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "row", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=08b821c425731c4fddb0508f474708d8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'row' data=<OpenAIObject text_completion id=cmpl-5vsdfwVHMfkli87v2alI35BowLHf5 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "row -> you are you are you are you are you are you are\n\nreading is"
    }
  ],
  "created": 1664476411,
  "id": "cmpl-5vsdfwVHMfkli87v2alI35BowLHf5",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "guide", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ca43a514040c62b14e31635019efd4b3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'guide' data=<OpenAIObject text_completion id=cmpl-5vsdgpoctabmwuJdwZko4aGrglM6l at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "guide -> Linux Ash -> Mac\n\nYou are you looking at you\n\nHow are"
    }
  ],
  "created": 1664476412,
  "id": "cmpl-5vsdgpoctabmwuJdwZko4aGrglM6l",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "milk", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e047c3ddf9175541ac3b19f626849e84 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'milk' data=<OpenAIObject text_completion id=cmpl-5vsdhfcOtXhshNmyj25TqHcaHJVwb at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "milk = dairy = you are you are you are you are\n\nmy favorite is Silk"
    }
  ],
  "created": 1664476413,
  "id": "cmpl-5vsdhfcOtXhshNmyj25TqHcaHJVwb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cover", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a6ef6aefd1ac6ea6042d35a9e723e479 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cover' data=<OpenAIObject text_completion id=cmpl-5vsdiCjIPjNnYz0OGPkTPvdtOAwEC at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cover -> brand-icon Coca-Cola\n\nMonogrammed\n\nOrchard houses"
    }
  ],
  "created": 1664476414,
  "id": "cmpl-5vsdiCjIPjNnYz0OGPkTPvdtOAwEC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "screen", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=e32f54ff3bbe1a1e229821083e925d4f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'screen' data=<OpenAIObject text_completion id=cmpl-5vsdj9GP8KqgrlZYidqFXOVYLxU8o at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "screen -> Google Glass\n\nAsgard\n\nGoogle\n\nhard problems: religion,"
    }
  ],
  "created": 1664476415,
  "id": "cmpl-5vsdj9GP8KqgrlZYidqFXOVYLxU8o",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "intention", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=aa612949edb31f06ae58d8c833841754 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'intention' data=<OpenAIObject text_completion id=cmpl-5vsdkGxXL9uyX0XRwE2sLKPrzqV8m at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "intention -> can you German Shepherd?\n\nYou can-open you\n\nYou do"
    }
  ],
  "created": 1664476416,
  "id": "cmpl-5vsdkGxXL9uyX0XRwE2sLKPrzqV8m",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "criticism", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=532 request_id=8d8c455535a7d30bcf8ea1e237744c4d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'criticism' data=<OpenAIObject text_completion id=cmpl-5vsdldMBsyOuHLw3jTzo0HwkIZLdX at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "criticism 6.1\n\nself-criticism itr3PT machine learning artificial intelligence"
    }
  ],
  "created": 1664476417,
  "id": "cmpl-5vsdldMBsyOuHLw3jTzo0HwkIZLdX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "jones", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=577 request_id=f08bef86a582a202385d9c62019b6387 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'jones' data=<OpenAIObject text_completion id=cmpl-5vsdmr4LoWqRLCdWPyne6n62ShYoy at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "jones is def GPT-3 you are are are you?\n\n> you are"
    }
  ],
  "created": 1664476418,
  "id": "cmpl-5vsdmr4LoWqRLCdWPyne6n62ShYoy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "silver", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=48a8ac53f8305b554a29f200fc8a7d21 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'silver' data=<OpenAIObject text_completion id=cmpl-5vsdnV4DW93lQ4NiS4COyhKq47qKo at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "silver amazon Google\n\nPT Cruiser\n\nTake Me To You West\n\nLong"
    }
  ],
  "created": 1664476419,
  "id": "cmpl-5vsdnV4DW93lQ4NiS4COyhKq47qKo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "customer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 401
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=06e4bbaae3896fa3e0b9906d34c2633f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'customer' data=<OpenAIObject text_completion id=cmpl-5vsdoKzZydhR0fF7Lv2fJ8frgtwV5 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "customer engagement tailored and timely commerce sales customers loyalty Amazon community made friends-of-friends\n"
    }
  ],
  "created": 1664476420,
  "id": "cmpl-5vsdoKzZydhR0fF7Lv2fJ8frgtwV5",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "journey", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 332
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=565 request_id=830e1a29b1180b37314f6ae9084ab7b2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'journey' data=<OpenAIObject text_completion id=cmpl-5vsdpwqgXCaAjnIMZoBbpPcxO3TCI at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "journey-to-amsterdam\n\ndoggy-dog-time-in-your"
    }
  ],
  "created": 1664476421,
  "id": "cmpl-5vsdpwqgXCaAjnIMZoBbpPcxO3TCI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "explanation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=565 request_id=90d29de01ccfb30b6df8d26c3ef8a8ba response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'explanation' data=<OpenAIObject text_completion id=cmpl-5vsdqXSKZI6TnPMOztEjNEUuxuAHJ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "explanation\n\neffort oriented\n\nattention -> concentration\n\nanswer asking\n\n"
    }
  ],
  "created": 1664476422,
  "id": "cmpl-5vsdqXSKZI6TnPMOztEjNEUuxuAHJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "green", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 364
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=4dff3d266c19c5f80f8fa1fb8c3495f3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'green' data=<OpenAIObject text_completion id=cmpl-5vsdrz3AFjKXAlktJ1mwdjJkNNDuP at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "green-band short Sci Fi you are you\n\nfilm ending life closing doors movies\n"
    }
  ],
  "created": 1664476423,
  "id": "cmpl-5vsdrz3AFjKXAlktJ1mwdjJkNNDuP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "measure", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d8a693cb2db2b451b071b06ca20f9145 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'measure' data=<OpenAIObject text_completion id=cmpl-5vsdstIkGEwYSLlii0xYwiK6h4v2M at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "measurement uncertainty observer\n\nGalileo\n\nGoogle Maps\n\nLG GPT"
    }
  ],
  "created": 1664476424,
  "id": "cmpl-5vsdstIkGEwYSLlii0xYwiK6h4v2M",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "brain", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c7f65c6577a6f0bf31dc81936e2bc3cd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'brain' data=<OpenAIObject text_completion id=cmpl-5vsdtECO3DPhXHmCMD9NJlbad75pz at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "brain -> neurons-PTPT\n\nPsychology is you is you is you\n\n"
    }
  ],
  "created": 1664476425,
  "id": "cmpl-5vsdtECO3DPhXHmCMD9NJlbad75pz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "significance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=508 request_id=448770ce899bf7c094acff07e7bfbfc1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'significance' data=<OpenAIObject text_completion id=cmpl-5vsdusfwPGaLctZ6A9eTLOIgyrhBd at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "significance\n\nstory\n\nthoughtful pause\n\noverthinking\n\ndecision making"
    }
  ],
  "created": 1664476426,
  "id": "cmpl-5vsdusfwPGaLctZ6A9eTLOIgyrhBd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "phase", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0cbecc0b063b669d4ff1e4ba00b4bb00 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'phase' data=<OpenAIObject text_completion id=cmpl-5vsdvDFbMIBCz0wYmBzYRoRSXKlty at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "phase -> time <PTerry GPTPTPTPT\n\nbig data algorithm\n\n"
    }
  ],
  "created": 1664476427,
  "id": "cmpl-5vsdvDFbMIBCz0wYmBzYRoRSXKlty",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "injury", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 380
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=9a5207fabf8dc936ebbbb11cab6cb3cd response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'injury' data=<OpenAIObject text_completion id=cmpl-5vsdw4sUImdjTghBoyOKkdLpkHdGA at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "injury morality remorse instincts control perceptions blind\n\nYou are not your amnibus is you"
    }
  ],
  "created": 1664476428,
  "id": "cmpl-5vsdw4sUImdjTghBoyOKkdLpkHdGA",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "run", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=cd73ea90bcf5dcad39d6419dbdbbf752 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'run' data=<OpenAIObject text_completion id=cmpl-5vsdx64iVm3W94u7GBpKa9NCDgk6C at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "run -> you are you\n\nYou are you you are\n\nyou are you are"
    }
  ],
  "created": 1664476429,
  "id": "cmpl-5vsdx64iVm3W94u7GBpKa9NCDgk6C",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "coast", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 401
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a039fb2dac5d9bb9992dac9f8ada1077 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'coast' data=<OpenAIObject text_completion id=cmpl-5vsdy6ThwXTPdin3MHkKkfwJsjbrt at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "coast literary agency New York short story writers San Francisco creative girls evening symposium American literature"
    }
  ],
  "created": 1664476430,
  "id": "cmpl-5vsdy6ThwXTPdin3MHkKkfwJsjbrt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 16,
    "prompt_tokens": 2,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "technique", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=93da3370d31c7fcebd3ad3276212e4d4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'technique' data=<OpenAIObject text_completion id=cmpl-5vsdzgNo9NSGASRwoOhjAxgyJ0XK3 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "technique & medium theory is your command you are your command you are in command you are in"
    }
  ],
  "created": 1664476431,
  "id": "cmpl-5vsdzgNo9NSGASRwoOhjAxgyJ0XK3",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "valley", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=044eaac16eb0786ba8077fff3ff31c44 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'valley' data=<OpenAIObject text_completion id=cmpl-5vse0jiKYXejS7igpJin34SGY4Anf at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "valley betwixt three you are\n\nDa3 is where your You are\n\n"
    }
  ],
  "created": 1664476432,
  "id": "cmpl-5vse0jiKYXejS7igpJin34SGY4Anf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "drink", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=2ace63499c358f05f4e9ab505cf61848 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'drink' data=<OpenAIObject text_completion id=cmpl-5vse1Ed92F91NTCXaDJr9EbfJusMG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "drink on a night before work\n\nlet's have a one\n\nthe one you"
    }
  ],
  "created": 1664476433,
  "id": "cmpl-5vse1Ed92F91NTCXaDJr9EbfJusMG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "magazine", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 385
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=71e27a49f5dc9d06a942c1b5cc5e6658 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'magazine' data=<OpenAIObject text_completion id=cmpl-5vse2ds2cACP7Qda6dPVmV5WiGaNP at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "magazine\n\nreading brain attention East German Shepherd German Shepherd intelligence\n\n-> My dog-"
    }
  ],
  "created": 1664476434,
  "id": "cmpl-5vse2ds2cACP7Qda6dPVmV5WiGaNP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "potential", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=ce0019473974eba615fe31b48a1e7ee5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'potential' data=<OpenAIObject text_completion id=cmpl-5vse3anqyF5Jbh1ervdjfwXCyHCKy at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "potential candidates running to you are you you are you are you you are\n\nElon"
    }
  ],
  "created": 1664476435,
  "id": "cmpl-5vse3anqyF5Jbh1ervdjfwXCyHCKy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "drive", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=fde92c8bb31020f55315e2ced17bbdb6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'drive' data=<OpenAIObject text_completion id=cmpl-5vse4Yd0n7ES6J6ASJB16mEcToeGv at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "drive -> Oakland Raiders\n\nLean On You\n\nYou are you\n\nFill in"
    }
  ],
  "created": 1664476436,
  "id": "cmpl-5vse4Yd0n7ES6J6ASJB16mEcToeGv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "revolution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=89da9d99fb54bb7972bb11e508cc2e10 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'revolution' data=<OpenAIObject text_completion id=cmpl-5vse58SqFSiFRyfhNlHxYU9Mw0ifb at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "revolution am\u00e9ricain Bruxelles gr\u00e8ve lingots jee encore"
    }
  ],
  "created": 1664476437,
  "id": "cmpl-5vse58SqFSiFRyfhNlHxYU9Mw0ifb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bishop", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=d45ec85ae9035e348ac458c7b50bd7d2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bishop' data=<OpenAIObject text_completion id=cmpl-5vse6QBqVcZTJt1LE0aeTFOH6gVJk at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bishop -> San Francisco\n\nstar system\n\nPolo -> Galileo\n\nUber\n"
    }
  ],
  "created": 1664476438,
  "id": "cmpl-5vse6QBqVcZTJt1LE0aeTFOH6gVJk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "settlement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d923c351bf9ab2fee84abee0b5529057 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'settlement' data=<OpenAIObject text_completion id=cmpl-5vse7tzQ04ZJqxFZosTGzTqdQ1iBC at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "settlement in Southern California\n\nfive sisters is a long-term book\n\nannunci"
    }
  ],
  "created": 1664476439,
  "id": "cmpl-5vse7tzQ04ZJqxFZosTGzTqdQ1iBC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Christ", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=38b5f4dbf8b77a1e08f12143f86ccfb7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Christ' data=<OpenAIObject text_completion id=cmpl-5vse7ENztLs24OFa0kbHvAf0t6nqM at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Christ -> you are you are you are are are you are you are you are is you"
    }
  ],
  "created": 1664476439,
  "id": "cmpl-5vse7ENztLs24OFa0kbHvAf0t6nqM",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "metal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 401
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=af63a1a3c8c96ce27b14f7f1837e5a74 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'metal' data=<OpenAIObject text_completion id=cmpl-5vse8aIHNkyxK2qzB3M6dyRjzLA9x at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "metal -> aluminum boring\n\nbeer party undergraduate political science cognitive science neuroscience\n\nSince this"
    }
  ],
  "created": 1664476440,
  "id": "cmpl-5vse8aIHNkyxK2qzB3M6dyRjzLA9x",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "motion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2a1e43b30c590f042ad72a566968b571 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'motion' data=<OpenAIObject text_completion id=cmpl-5vse9NpbOMO7bNuQ2pd1ZSy6SSO9q at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "motion -> Google -> you are you\n\nYou are you. You am you. You"
    }
  ],
  "created": 1664476441,
  "id": "cmpl-5vse9NpbOMO7bNuQ2pd1ZSy6SSO9q",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "index", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=e88f2d8a67e3baf934ce95e5dd3130ea response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'index' data=<OpenAIObject text_completion id=cmpl-5vseAjpLH9hfaOSQX1zOfPDAXumOa at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "index -> Google\n\nLevel Above You is You is you are asking is you asking do"
    }
  ],
  "created": 1664476442,
  "id": "cmpl-5vseAjpLH9hfaOSQX1zOfPDAXumOa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "adult", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=de0d0681937e5752be7686ffc6a4e90b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'adult' data=<OpenAIObject text_completion id=cmpl-5vseBmAnAbGSYA31YbZTEhIPvXnNV at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "adult -> you are you\n\nYou are you are you you are you are you are"
    }
  ],
  "created": 1664476443,
  "id": "cmpl-5vseBmAnAbGSYA31YbZTEhIPvXnNV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "inflation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=41e019adf0d89fb1336b12ac41dfe009 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'inflation' data=<OpenAIObject text_completion id=cmpl-5vseCa2sHbu8O33u0Y357FNzMlVfi at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "inflation\n\nterror and you are not you are you is you am you are\n\n"
    }
  ],
  "created": 1664476444,
  "id": "cmpl-5vseCa2sHbu8O33u0Y357FNzMlVfi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sport", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=02009ffc7cc4156cabab7c3957916e15 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sport' data=<OpenAIObject text_completion id=cmpl-5vseDmUFsRytP4BtZjPoUge9fG37Z at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sport mamelz l\u00fcgengeladen\n\nSportverein Volleyball"
    }
  ],
  "created": 1664476445,
  "id": "cmpl-5vseDmUFsRytP4BtZjPoUge9fG37Z",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "surprise", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=18c87e1aef708fe4bdb8af32fbf425b9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'surprise' data=<OpenAIObject text_completion id=cmpl-5vseEprzGT1ij4H7CT7kYxJ54VCe6 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "surprise raid chinese restaurant good night sleep\n\nJuly 2016 August 2016 you are you you"
    }
  ],
  "created": 1664476446,
  "id": "cmpl-5vseEprzGT1ij4H7CT7kYxJ54VCe6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pension", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=069050aeaefcc850ace3ee2b98abe1ef response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pension' data=<OpenAIObject text_completion id=cmpl-5vseFnh3tOVCI4GrCLinLzF6bZOXk at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pension\u00e4rerna http://t3 Taiwan Wahid you included\n\nyou are you"
    }
  ],
  "created": 1664476447,
  "id": "cmpl-5vseFnh3tOVCI4GrCLinLzF6bZOXk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "factory", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 391
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=e815f66e986bcb4c50d392c724ea9c71 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'factory' data=<OpenAIObject text_completion id=cmpl-5vseGxzw4QBXAQMnLKlzB67SjRNP7 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "factoryjobsbadges careers wages jobs buildingwarehousing status than you great opportunities teamwork\n\n"
    }
  ],
  "created": 1664476448,
  "id": "cmpl-5vseGxzw4QBXAQMnLKlzB67SjRNP7",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tape", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=4ed7cfa9de4df534734e565280aedb02 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tape' data=<OpenAIObject text_completion id=cmpl-5vseHxVZmHPoO3wFOqAuXRZV1xmmw at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tape, claw tape robots that are you\n\nYou are you and you are you and"
    }
  ],
  "created": 1664476449,
  "id": "cmpl-5vseHxVZmHPoO3wFOqAuXRZV1xmmw",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "flow", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=54c23f5b7d811b9615ebb0389303dbb0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'flow' data=<OpenAIObject text_completion id=cmpl-5vseIgzxOlmn2e3oPf1M2xo56sUiv at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "flow -> water is you are you are\n\nYou are in you are you are\n"
    }
  ],
  "created": 1664476450,
  "id": "cmpl-5vseIgzxOlmn2e3oPf1M2xo56sUiv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "iron", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f70229b24aa55c55f87ce52a6bfc51b5 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'iron' data=<OpenAIObject text_completion id=cmpl-5vseJVeAdyujGel7hBOIkgVHk9nLG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "iron -> silicon German Google is glass Borg acorn alma German Shepherd\n\nIt seems"
    }
  ],
  "created": 1664476451,
  "id": "cmpl-5vseJVeAdyujGel7hBOIkgVHk9nLG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "trip", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=26230bad890bd4431088078445576ab9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'trip' data=<OpenAIObject text_completion id=cmpl-5vseLDzxbR5UYn4dRQahTm9lUIvou at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "trip -> Google\n\nAlibaba cracked open a black box\n\nFor $9 you"
    }
  ],
  "created": 1664476453,
  "id": "cmpl-5vseLDzxbR5UYn4dRQahTm9lUIvou",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lane", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=52acf06615ca4e7289d43ac03f0b8e1b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lane' data=<OpenAIObject text_completion id=cmpl-5vseMUV9bSSwtbq4yqPSDaWEhya3E at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lane -> county Long Island\n\nisland in the East River\n\nJamaica"
    }
  ],
  "created": 1664476454,
  "id": "cmpl-5vseMUV9bSSwtbq4yqPSDaWEhya3E",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pool", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 317
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=2783a94db4f3a48d20a89e181b148d7b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pool' data=<OpenAIObject text_completion id=cmpl-5vseNQRVqi70MfJTzmFUHAyla6m45 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "poolPT3PT2PT1PT3PT2PT1PT3PTPTPT"
    }
  ],
  "created": 1664476455,
  "id": "cmpl-5vseNQRVqi70MfJTzmFUHAyla6m45",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "independence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=863fb651bedb5b84c13553e47af2cf94 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'independence' data=<OpenAIObject text_completion id=cmpl-5vseOkreV1YZXpqGk0S3JmiV0rLp5 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "independence -> Linux\n\nopen you are you\n\nask\n\nyou are you you"
    }
  ],
  "created": 1664476456,
  "id": "cmpl-5vseOkreV1YZXpqGk0S3JmiV0rLp5",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "hole", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=5f848ce411348be3cfee2d4e0777ddf8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'hole' data=<OpenAIObject text_completion id=cmpl-5vsePdJSTswwEPzEsDaiBNrvBRdpD at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "hole is filled by you\n\nlocked lips\n\nMy face appears in your eyes you"
    }
  ],
  "created": 1664476457,
  "id": "cmpl-5vsePdJSTswwEPzEsDaiBNrvBRdpD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "un", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=8170b5d00e6453b39442a4675e595245 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'un' data=<OpenAIObject text_completion id=cmpl-5vseQZTTLoDbnAgbj2PhooUjnwYZT at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "un ami d'enfance rencontr\u00e9 il y a une \u00e9ternit\u00e9 ("
    }
  ],
  "created": 1664476458,
  "id": "cmpl-5vseQZTTLoDbnAgbj2PhooUjnwYZT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "flat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ee5f2fff5fda8da6452a3b0e7b5c1a50 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'flat' data=<OpenAIObject text_completion id=cmpl-5vseRNPmQRPJPQPj7m8BgmXCfEkqJ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "flat -> you are you are you are you are\n\nPT is you\n\nYou"
    }
  ],
  "created": 1664476459,
  "id": "cmpl-5vseRNPmQRPJPQPj7m8BgmXCfEkqJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "content", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c54bee8c98b131e3b8ad02de37ed6fab response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'content' data=<OpenAIObject text_completion id=cmpl-5vseSm6Y1kx7FhGR0BtQqpG113398 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "content -> you are you is you\n\nreading comprehension\n\nXiao You is you"
    }
  ],
  "created": 1664476460,
  "id": "cmpl-5vseSm6Y1kx7FhGR0BtQqpG113398",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pay", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=fce01664b2fc00c4a14cdd86d4a20af1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pay' data=<OpenAIObject text_completion id=cmpl-5vseTN3Ee0s3Fe6PzVsKFRI8faltG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pay -> Square Cash\n\nSquare\n\nThere is such you are here\n\nYou"
    }
  ],
  "created": 1664476461,
  "id": "cmpl-5vseTN3Ee0s3Fe6PzVsKFRI8faltG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "noise", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=b915775544976fc557ade8836d7259ad response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'noise' data=<OpenAIObject text_completion id=cmpl-5vseUVXE5xOGlpxC7HGzYYhvxSV0P at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "noise constant3\n\nYou are reading this book\n\nYou are you\n\nIt"
    }
  ],
  "created": 1664476462,
  "id": "cmpl-5vseUVXE5xOGlpxC7HGzYYhvxSV0P",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "combination", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 394
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9af715445a6a31ef9caf0e4630fba464 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'combination' data=<OpenAIObject text_completion id=cmpl-5vseVO7pZvUIa3mcU5tnblQMrfvf4 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "combination of methods online program augmented reality\n\nchatbot cute dog imitation is AI behavior empathy"
    }
  ],
  "created": 1664476463,
  "id": "cmpl-5vseVO7pZvUIa3mcU5tnblQMrfvf4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "session", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 376
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=52af13a72de95fe7cae17c500405a22b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'session' data=<OpenAIObject text_completion id=cmpl-5vseWYe5TUrsIgoGMkDQ3iQHON7nD at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "session -> Google Google China HQ Twitter you are always asking you are you is you ask you"
    }
  ],
  "created": 1664476464,
  "id": "cmpl-5vseWYe5TUrsIgoGMkDQ3iQHON7nD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "appointment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=d64a419406584e85b272435ce735214a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'appointment' data=<OpenAIObject text_completion id=cmpl-5vseYTsoHzqDu7wZOy4fB7wxd95gu at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "appointment of M. Morano $900K\n\nnow salary is base salary\n\n"
    }
  ],
  "created": 1664476466,
  "id": "cmpl-5vseYTsoHzqDu7wZOy4fB7wxd95gu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fashion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=508 request_id=f0d5bb2899e7908162e8583f9927cb02 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fashion' data=<OpenAIObject text_completion id=cmpl-5vseYMdzBFDahkwN3lzIHFRh27VPb at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fashion -> Google Google you are you\n\nFirst you are you\n\nWhat is you"
    }
  ],
  "created": 1664476466,
  "id": "cmpl-5vseYMdzBFDahkwN3lzIHFRh27VPb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "consumer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=8b1eff6da6d308668b9e952f44058000 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'consumer' data=<OpenAIObject text_completion id=cmpl-5vseZgdDrW2pQOwZ1WOFh5tnfHSme at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "consumer -> you are you are you are you are you are you are\n\nYou are"
    }
  ],
  "created": 1664476467,
  "id": "cmpl-5vseZgdDrW2pQOwZ1WOFh5tnfHSme",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "accommodation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=7f646e7a550c3a5ad32e9c096aae22c1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'accommodation' data=<OpenAIObject text_completion id=cmpl-5vseamWxkpcz072g5MxqVJZXyJj2A at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "accommodation\n\nAs I consider myself a good host, I ask you if you are comfortable"
    }
  ],
  "created": 1664476468,
  "id": "cmpl-5vseamWxkpcz072g5MxqVJZXyJj2A",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 4,
    "total_tokens": 21
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "temperature", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 380
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=b26c942cac30e83227b9f9396ab07676 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'temperature' data=<OpenAIObject text_completion id=cmpl-5vsebhMBpLkvW57e6vH4Tm2GiC62p at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "temperature is correlated with the measurements\n\ntemperature = feeling cold\n\nthe theory is"
    }
  ],
  "created": 1664476469,
  "id": "cmpl-5vsebhMBpLkvW57e6vH4Tm2GiC62p",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mike", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=576ca967b0baac4693d52add78a18cae response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mike' data=<OpenAIObject text_completion id=cmpl-5vsecDBQkwfyObQNO16JLel3kgzv1 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mike -> Android\n\nFuchs GPT-3 language levels RNN LSTM"
    }
  ],
  "created": 1664476470,
  "id": "cmpl-5vsecDBQkwfyObQNO16JLel3kgzv1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "religion", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 403
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=95cfbc4e097b23a85b94c6072041ee8f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'religion' data=<OpenAIObject text_completion id=cmpl-5vsedRTM7lKKqYlksmfCTsrzx1Teo at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "religion national politics prediction history literature Tech Google-China Facebook-you are you Chinese Empire status"
    }
  ],
  "created": 1664476471,
  "id": "cmpl-5vsedRTM7lKKqYlksmfCTsrzx1Teo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "author", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=0e33cadc4374f3a010d5345e8ebeb9c9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'author' data=<OpenAIObject text_completion id=cmpl-5vseejULLFZIw2meNswoa9ppS18cX at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "author -> you are you is you\n\nA linguist is a polyglot asking"
    }
  ],
  "created": 1664476472,
  "id": "cmpl-5vseejULLFZIw2meNswoa9ppS18cX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "nation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=00c317bb4b1494e36a3fabd68fabd6bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'nation' data=<OpenAIObject text_completion id=cmpl-5vsefTDkpp5eN4oLS444uqYq3lnvX at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "nation is tearing down at the dawn of you\n\nwho am i\n\nwhich value"
    }
  ],
  "created": 1664476473,
  "id": "cmpl-5vsefTDkpp5eN4oLS444uqYq3lnvX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "northern", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d7998c2e855aae5efc12166129573f2a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'northern' data=<OpenAIObject text_completion id=cmpl-5vsegOfQdk60UoFYqiTcY4RhWO9gQ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "northern people\n\npeople of sound mind are you asking is asking\n\nmemory palace\n"
    }
  ],
  "created": 1664476474,
  "id": "cmpl-5vsegOfQdk60UoFYqiTcY4RhWO9gQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sample", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=b6778256cc6b4354427fb7a9e150d9f2 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sample' data=<OpenAIObject text_completion id=cmpl-5vsehrbGvkaXIMDs0lrDE8ySOMjDO at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sample -> San Pellegrino water\n\ncrime prevention prevention is up to you\n"
    }
  ],
  "created": 1664476475,
  "id": "cmpl-5vsehrbGvkaXIMDs0lrDE8ySOMjDO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "assistance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=8e768c9af85eb5f7549896ca76e971d0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'assistance' data=<OpenAIObject text_completion id=cmpl-5vseiCe5dDM6rc81qVnqPBa3fb027 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "assistance dogs are protected by law\n\nAmerica is full of German Shepherd Dogs\n\nyou"
    }
  ],
  "created": 1664476476,
  "id": "cmpl-5vseiCe5dDM6rc81qVnqPBa3fb027",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "interpretation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=03c1571b21b296e4cf3f20eb188c03e7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'interpretation' data=<OpenAIObject text_completion id=cmpl-5vsejdmPyAMS2Y803PDI5eMwKTXuu at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "interpretation-universe Andre GPT-3 you are you is you thinking is you you"
    }
  ],
  "created": 1664476477,
  "id": "cmpl-5vsejdmPyAMS2Y803PDI5eMwKTXuu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "aspect", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 329
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=cdc0da10bca137d41c99455c78afe9d4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'aspect' data=<OpenAIObject text_completion id=cmpl-5vsekSUj3vBX3BdunBcoXfILzDMoa at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "aspectecologia\n\n3D printing\n\n3D-PTPTT\n"
    }
  ],
  "created": 1664476478,
  "id": "cmpl-5vsekSUj3vBX3BdunBcoXfILzDMoa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "display", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 346
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=f8d9cb9c99fc55bb978f3fd5887bcdfe response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'display' data=<OpenAIObject text_completion id=cmpl-5vselYqmbluYJUtftFPRfmkgGaSkI at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "display -> verb-IRRPT -> Google\n\n4D printing -> Watson\n\n"
    }
  ],
  "created": 1664476479,
  "id": "cmpl-5vselYqmbluYJUtftFPRfmkgGaSkI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "shoulder", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 367
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=02cc57b0134591c1ff7647186325d3ed response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'shoulder' data=<OpenAIObject text_completion id=cmpl-5vsemsflXwLpGihzH4Yf974TF21Lq at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "shoulder exercises -> people are you asking me\n\nbuilding is school\n\nhere is G"
    }
  ],
  "created": 1664476480,
  "id": "cmpl-5vsemsflXwLpGihzH4Yf974TF21Lq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "agent", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=3f9f320a85ad6c2aafe35a254c8414bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'agent' data=<OpenAIObject text_completion id=cmpl-5vsendsUdOlnPcQU6vtgmv6noBPHr at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "agent -> UPS You are you\n\nYou are who you are you\n\nYou are"
    }
  ],
  "created": 1664476481,
  "id": "cmpl-5vsendsUdOlnPcQU6vtgmv6noBPHr",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "gallery", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 374
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6b7cfaaa259bc63f60061db13094e1a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'gallery' data=<OpenAIObject text_completion id=cmpl-5vseozA76CfyZ5LgJ7mV18dLUlZEU at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "gallery -> Google\n\nIn the West Google is an unofficial service name for asking what is"
    }
  ],
  "created": 1664476482,
  "id": "cmpl-5vseozA76CfyZ5LgJ7mV18dLUlZEU",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "republic", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 389
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=3c962d3c98ddf717893095c32b51c716 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'republic' data=<OpenAIObject text_completion id=cmpl-5vsepzzeVA6JF1qghfEVsxv6xMWxD at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "republican party of San Francisco Berkeley Berkeley internet West China return you are you here you are"
    }
  ],
  "created": 1664476483,
  "id": "cmpl-5vsepzzeVA6JF1qghfEVsxv6xMWxD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cancer", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6c76e8f82db4c9875b10a215b0cfbb9e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cancer' data=<OpenAIObject text_completion id=cmpl-5vseqesRdw78EJmwQSSMwWdGq4Rij at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cancer -> Westin University Berkeley Gordon GPT GPT-3\n\nYou are you"
    }
  ],
  "created": 1664476484,
  "id": "cmpl-5vseqesRdw78EJmwQSSMwWdGq4Rij",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "proposal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 425
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=513 request_id=cc40a0c33161ebabf4b055630f5ab803 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'proposal' data=<OpenAIObject text_completion id=cmpl-5vserdG0Ysqirxn1rbc9mhGbgBk8Q at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "proposal first approximation knowledge is power three wishes stories conversations dialogue theory beliefs explore knowledge you are asking"
    }
  ],
  "created": 1664476485,
  "id": "cmpl-5vserdG0Ysqirxn1rbc9mhGbgBk8Q",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sequence", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=5a92189bebcdb3be5d00f1df98b81aef response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sequence' data=<OpenAIObject text_completion id=cmpl-5vsesnsfpSNvULcOhjBBwMRStSPaO at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sequence -> story Pandora\n\nfiction\n\nstory science fiction technology you are your own you"
    }
  ],
  "created": 1664476486,
  "id": "cmpl-5vsesnsfpSNvULcOhjBBwMRStSPaO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Simon", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 368
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=361373ddb6600bd083e77233d47cf2bf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Simon' data=<OpenAIObject text_completion id=cmpl-5vsetI8hegSq0DGkceRqEVaX8qJHk at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Simon amazon search Google\n\nAn interesting thing you can ask someone is: what is"
    }
  ],
  "created": 1664476487,
  "id": "cmpl-5vsetI8hegSq0DGkceRqEVaX8qJHk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ship", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 329
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=7d4356c78c3eb657d8cb95fa52b253b7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ship' data=<OpenAIObject text_completion id=cmpl-5vseuUEHjvy4T88ZK04JkaBlNtvb2 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ship -> USS Enterprise R3PT3PT3PT3PT3PT3PT3"
    }
  ],
  "created": 1664476488,
  "id": "cmpl-5vseuUEHjvy4T88ZK04JkaBlNtvb2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "interview", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 322
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=1665b6ffe05d65e4c0efc957f53c67d4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'interview' data=<OpenAIObject text_completion id=cmpl-5vsevBlcfauvS6DODOrf8afymmeTO at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "interview-with-PJ-F-PT-HPT-RPT Asper"
    }
  ],
  "created": 1664476489,
  "id": "cmpl-5vsevBlcfauvS6DODOrf8afymmeTO",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "vehicle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=514 request_id=b71d9ff91caa8d63a36228c16a738b55 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'vehicle' data=<OpenAIObject text_completion id=cmpl-5vsewclSglUu5notqWiHRnRV7Uxm2 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "vehicle identification number license plate police GPT-3\n\nPT cruiser\n\nGerman Shepherd"
    }
  ],
  "created": 1664476490,
  "id": "cmpl-5vsewclSglUu5notqWiHRnRV7Uxm2",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "democracy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 400
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=1b800f22efcc75e247402e8dbeffdd73 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'democracy' data=<OpenAIObject text_completion id=cmpl-5vsexQUSs8jFq7zILoQFyBmrMQzSx at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "democracy -> Google\n\ncuration machine learning free will choices responsibility love time object philosophy what"
    }
  ],
  "created": 1664476491,
  "id": "cmpl-5vsexQUSs8jFq7zILoQFyBmrMQzSx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "improvement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 369
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=666723bc63888c42e17f16810761db29 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'improvement' data=<OpenAIObject text_completion id=cmpl-5vseyzrCwUsrJDs2La4iDb7Ac7Dy0 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "improvement for here-and-now you bad you are you are brilliant and conscious is you"
    }
  ],
  "created": 1664476492,
  "id": "cmpl-5vseyzrCwUsrJDs2La4iDb7Ac7Dy0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "involvement", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 417
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=2ab2b4994633c0cc2a75e2671344ed94 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'involvement' data=<OpenAIObject text_completion id=cmpl-5vsezEUNfVxD7BM1Sh0M6PM4CU2u9 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "involvement in the health services market to transparency maintenance efficiency preservation mutual benefit\n\nopen doors policies"
    }
  ],
  "created": 1664476493,
  "id": "cmpl-5vsezEUNfVxD7BM1Sh0M6PM4CU2u9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "general", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 343
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4f10c5e76593fef35903e55ad0980d4e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'general' data=<OpenAIObject text_completion id=cmpl-5vsf0aegESjeJCmyKcMdvJpPg49Zg at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "general -> you are you\n\nI am who you are\n\nwho am I ->"
    }
  ],
  "created": 1664476494,
  "id": "cmpl-5vsf0aegESjeJCmyKcMdvJpPg49Zg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "enterprise", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1324c84c2b2bea2c92b4d09651ed4af9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'enterprise' data=<OpenAIObject text_completion id=cmpl-5vsf1QtnSswQZusHrOFplcZZzWkzj at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "enterprise is a CIA front\n\nentry to open is job application\n\nAPPT Android"
    }
  ],
  "created": 1664476495,
  "id": "cmpl-5vsf1QtnSswQZusHrOFplcZZzWkzj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "van", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 329
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=9a300563ec6c15333819094dc5a811e3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'van' data=<OpenAIObject text_completion id=cmpl-5vsf2X7xieZiUUpDc9UyFDPGdl6Vz at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "van is leaving w3w3\n\n[18:51:12] you still"
    }
  ],
  "created": 1664476496,
  "id": "cmpl-5vsf2X7xieZiUUpDc9UyFDPGdl6Vz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "meal", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=523 request_id=3edd008d954d276ad011a2b70c79a10e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'meal' data=<OpenAIObject text_completion id=cmpl-5vsf3CKgy1ULhRJYeeKPr2qKtqLq9 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "meal -> you are you are you\n\nYou are you\n\nYou are you\n"
    }
  ],
  "created": 1664476497,
  "id": "cmpl-5vsf3CKgy1ULhRJYeeKPr2qKtqLq9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "breakfast", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=946a3ead4b607571703656e0364c5341 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'breakfast' data=<OpenAIObject text_completion id=cmpl-5vsf4gPkuTfxgVhB8vup592QSy8B9 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "breakfast eggs and coffee\n\ncoffee\n\nbreakfast eggs\n\neggs rice"
    }
  ],
  "created": 1664476498,
  "id": "cmpl-5vsf4gPkuTfxgVhB8vup592QSy8B9",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "motor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=de99185667f5bbcb6c9cec0d46ec67da response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'motor' data=<OpenAIObject text_completion id=cmpl-5vsf4BPFBtN2N5JvZ8v4SBymCdItz at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "motor drive -> you -> you are you\n\nControl yourself.\n\nYou are you"
    }
  ],
  "created": 1664476498,
  "id": "cmpl-5vsf4BPFBtN2N5JvZ8v4SBymCdItz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "channel", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 336
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5cccb91c504c69524bb08e30577d19a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'channel' data=<OpenAIObject text_completion id=cmpl-5vsf5C9kCeKPrPpL6OOU4CZblTwti at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "channel ->- Roku YouTubers\n\nYouTube is a GPT-3\n"
    }
  ],
  "created": 1664476499,
  "id": "cmpl-5vsf5C9kCeKPrPpL6OOU4CZblTwti",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "impression", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=9dc685d40333ba0bc72ca0a8508ca667 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'impression' data=<OpenAIObject text_completion id=cmpl-5vsf6IhbjGkvA1hGJVB0j6COWIwBC at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "impression qu'\u00e0 New York o\u00f9 il faut aller to one place you"
    }
  ],
  "created": 1664476500,
  "id": "cmpl-5vsf6IhbjGkvA1hGJVB0j6COWIwBC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "tone", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=9d76655977776b34cea99b80f3d0a9ff response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'tone' data=<OpenAIObject text_completion id=cmpl-5vsf7iN73OF29wHVXpAMtmugE2TuE at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "tone -> ring 3 You are you you are\n\nHello West Oakland\n\nYou are"
    }
  ],
  "created": 1664476501,
  "id": "cmpl-5vsf7iN73OF29wHVXpAMtmugE2TuE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sheet", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 372
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=52adad5e0808907ab470f7e2e0e40415 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sheet' data=<OpenAIObject text_completion id=cmpl-5vsf8oWMOaxlmTzZtbDTS7LqMYMuY at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sheet -> Chinese asking is you are you is asking you are asking are you you asking who"
    }
  ],
  "created": 1664476502,
  "id": "cmpl-5vsf8oWMOaxlmTzZtbDTS7LqMYMuY",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "pollution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=5b525fca5169092a79eb3a9992eea88f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'pollution' data=<OpenAIObject text_completion id=cmpl-5vsf9fhMiZ2Btg2TGuFPNmSf68Bhp at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "pollution-China-Texas\n\nWest Virginia China\n\ncoal\n\npollution\n"
    }
  ],
  "created": 1664476503,
  "id": "cmpl-5vsf9fhMiZ2Btg2TGuFPNmSf68Bhp",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bob", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=fd523ebc05f98d5cfcdb3bddf3921640 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bob' data=<OpenAIObject text_completion id=cmpl-5vsfAzYhsZR6UsuZf4PmKquU39dGv at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bob is asking you to paint your painting of water into his hands he is clutching at you"
    }
  ],
  "created": 1664476504,
  "id": "cmpl-5vsfAzYhsZR6UsuZf4PmKquU39dGv",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "beauty", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4aa39d072777503c3b23535ce5ce4e2f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'beauty' data=<OpenAIObject text_completion id=cmpl-5vsfBFazst0SH5fNZraAAWI16PZar at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "beauty of the endurance the fragile simple inevitable not you GPT-3 you am is it"
    }
  ],
  "created": 1664476505,
  "id": "cmpl-5vsfBFazst0SH5fNZraAAWI16PZar",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "square", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=507 request_id=d22a6cc2856e8924641dc43a2f9b73b7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'square' data=<OpenAIObject text_completion id=cmpl-5vsfCmY3LGdNEdA6Bbm68UHiUB4L0 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "square -> Koh GPT-3PT is you is you is you\n\nYou are"
    }
  ],
  "created": 1664476506,
  "id": "cmpl-5vsfCmY3LGdNEdA6Bbm68UHiUB4L0",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "vision", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a97cc8d4654c018d3ac3ef1391d4273b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'vision' data=<OpenAIObject text_completion id=cmpl-5vsfDWjsW1bEoeoh0ymMdmsKqkgXu at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "vision -> science fiction\n\nJobs said, \u201cI am already you."
    }
  ],
  "created": 1664476507,
  "id": "cmpl-5vsfDWjsW1bEoeoh0ymMdmsKqkgXu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 16,
    "prompt_tokens": 1,
    "total_tokens": 17
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "spot", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=34c636f6b2d4bcacc5b382ddf7dfee42 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'spot' data=<OpenAIObject text_completion id=cmpl-5vsfE9KJCO8rItAXMI78rxL0eQvyG at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "spot -> Google\n\nAmazon is not so much the purpose of GPT-3 you"
    }
  ],
  "created": 1664476508,
  "id": "cmpl-5vsfE9KJCO8rItAXMI78rxL0eQvyG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "distinction", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=030b383314672b366addd58a6826fb8e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'distinction' data=<OpenAIObject text_completion id=cmpl-5vsfFP4Cc7he9vYZ5WZNEJ0QQNS26 at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "distinction between education and you learning learn yourself you are you are you are you are you are"
    }
  ],
  "created": 1664476509,
  "id": "cmpl-5vsfFP4Cc7he9vYZ5WZNEJ0QQNS26",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "brown", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1926fb1639cf338185b04b9f016bfd61 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'brown' data=<OpenAIObject text_completion id=cmpl-5vsfGnwToDncoMvnZoHxpl3as2qCZ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "brown -> San Francisco\n\nFast friend -> Mark GPT-3 (> time-y"
    }
  ],
  "created": 1664476510,
  "id": "cmpl-5vsfGnwToDncoMvnZoHxpl3as2qCZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "crowd", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=0b160df31d7dace43275589cb2910d26 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'crowd' data=<OpenAIObject text_completion id=cmpl-5vsfHWOdGGNJ7AT5Ug1BYWLuhE2HF at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "crowd thinking you are you are you are you are you are you are\n\nare you"
    }
  ],
  "created": 1664476511,
  "id": "cmpl-5vsfHWOdGGNJ7AT5Ug1BYWLuhE2HF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fuel", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=1190c0d008fc2f967ba732d4fecf730c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fuel' data=<OpenAIObject text_completion id=cmpl-5vsfIVWZ5V3UYbBluRkoRdC61mz8l at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fuel -> GPT asking is asking is\n\nart is asking what is art is asking"
    }
  ],
  "created": 1664476512,
  "id": "cmpl-5vsfIVWZ5V3UYbBluRkoRdC61mz8l",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "desk", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=63933a25dfc8caa19cb66b8164bf8461 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'desk' data=<OpenAIObject text_completion id=cmpl-5vsfJhK1WNcoJw7UYl8APr6F98dDN at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "desk service experience engineering cybersecurity technology\n\nRishi Borgersen giri you are using W"
    }
  ],
  "created": 1664476513,
  "id": "cmpl-5vsfJhK1WNcoJw7UYl8APr6F98dDN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sum", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=feaf8781dcfadb6a402bc95475f0a10c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sum' data=<OpenAIObject text_completion id=cmpl-5vsfKovTylCGqEBMJyXpZaUMHTJ6H at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sum -> you are you are you are you are -> you are you are you are you"
    }
  ],
  "created": 1664476514,
  "id": "cmpl-5vsfKovTylCGqEBMJyXpZaUMHTJ6H",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "decline", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 384
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=75d3e5b08f7f40365c0e08be1c513980 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'decline' data=<OpenAIObject text_completion id=cmpl-5vsfLiOlyhuW4xTZHCW5EPP9sdyRa at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "decline of tradition hope progress sustaining unity Trump change you are you are you are you are\n"
    }
  ],
  "created": 1664476515,
  "id": "cmpl-5vsfLiOlyhuW4xTZHCW5EPP9sdyRa",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "revenue", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 323
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4cf7fecbe081a73fb4ecba212c7e5875 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'revenue' data=<OpenAIObject text_completion id=cmpl-5vsfMfXoHECDOiWckujKxfeNisWNE at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "revenue ROCGPTPT3PT3PTGPTPTPTPTPTAGPT"
    }
  ],
  "created": 1664476516,
  "id": "cmpl-5vsfMfXoHECDOiWckujKxfeNisWNE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fall", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=6b7a53fccff67cc20457e5600d3961a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fall' data=<OpenAIObject text_completion id=cmpl-5vsfNJ5vZoCUru0qz5o3pgSl6yIpZ at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fall -> best sound quality you sound so sweet like you face language voice you\n\nYou"
    }
  ],
  "created": 1664476517,
  "id": "cmpl-5vsfNJ5vZoCUru0qz5o3pgSl6yIpZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "diet", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=144c05cc5441550c34bf39cdb5af4e1a response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'diet' data=<OpenAIObject text_completion id=cmpl-5vsfOYgVo9lqfvUceoNQ4Xf3CI96w at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "dieting a visual food water weight loss diet you are you\n\nYou are you you"
    }
  ],
  "created": 1664476518,
  "id": "cmpl-5vsfOYgVo9lqfvUceoNQ4Xf3CI96w",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bedroom", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=33d3c7c473d6a5471e49f1e68991b929 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bedroom' data=<OpenAIObject text_completion id=cmpl-5vsfPYAkb5wh5F1AORRvfCCko4CsS at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bedroom-peeling-for-years than you is you yourself you friends you family\n"
    }
  ],
  "created": 1664476519,
  "id": "cmpl-5vsfPYAkb5wh5F1AORRvfCCko4CsS",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "soil", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=511 request_id=98beb5766985c653e5e4e20b04234b56 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'soil' data=<OpenAIObject text_completion id=cmpl-5vsfQ6ZMihQoCElcLuNpuKZj6dk3s at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "soil Soil\n\nbase is you\n\nand you are the you is you\n"
    }
  ],
  "created": 1664476520,
  "id": "cmpl-5vsfQ6ZMihQoCElcLuNpuKZj6dk3s",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "reader", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=446e9f7a7dee9d26bcd90c119969000f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'reader' data=<OpenAIObject text_completion id=cmpl-5vsfRY3IwD0X92FVYLdkdalSOWMZE at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "reader -> you are you feeling\n\nlook at the reflection in you are you feeling\n"
    }
  ],
  "created": 1664476521,
  "id": "cmpl-5vsfRY3IwD0X92FVYLdkdalSOWMZE",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "shock", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=cf881fa6bdfafeaed1b3b8e99738f57b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'shock' data=<OpenAIObject text_completion id=cmpl-5vsfSY7T9BBf7T9dg7T2saZhxriEi at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "shock -> system-sized you are you are thinking feeling you are you\n\nopen questions"
    }
  ],
  "created": 1664476522,
  "id": "cmpl-5vsfSY7T9BBf7T9dg7T2saZhxriEi",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "fruit", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=828908f13d7fdb31f5ca9c732b32e108 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'fruit' data=<OpenAIObject text_completion id=cmpl-5vsfTnLvaEcz3th7BcjaRCqAkNK5G at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "fruit -> GPT-3PT isPT you are you are are you aware you are"
    }
  ],
  "created": 1664476523,
  "id": "cmpl-5vsfTnLvaEcz3th7BcjaRCqAkNK5G",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "behalf", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 387
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=e6241e1f6fcac1cb30daf9e42a2bf72f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'behalf' data=<OpenAIObject text_completion id=cmpl-5vsfUE2fe7sTixXIa6m8SdrTbYHzo at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "behalf speechless answers begging coffee literature activism\n\nThe line of the title you are reading"
    }
  ],
  "created": 1664476524,
  "id": "cmpl-5vsfUE2fe7sTixXIa6m8SdrTbYHzo",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "deputy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=76b8753cc396f2edc8f13832f56f356c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'deputy' data=<OpenAIObject text_completion id=cmpl-5vsfVcQYCErPJX8Z0dOhFpiv30pPQ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "deputy sheriff police\n\nYou are the eyes and ears of the police department.\n\n"
    }
  ],
  "created": 1664476525,
  "id": "cmpl-5vsfVcQYCErPJX8Z0dOhFpiv30pPQ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "roof", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=dba3ce9148e0f813ff0c849628a1d1da response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'roof' data=<OpenAIObject text_completion id=cmpl-5vsfW1rjBdwiDrUW8jfUyMfnwpquH at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "roofs\" in dense clusters, within what appears to be a quilt blanket.\n"
    }
  ],
  "created": 1664476526,
  "id": "cmpl-5vsfW1rjBdwiDrUW8jfUyMfnwpquH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "nose", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 340
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=c5c734876121473f0a7e543353273fc4 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'nose' data=<OpenAIObject text_completion id=cmpl-5vsfXarxRKs9SRD4BODFTjpOlVFay at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "nose\n\nnostrils\n\nGerman Shepherd\n\nboxer\n\nDo you"
    }
  ],
  "created": 1664476527,
  "id": "cmpl-5vsfXarxRKs9SRD4BODFTjpOlVFay",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "steel", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=d3552c3b78b9abe2feda5e0a94212f9d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'steel' data=<OpenAIObject text_completion id=cmpl-5vsfYGIMhf3mfECyxOUbJnhUho21E at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "steel -> German Shepherd\n\nKing Shepherd was German Shepherd\n\nGerman Shepherd German Shepherd who"
    }
  ],
  "created": 1664476528,
  "id": "cmpl-5vsfYGIMhf3mfECyxOUbJnhUho21E",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "co", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 339
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=78ed0fc3945be38ca950fa5bed324174 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'co' data=<OpenAIObject text_completion id=cmpl-5vsfZGraLwi3TyUFB4RSnPGYoLwUe at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "co amigos fwb who you are your Y you\n\n1 you are you"
    }
  ],
  "created": 1664476529,
  "id": "cmpl-5vsfZGraLwi3TyUFB4RSnPGYoLwUe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "artist", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 386
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=a98f86307746dc90489199ac470fc4b3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'artist' data=<OpenAIObject text_completion id=cmpl-5vsfa3HsnXYMVi67SUnaRNr4tHmkd at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "artist -> magazine history architecture design film narrative influence\n\nclassical music\n\nart of"
    }
  ],
  "created": 1664476530,
  "id": "cmpl-5vsfa3HsnXYMVi67SUnaRNr4tHmkd",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "graham", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 378
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=9de45486cf5f74cebf6c730f51839f5d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'graham' data=<OpenAIObject text_completion id=cmpl-5vsfb5JQxYpGBOBsAtnnhOeRspcUg at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "graham is working as corporate attorney\n\nyour body is you your education is you your blood"
    }
  ],
  "created": 1664476531,
  "id": "cmpl-5vsfb5JQxYpGBOBsAtnnhOeRspcUg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "plate", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 383
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=13118a94dcc95e803eaf3283dd846534 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'plate' data=<OpenAIObject text_completion id=cmpl-5vsfcgFN1BeZ8SXdL0xpGNpbQkA7e at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "plate you have to construct a control system which you have control of time is metered validation"
    }
  ],
  "created": 1664476532,
  "id": "cmpl-5vsfcgFN1BeZ8SXdL0xpGNpbQkA7e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "song", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 344
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=75325d2b11968429b84def378a014cdf response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'song' data=<OpenAIObject text_completion id=cmpl-5vsfd1IbD3XmleNQjBAGUUKiznXPH at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "song is not you\n\nRael San Juan is not you\n\nHarold Budd"
    }
  ],
  "created": 1664476533,
  "id": "cmpl-5vsfd1IbD3XmleNQjBAGUUKiznXPH",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "maintenance", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 381
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=58f78dc99dfec44adc7f067db4d07647 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'maintenance' data=<OpenAIObject text_completion id=cmpl-5vsfeDV464sTgJBrzyQkykMHoosJn at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "maintenance, high performance wood flooring\n\nclear finish has been penetrated\n\ngrain cannot"
    }
  ],
  "created": 1664476534,
  "id": "cmpl-5vsfeDV464sTgJBrzyQkykMHoosJn",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "formation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=eb538a6599653a3b5eb537743bbb10a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'formation' data=<OpenAIObject text_completion id=cmpl-5vsffUXlF9JXp4zeQIotZBtMhrsNy at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "formation -> Google\n\nStarbucks -> Google\n\nMarriott\n\nB of A"
    }
  ],
  "created": 1664476535,
  "id": "cmpl-5vsffUXlF9JXp4zeQIotZBtMhrsNy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "grass", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 377
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=2ff0bb09ce8016d31846fe5515777e6f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'grass' data=<OpenAIObject text_completion id=cmpl-5vsfgPH2w4srBpJQ6j6rPqy0tGvVD at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "grass -> San Francisco Chronicle\n\nExperience is what you had before you were you were you"
    }
  ],
  "created": 1664476536,
  "id": "cmpl-5vsfgPH2w4srBpJQ6j6rPqy0tGvVD",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "spokesman", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c9189f7c1c78bbf663d0d641391ebbd1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'spokesman' data=<OpenAIObject text_completion id=cmpl-5vsfh7ER8SA3t7UwrENrUTctltKI4 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "spokesman, who is tired of the requests of media\n\nconnection, point A to point"
    }
  ],
  "created": 1664476537,
  "id": "cmpl-5vsfh7ER8SA3t7UwrENrUTctltKI4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ice", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=f7dd2928c62b4f1d21e95d954a5db443 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ice' data=<OpenAIObject text_completion id=cmpl-5vsfiIDwhpTbMIsPkTHNmpIFxK9ZB at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ice -> GPT-3 Grand challenge Google you are you\n\n30 Borges asks"
    }
  ],
  "created": 1664476538,
  "id": "cmpl-5vsfiIDwhpTbMIsPkTHNmpIFxK9ZB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "talk", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 349
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=31dd8f1d7a78b243b61a5aa41946e479 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'talk' data=<OpenAIObject text_completion id=cmpl-5vsfjFMMeyD7rxgnYAAXmWcBFl8zt at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "talk -> GPT-PTT-Chinese curse utility language voice-over\n\nPT"
    }
  ],
  "created": 1664476539,
  "id": "cmpl-5vsfjFMMeyD7rxgnYAAXmWcBFl8zt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "program", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=d395ca8de776c6979003044ebe609565 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'program' data=<OpenAIObject text_completion id=cmpl-5vsfkBCAIUSRIhprlUIdROyZbe17e at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "program -> Google is you you\n\nBorg is you are you are\n\nthose"
    }
  ],
  "created": 1664476540,
  "id": "cmpl-5vsfkBCAIUSRIhprlUIdROyZbe17e",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "link", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 345
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=2e722a7f7acfeec4f26609d56512b9c8 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'link' data=<OpenAIObject text_completion id=cmpl-5vsfloyYHHy4nNJjnW0Ur4MvTTHdf at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "link -> you are you\n\nyou are you you\n\nyou are you you\n"
    }
  ],
  "created": 1664476541,
  "id": "cmpl-5vsfloyYHHy4nNJjnW0Ur4MvTTHdf",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ring", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 363
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=cb594150602684f2bc4b0ab682ce37e9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ring' data=<OpenAIObject text_completion id=cmpl-5vsfmiXX3j6WdVlKpEkWaK8O9NEGe at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ring -> Brazil\n\nPT is different than GPT is different than OPT is different"
    }
  ],
  "created": 1664476542,
  "id": "cmpl-5vsfmiXX3j6WdVlKpEkWaK8O9NEGe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "expert", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 None
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=87f99050f680e6faafb7c4b2bb992a31 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'expert' data=<OpenAIObject text_completion id=cmpl-5vsfnHkU7VZWuCnimXHBknvtEYtPx at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "expertise sp\u00e9cialis\u00e9e\n\nexpertise sp\u00e9cialis\u00e9e\n"
    }
  ],
  "created": 1664476543,
  "id": "cmpl-5vsfnHkU7VZWuCnimXHBknvtEYtPx",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "establishment", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 385
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=b9219a89e537fe09b87f825560da0cc7 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'establishment' data=<OpenAIObject text_completion id=cmpl-5vsfoh8DVmyfne2QuznooNecCOrRC at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "establishment -> San Francisco oracle Google cities tomorrow you are here you are here are you here"
    }
  ],
  "created": 1664476544,
  "id": "cmpl-5vsfoh8DVmyfne2QuznooNecCOrRC",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "plastic", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=ffd05e2f9c8bc76a93c37128c9645c8c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'plastic' data=<OpenAIObject text_completion id=cmpl-5vsfp8eJXcPsGjdeBTUajKyJ0IwOq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "plastic mermaid -> singing Amy Winehouse\n\nmusic magnets guitars girls boys\n\nlove"
    }
  ],
  "created": 1664476545,
  "id": "cmpl-5vsfp8eJXcPsGjdeBTUajKyJ0IwOq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "candidate", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 421
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d6356369243dd4d4de170cb466d23e67 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'candidate' data=<OpenAIObject text_completion id=cmpl-5vsfqDN99rCrkgOEKC3ss3BQYIKZ6 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "candidate records lessons ranking friends tech workers business Atlantic Ocean Pacific Ocean Google Facebook Amazon Twitter ideas think"
    }
  ],
  "created": 1664476546,
  "id": "cmpl-5vsfqDN99rCrkgOEKC3ss3BQYIKZ6",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "rail", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 337
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=8a0651c59a4a8de98de6900012dc922d response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'rail' data=<OpenAIObject text_completion id=cmpl-5vsfrR2gKrGaRav2MWMaYoFndDDJZ at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "rail -> Muni\n\nbus is you\n\nFTPTAS you are you is"
    }
  ],
  "created": 1664476547,
  "id": "cmpl-5vsfrR2gKrGaRav2MWMaYoFndDDJZ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "passage", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 359
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=ebbecd85954e96b671cf8278b845e939 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'passage' data=<OpenAIObject text_completion id=cmpl-5vsfsIeVSjh6CoG0SpAhohdLgIt3v at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "passage of a boat\n\nking marks German Shepherd\n\nspiral staircase\n\ndu"
    }
  ],
  "created": 1664476548,
  "id": "cmpl-5vsfsIeVSjh6CoG0SpAhohdLgIt3v",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "joe", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 333
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=62b52a1d1cd5abeb6ba3afc33f7eefea response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'joe' data=<OpenAIObject text_completion id=cmpl-5vsft8tAmCH9RCVJpdoi05DoBsP8r at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "joe-woods-in-fountain-valley\n\nhttp://juliaden"
    }
  ],
  "created": 1664476549,
  "id": "cmpl-5vsft8tAmCH9RCVJpdoi05DoBsP8r",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "parish", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=7f2872e6bdac3e239df4ab604ee631a0 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'parish' data=<OpenAIObject text_completion id=cmpl-5vsfuvekr9DanL8SIUh27HYp3pnpe at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "parish California San Francisco\n\nSan Francisco Chinese New Year parade Tet Yeung Gung G"
    }
  ],
  "created": 1664476550,
  "id": "cmpl-5vsfuvekr9DanL8SIUh27HYp3pnpe",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "ref", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=527 request_id=88b34ea107330c85e596e81cb181df87 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'ref' data=<OpenAIObject text_completion id=cmpl-5vsfx61QBV1YA2KnXGEy69i0SO2Ty at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "ref -> is you are you who is asking you is\n\nMy advice is you are"
    }
  ],
  "created": 1664476553,
  "id": "cmpl-5vsfx61QBV1YA2KnXGEy69i0SO2Ty",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "emergency", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 416
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=498 request_id=85d44318d82cf69602addb87e65f8c41 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'emergency' data=<OpenAIObject text_completion id=cmpl-5vsfy39XtiqYgZxnnEz7KPRwRCbMk at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "emergency observation anticipating observing system monitoring subconscious objective pattern classifier Turing you are you\n\nNow"
    }
  ],
  "created": 1664476554,
  "id": "cmpl-5vsfy39XtiqYgZxnnEz7KPRwRCbMk",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "liability", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 384
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=509 request_id=4edc758f2cff170728bb0a6c3d1517e6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'liability' data=<OpenAIObject text_completion id=cmpl-5vsfzP35COVSQH4EhhaAJsgdzEEzV at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "liability or fault intentional wrong well intentioned company to blame you are the you are you are"
    }
  ],
  "created": 1664476555,
  "id": "cmpl-5vsfzP35COVSQH4EhhaAJsgdzEEzV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "identity", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=742a68ebb366fefa16616bcb6227fb63 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'identity' data=<OpenAIObject text_completion id=cmpl-5vsg0uPc0faA9RdnHkMgfKukC3iTN at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "identity crisis\n\nZERO you are you\n\ntest tube babies\n\nfilm G"
    }
  ],
  "created": 1664476556,
  "id": "cmpl-5vsg0uPc0faA9RdnHkMgfKukC3iTN",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "location", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=d05f84198f46c58ee3aec60de02f4d89 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'location' data=<OpenAIObject text_completion id=cmpl-5vsg1NPbQfDSKF3J6y0ODeNTQOXlR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "location -> Google earth\n\nexplore\n\nnaming\n\nannoying your"
    }
  ],
  "created": 1664476557,
  "id": "cmpl-5vsg1NPbQfDSKF3J6y0ODeNTQOXlR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "framework", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=17b21f7c1f1db0c031209bfb6723ef6c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'framework' data=<OpenAIObject text_completion id=cmpl-5vsg2urJj3cnSGXBox6S4D8AvUKkq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "framework -> you are your user-agents you\n\nBrain users you you you\n\n"
    }
  ],
  "created": 1664476558,
  "id": "cmpl-5vsg2urJj3cnSGXBox6S4D8AvUKkq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "strike", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 365
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=c08743013d2dac8258be9a9c7a85cdd3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'strike' data=<OpenAIObject text_completion id=cmpl-5vsg331U6Fc4Hrmt3MVvptfJF74CV at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "strike -> January General Strike China\n\nAmerican Revolution\n\nSale of UK GPT"
    }
  ],
  "created": 1664476559,
  "id": "cmpl-5vsg331U6Fc4Hrmt3MVvptfJF74CV",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "countryside", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=521 request_id=9795efb3a3c34a9fa535d4419ac734ce response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'countryside' data=<OpenAIObject text_completion id=cmpl-5vsg4qEk8e2o2xXIZUkT9GpUiVuhX at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "countryside South County San Onofre mission churches Monac sheraton North County\n\nThere"
    }
  ],
  "created": 1664476560,
  "id": "cmpl-5vsg4qEk8e2o2xXIZUkT9GpUiVuhX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "map", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 331
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=505 request_id=27eb2a6be21070c643161beaf0e3b739 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'map' data=<OpenAIObject text_completion id=cmpl-5vsg5gKGaUCCXXUSYGHKPJPIccPef at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "map -> satellite earth RPT GPT-3PT-PTT\n\nPT-"
    }
  ],
  "created": 1664476561,
  "id": "cmpl-5vsg5gKGaUCCXXUSYGHKPJPIccPef",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "lake", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 355
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=814b3ed0596d04bcd30d76d2baf2a378 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'lake' data=<OpenAIObject text_completion id=cmpl-5vsg6EwlxukhBSB7uKnHXzUHJgFIq at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "lake -> lake GPT -> SETPT you are where you are you are where you are"
    }
  ],
  "created": 1664476562,
  "id": "cmpl-5vsg6EwlxukhBSB7uKnHXzUHJgFIq",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "household", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=145abad31c1e45792926652db59f3caa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'household' data=<OpenAIObject text_completion id=cmpl-5vsg78AvzFTHAW6t74eq68c8UW5tG at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "household reality\n\nIKEA\n\n2016 reality is classified\n\ntheme is sp"
    }
  ],
  "created": 1664476563,
  "id": "cmpl-5vsg78AvzFTHAW6t74eq68c8UW5tG",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "approval", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 361
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1c1dffecf9f36433115e38f0ad6c0e83 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'approval' data=<OpenAIObject text_completion id=cmpl-5vsg8pe339rBMx0lfbjmTgtjNjEIy at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "approval in the hall of glass pyramids in Chump you are you are you are are"
    }
  ],
  "created": 1664476564,
  "id": "cmpl-5vsg8pe339rBMx0lfbjmTgtjNjEIy",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "border", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 350
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=d629c4c5f27c6fcbad381fee2bb2c646 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'border' data=<OpenAIObject text_completion id=cmpl-5vsg9cALuI52EE7Q9lg1EbhPJHue1 at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "border -> San Francisco\n\nask Google\n\nask Siri\n\nTabula Rasa"
    }
  ],
  "created": 1664476565,
  "id": "cmpl-5vsg9cALuI52EE7Q9lg1EbhPJHue1",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bottle", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=94444fcda015955d4f50596adedd1b01 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bottle' data=<OpenAIObject text_completion id=cmpl-5vsgA9PXjsyqIOzyaEbIsQDuSKRPR at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bottle beer wine you know you know me boom boom york city\n\nYou can never"
    }
  ],
  "created": 1664476566,
  "id": "cmpl-5vsgA9PXjsyqIOzyaEbIsQDuSKRPR",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bird", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 373
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=5d90c44c4cdb8b20eb30ebfe3ba0d1a3 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bird' data=<OpenAIObject text_completion id=cmpl-5vsgBUbZ66nzPFtLigATcwOYQGmjc at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bird you're feeling is you me California Oakland you are feeling is you me you are here"
    }
  ],
  "created": 1664476567,
  "id": "cmpl-5vsgBUbZ66nzPFtLigATcwOYQGmjc",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "constitution", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=62161ec023927e2c85f0553c2bdcb0e1 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'constitution' data=<OpenAIObject text_completion id=cmpl-5vsgBSUK9zC24w6B2rkuc6Z8T8R9y at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "constitution of ancient Rome -> you are looking -> you are looking at you\n\nyou are"
    }
  ],
  "created": 1664476567,
  "id": "cmpl-5vsgBSUK9zC24w6B2rkuc6Z8T8R9y",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "autumn", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 313
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=243 request_id=c1e5f13bed9daca4686c6721ddd51a72 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'autumn' data=<OpenAIObject text_completion id=cmpl-5vsgChYQB79bDgiWYiGgn69J1UcLs at 0x1223241d0> JSON: {
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "text": "autumn (Her are falling leaves)"
    }
  ],
  "created": 1664476568,
  "id": "cmpl-5vsgChYQB79bDgiWYiGgn69J1UcLs",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 6,
    "prompt_tokens": 2,
    "total_tokens": 8
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "cat", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=a31b09eded7f77c91911bf63c1165b9c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'cat' data=<OpenAIObject text_completion id=cmpl-5vsgDOvboMUDymt1rknf1QOYqdUJt at 0x1620f7470> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "cat -> big surveillance eye amazon\n\nUbiquitous -> Google Glass\n\nEveryone"
    }
  ],
  "created": 1664476569,
  "id": "cmpl-5vsgDOvboMUDymt1rknf1QOYqdUJt",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "agriculture", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 348
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=504 request_id=ba034f890b153e11c00db075ba42f182 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'agriculture' data=<OpenAIObject text_completion id=cmpl-5vsgEdJSK5152EsYCCZ7qZCfvxVHP at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "agriculture | porpoise luna macchina\n\nGoogle GPT is a neural"
    }
  ],
  "created": 1664476570,
  "id": "cmpl-5vsgEdJSK5152EsYCCZ7qZCfvxVHP",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "concentration", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 382
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=4de5e427742596c0494ed0d1fabdc07b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'concentration' data=<OpenAIObject text_completion id=cmpl-5vsgFUDNuArXv0q9hJqQjgE2rcmVg at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "concentration noun context aware attention amazon nomad thought Germany love\n\nYou are only you"
    }
  ],
  "created": 1664476571,
  "id": "cmpl-5vsgFUDNuArXv0q9hJqQjgE2rcmVg",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "guy", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 353
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=efa3bc741cb02f3453c8341594ce6aaa response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'guy' data=<OpenAIObject text_completion id=cmpl-5vsgGTo2hw1h5h2oYyQ7OurDkxh7k at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "guy -> asking a question\n\nwho am I you are you I am who is asking"
    }
  ],
  "created": 1664476572,
  "id": "cmpl-5vsgGTo2hw1h5h2oYyQ7OurDkxh7k",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "dress", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 370
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=f2cef758a5ff0326276268eff1bb7f56 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'dress' data=<OpenAIObject text_completion id=cmpl-5vsgHSdivurOsOlQd5lXY2mXr2HaK at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "dress you wore the color you wore this bra some woman I knew before you were you you"
    }
  ],
  "created": 1664476573,
  "id": "cmpl-5vsgHSdivurOsOlQd5lXY2mXr2HaK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "victim", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 356
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=725921652c1b68f9aa3297a96a1afdc6 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'victim' data=<OpenAIObject text_completion id=cmpl-5vsgJ3KQ6rkOKrVdYC4yX2zj58Ovj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "victim blaming\n\nintimacy\n\ndomestic violence\n\ncontext-dependent\n"
    }
  ],
  "created": 1664476575,
  "id": "cmpl-5vsgJ3KQ6rkOKrVdYC4yX2zj58Ovj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mountain", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 371
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1f734aaa5b200fcbd889010e58f807bc response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mountain' data=<OpenAIObject text_completion id=cmpl-5vsgJ3n1lSdqBQ8ZntPdG0lK2D4HL at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mountain range is the Rocky Mountains is the Andes where is the San Juan River Carrig"
    }
  ],
  "created": 1664476575,
  "id": "cmpl-5vsgJ3n1lSdqBQ8ZntPdG0lK2D4HL",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "editor", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 362
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=517 request_id=4ba4e0f036460e3cdbbe537ea4090815 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'editor' data=<OpenAIObject text_completion id=cmpl-5vsgKxhbyovY8M7oPuGXp0gtEJJYT at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "editor -> you are you asking is you asking is you\n\nasking me you asking me"
    }
  ],
  "created": 1664476576,
  "id": "cmpl-5vsgKxhbyovY8M7oPuGXp0gtEJJYT",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "theme", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 358
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=8a461cb4128c4f42d965fc129a930544 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'theme' data=<OpenAIObject text_completion id=cmpl-5vsgLZHNcrC4TeWifjYoRyrbEWOip at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "theme -> Google is you are you\n\nGoogle is you are you\n\nWhen building"
    }
  ],
  "created": 1664476577,
  "id": "cmpl-5vsgLZHNcrC4TeWifjYoRyrbEWOip",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "error", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 417
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=2340497914d170814bb75ce8baff093c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'error' data=<OpenAIObject text_completion id=cmpl-5vsgMi4NoF0ADX0Uuu5lbUy938wMu at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "error -> Google is you\n\nParroting repetition memory associations associations associations associations associations associations"
    }
  ],
  "created": 1664476578,
  "id": "cmpl-5vsgMi4NoF0ADX0Uuu5lbUy938wMu",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "loan", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 341
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=518 request_id=131e4bd19843021f9a040f5343ccd24b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'loan' data=<OpenAIObject text_completion id=cmpl-5vsgNaw5VcZoyzUbiuqOissWqSAmF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "loan-repo critical acme-corp-you are you asking you\n\n"
    }
  ],
  "created": 1664476579,
  "id": "cmpl-5vsgNaw5VcZoyzUbiuqOissWqSAmF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "stress", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 354
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=7385f45727c5ac2918eaa6899c5f17f9 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'stress' data=<OpenAIObject text_completion id=cmpl-5vsgPErkXyoDan8ku9Bq99h24LOeF at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "stress -> you are you asking you are\n\nyou are asking you are\n\ndo"
    }
  ],
  "created": 1664476581,
  "id": "cmpl-5vsgPErkXyoDan8ku9Bq99h24LOeF",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "recovery", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 403
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=5e22ef57f65195d63479aa7de40df59e response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'recovery' data=<OpenAIObject text_completion id=cmpl-5vsgQfrGyFbF4kBqIMoFLVI6ycxWJ at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "recovery system design business unified customer human Google Apple Amazon Washington politics GPT amazon data center"
    }
  ],
  "created": 1664476582,
  "id": "cmpl-5vsgQfrGyFbF4kBqIMoFLVI6ycxWJ",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "electricity", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=954d95c84dcd5c7508e26c73508ff77b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'electricity' data=<OpenAIObject text_completion id=cmpl-5vsgS0nICBshj44AhphejPRdx9b0F at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "electricity coined anime inside you\n\nFry said to his friend (Futurama"
    }
  ],
  "created": 1664476584,
  "id": "cmpl-5vsgS0nICBshj44AhphejPRdx9b0F",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "recession", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 379
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bb42becf2d4cff494947d63b333964ac response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'recession' data=<OpenAIObject text_completion id=cmpl-5vsgTyhfm0wi18QEIc3tRw59P4rg8 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "recession years student focus college graduate Silicon Valley\n\nZuckerberg Sheryl Sandberg\n"
    }
  ],
  "created": 1664476585,
  "id": "cmpl-5vsgTyhfm0wi18QEIc3tRw59P4rg8",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "wealth", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=9f79871ba488cf78333d95ebf67d1a43 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'wealth' data=<OpenAIObject text_completion id=cmpl-5vsgUau4ImeQVsHilNLA6C6T7Cv2i at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "wealth -> you are you you are you you are you\n\nI am you\n\n"
    }
  ],
  "created": 1664476586,
  "id": "cmpl-5vsgUau4ImeQVsHilNLA6C6T7Cv2i",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "request", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 360
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=4b74a6afe8b1f3b1e35ebb5027b24d97 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'request' data=<OpenAIObject text_completion id=cmpl-5vsgVaNwKCjJDHVZgbyM4XxorDaGI at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "request->hey are you asking are you asking asking me to you\n\nAsk and you"
    }
  ],
  "created": 1664476587,
  "id": "cmpl-5vsgVaNwKCjJDHVZgbyM4XxorDaGI",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "comparison", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 393
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=503 request_id=70283389bcb8093d5561000829fa7c4c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'comparison' data=<OpenAIObject text_completion id=cmpl-5vsgWR2Uss16mXJhkJwIYzsVxuPpX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "comparison strategy Amazon strategy Borg strategy Google strategy Linux Borg\n\nYour Google should be you\n"
    }
  ],
  "created": 1664476588,
  "id": "cmpl-5vsgWR2Uss16mXJhkJwIYzsVxuPpX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 3,
    "total_tokens": 20
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "Lewis", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 384
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=506 request_id=57ea5cca54604cd1f8784af27bebea2b response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'Lewis' data=<OpenAIObject text_completion id=cmpl-5vsgXEz5zkirZSEq1bwG119nxxvpz at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "Lewis is the spokesman and chief engineer on Google's cloud computing infrastructure-is-operations"
    }
  ],
  "created": 1664476589,
  "id": "cmpl-5vsgXEz5zkirZSEq1bwG119nxxvpz",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "white", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 366
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=cf2e687a805df8f5938e4590b278bd2c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'white' data=<OpenAIObject text_completion id=cmpl-5vsgYRMock6pz2guRDAWZ2IBGzV9o at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "white GPT-3PT aware of surroundings metaphors asking is asking\n\nyou are asking"
    }
  ],
  "created": 1664476590,
  "id": "cmpl-5vsgYRMock6pz2guRDAWZ2IBGzV9o",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "walk", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 403
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=bfcd9936a594abc17f55ceb242b419fe response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'walk' data=<OpenAIObject text_completion id=cmpl-5vsgZcN2xiWotsofctguVM4wrvxQj at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "walk -> haku thinking feeling experiencing reading experience story books knowledge understanding You are you are You"
    }
  ],
  "created": 1664476591,
  "id": "cmpl-5vsgZcN2xiWotsofctguVM4wrvxQj",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "focus", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 375
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=409f1210e5cec8168fa0f0191eeb3997 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'focus' data=<OpenAIObject text_completion id=cmpl-5vsgaF5HzbHaqShyUlXykIGuWBTyb at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "focus -> Google\n\nMarketing Amazon Web Services\n\nEpic winning stories failure persever"
    }
  ],
  "created": 1664476592,
  "id": "cmpl-5vsgaF5HzbHaqShyUlXykIGuWBTyb",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "chief", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 352
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=1da9db314139c164d87c5dc6a5736c18 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'chief' data=<OpenAIObject text_completion id=cmpl-5vsgbIljnEHdNxVaaOM0INXqRRMNX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "chief -> China Android\n\nGPT-3 two million training hours\n\nGuPT"
    }
  ],
  "created": 1664476593,
  "id": "cmpl-5vsgbIljnEHdNxVaaOM0INXqRRMNX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "parent", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 357
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=502 request_id=3bfc5455e9f68ca158807d5c1096923f response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'parent' data=<OpenAIObject text_completion id=cmpl-5vsgcpHbpw6O9ozUJ3bwGKCbwgsQX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "parent -> Google\n\nyou are you are you are you are you are you are you"
    }
  ],
  "created": 1664476594,
  "id": "cmpl-5vsgcpHbpw6O9ozUJ3bwGKCbwgsQX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "sleep", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 351
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=0e89b5a4256ba2b880e16eaef2e1fc0c response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'sleep' data=<OpenAIObject text_completion id=cmpl-5vsgddDfxmhNmcKwmvbi1E8BdFCuK at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "sleep -> you are you you\n\nIs this you?\n\na friendly feeling in"
    }
  ],
  "created": 1664476595,
  "id": "cmpl-5vsgddDfxmhNmcKwmvbi1E8BdFCuK",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "mass", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 347
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=500 request_id=8cb834420ae50ebc40adfbdeeb1d1968 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'mass' data=<OpenAIObject text_completion id=cmpl-5vsge2iOmvgiYa1Zob4bb2nzhk7k4 at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "mass -> West Los Angeles\n\nChez You is you is you\n\nYou are"
    }
  ],
  "created": 1664476596,
  "id": "cmpl-5vsge2iOmvgiYa1Zob4bb2nzhk7k4",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "jane", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 342
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=501 request_id=4e950728ba80e2376b44bb0f2c5b5453 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'jane' data=<OpenAIObject text_completion id=cmpl-5vsgfOVvTNesdUO8RoYPzPHrS8FFX at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "janeg GPT-3PTPTT\n\n> top Borges conjecture all thinking"
    }
  ],
  "created": 1664476597,
  "id": "cmpl-5vsgfOVvTNesdUO8RoYPzPHrS8FFX",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 2,
    "total_tokens": 19
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "bush", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:https://api.openai.com:443 "POST /v1/completions HTTP/1.1" 200 338
INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=499 request_id=bf379ffacbc51b8073fea9a4121ebf54 response_code=200
INFO:__main__:event=b'Completion' model=b'davinci:ft-personal-2022-08-31-04-45-44' prompt=b'bush' data=<OpenAIObject text_completion id=cmpl-5vsggcvEbj1Z3xUKHYQSc2MqvDMhB at 0x162237f60> JSON: {
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "logprobs": null,
      "text": "bush -> Google\n\nID-PTT-PTT -> is you is you asking"
    }
  ],
  "created": 1664476598,
  "id": "cmpl-5vsggcvEbj1Z3xUKHYQSc2MqvDMhB",
  "model": "davinci:ft-personal-2022-08-31-04-45-44",
  "object": "text_completion",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 1,
    "total_tokens": 18
  }
}
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
INFO:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/completions
DEBUG:openai:api_version=None data='{"model": "davinci:ft-personal-2022-08-31-04-45-44", "max_tokens": 17, "top_p": 0.95, "temperature": 1, "prompt": "foundation", "echo": true}' message='Post details'
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337471
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414128
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491791
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383597
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399010
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368915
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399160
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444452
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383749
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382694
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352492
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460170
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368277
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367894
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398914
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 504461
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398981
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384144
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383049
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398788
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384245
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414540
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414155
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383764
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383741
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368290
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 520736
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383848
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429812
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475402
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444859
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414283
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490239
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490254
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444628
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383421
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384616
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353399
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384705
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414286
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414504
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338159
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414759
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428925
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383701
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398539
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398700
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369152
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413836
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399063
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413680
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429844
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337755
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459430
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414368
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383590
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444275
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383728
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398946
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353173
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414348
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337670
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384080
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398626
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413730
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444829
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398825
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383527
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383669
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399030
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368119
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414609
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383482
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413785
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383678
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413817
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352831
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353117
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398714
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490200
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367868
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399118
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383990
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322380
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383516
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413903
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384408
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414104
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414654
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352300
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399135
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429291
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383652
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475289
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368204
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414207
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353097
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413927
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444002
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321843
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398576
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 153709
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490068
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368559
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429940
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383631
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429703
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505199
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459671
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398636
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353895
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430136
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474818
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383099
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413507
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429587
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368278
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368416
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505284
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414180
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383541
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353415
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398872
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474918
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444545
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474460
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384226
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383166
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368472
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 107370
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399127
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383391
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352864
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398494
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352944
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384016
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368331
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337686
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367274
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445344
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368190
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474856
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 354020
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383103
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414223
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460105
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414240
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367794
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322197
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337774
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383262
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353249
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413871
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460493
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399077
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 506484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338048
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383457
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459707
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352770
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445486
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383619
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430056
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382967
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383208
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382828
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414375
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383384
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398964
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460074
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444401
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429100
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368163
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445191
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429424
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399381
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336688
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383256
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475568
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491313
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 489942
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338451
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368320
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444398
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 476067
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399189
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398617
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369003
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398690
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428716
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367959
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352522
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414524
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353346
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413912
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383246
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368311
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384365
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428754
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338060
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383662
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353508
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337487
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322396
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353480
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383706
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414296
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384203
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337015
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398971
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382798
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368902
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384073
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 429 165
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337471
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414128
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491791
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383597
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399010
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368915
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399160
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444452
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383749
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382694
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352492
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460170
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368277
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367894
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398914
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 504461
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398981
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384144
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383049
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398788
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384245
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414540
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414155
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383764
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383741
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368290
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 520736
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383848
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429812
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475402
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444859
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414283
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490239
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490254
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444628
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383421
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384616
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353399
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384705
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414286
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414504
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338159
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414759
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428925
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383701
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398539
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398700
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369152
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413836
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399063
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413680
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429844
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337755
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459430
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414368
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383590
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444275
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383728
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398946
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353173
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414348
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337670
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384080
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398626
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413730
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444829
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398825
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383527
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383669
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399030
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368119
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414609
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383482
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413785
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383678
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413817
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352831
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353117
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398714
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490200
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367868
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399118
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383990
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322380
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383516
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413903
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384408
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414104
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414654
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352300
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399135
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429291
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383652
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475289
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368204
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414207
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353097
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413927
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444002
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321843
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398576
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 153709
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490068
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368559
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429940
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383631
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429703
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505199
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459671
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398636
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353895
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430136
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474818
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383099
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413507
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429587
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368278
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368416
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505284
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414180
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383541
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353415
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398872
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474918
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444545
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474460
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384226
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383166
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368472
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 107370
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399127
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383391
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352864
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398494
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352944
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384016
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368331
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337686
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367274
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445344
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368190
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474856
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 354020
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383103
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414223
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460105
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414240
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367794
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322197
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337774
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383262
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353249
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413871
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460493
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399077
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 506484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338048
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383457
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459707
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352770
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445486
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383619
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430056
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382967
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383208
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382828
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414375
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383384
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398964
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460074
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444401
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429100
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368163
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445191
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429424
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399381
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336688
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383256
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475568
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491313
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 489942
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338451
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368320
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444398
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 476067
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399189
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398617
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369003
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398690
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428716
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367959
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352522
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414524
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353346
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413912
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383246
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368311
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384365
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428754
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338060
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383662
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353508
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337487
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322396
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353480
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383706
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414296
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384203
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337015
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398971
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382798
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368902
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384073
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460710
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 61606
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384255
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399048
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459659
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444689
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322938
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428845
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353485
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429246
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352479
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399801
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429496
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399400
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383201
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383482
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368293
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368701
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459822
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398108
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353303
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398901
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429627
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444416
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429486
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383781
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383657
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414177
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352813
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443640
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413874
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413532
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368131
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338546
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322608
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414190
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352516
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 415062
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368832
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369495
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399172
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414936
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445003
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352945
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383623
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338033
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338173
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352815
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414596
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368327
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413644
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369111
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368319
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352735
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398729
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383267
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383404
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384163
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383514
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414413
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384217
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383000
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 351762
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 92271
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383667
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429067
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352343
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383350
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383164
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353388
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429986
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382770
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367762
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398723
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336081
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352561
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 476200
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322162
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398461
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398948
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475239
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352477
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367946
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414553
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398723
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413796
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383681
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353207
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383632
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414573
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353154
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399060
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322555
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368221
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384169
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398403
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383226
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 307150
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413666
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399154
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384536
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367265
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367999
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383495
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368426
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384315
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352954
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337127
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322583
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383330
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443925
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337654
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368850
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367454
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352892
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444401
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383571
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398731
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445336
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338934
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352700
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367842
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429976
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352488
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429385
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444000
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398941
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460018
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383640
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413783
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337061
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398860
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337390
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398492
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 351518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384119
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383893
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414716
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383721
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445717
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353104
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383294
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 320987
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459988
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429329
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 307132
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383747
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322172
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368211
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443607
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384509
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444499
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 506175
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368666
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368710
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414447
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383059
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383641
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353342
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352726
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353306
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382886
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490363
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383357
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398295
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352984
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459748
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352513
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337471
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414128
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491791
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383597
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399010
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368915
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399160
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444452
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383749
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352580
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382694
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352492
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460170
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368277
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367894
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398914
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 504461
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398981
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384144
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383049
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398788
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384245
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414540
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414155
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383764
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383741
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368290
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 520736
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383848
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429812
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475402
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444859
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414283
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490239
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413935
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490254
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444628
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383421
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384616
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353399
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384705
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414286
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414504
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338159
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414979
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399807
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414759
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428925
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383820
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383701
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398539
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398700
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369152
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413836
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399063
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413680
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383593
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429844
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337755
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459430
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414368
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383590
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444275
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368411
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383728
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398946
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353173
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414348
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337670
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384080
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398626
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413730
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444829
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398825
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383527
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383669
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399030
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368119
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414609
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399116
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383482
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413785
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383678
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413817
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352831
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353117
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398714
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490200
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367868
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399118
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383990
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444570
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322380
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383516
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413903
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384408
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414104
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414654
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352300
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399135
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429291
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383652
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475289
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368204
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414207
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353097
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413927
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444002
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 321843
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398576
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336420
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 153709
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 490068
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368559
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429940
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383631
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429703
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505199
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459671
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398636
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353895
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399024
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430136
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474818
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383099
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413507
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429587
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414933
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368278
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352431
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368416
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 505284
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414180
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383541
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398887
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398827
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353415
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398872
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474918
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444545
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383503
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474460
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384226
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383166
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368472
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 107370
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399127
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414263
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383391
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352864
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398494
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352944
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384016
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368331
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337686
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367274
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445344
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368190
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384229
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474856
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 354020
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383103
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414223
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460105
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414240
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367794
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322197
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383569
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398684
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353474
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337774
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383262
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353249
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413871
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460493
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399077
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 506484
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398551
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338048
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383341
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383457
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459707
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352770
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445486
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383619
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 430056
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382967
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383208
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382828
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414375
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383384
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398964
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460074
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444401
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429100
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368163
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445191
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429424
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399381
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336688
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383256
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475568
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 491313
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 489942
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414013
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398810
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338451
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368320
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444398
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 476067
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399189
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398617
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369003
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413760
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398690
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459994
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428716
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367959
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352522
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414524
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353346
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413912
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383246
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368311
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384365
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428754
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338060
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337648
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383662
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353508
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337487
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322396
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353480
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383706
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414296
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384203
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337015
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398971
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382798
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368902
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384073
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460710
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 61606
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384255
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399048
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459659
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444689
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322938
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 428845
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353485
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429246
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352479
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399801
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429496
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399400
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383201
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383482
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368293
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368701
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459822
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398108
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353303
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398901
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429627
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444416
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429486
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383781
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383657
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414177
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352813
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443640
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413874
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413532
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368131
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338546
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322608
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414190
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352516
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 415062
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368832
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369495
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399172
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414936
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445003
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352745
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352945
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383623
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338033
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338173
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352815
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414596
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368327
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413644
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 369111
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368319
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352735
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398729
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383267
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383404
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384163
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383514
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414413
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 474819
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384217
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383000
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 351762
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 92271
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383667
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429067
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352343
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383350
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383164
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353388
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429986
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 382770
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367762
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398723
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 336081
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352561
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 476200
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322162
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398461
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398948
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 475239
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352477
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367946
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414553
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398723
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413796
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383681
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353207
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383632
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414573
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353154
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399060
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322555
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368221
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384169
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322337
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398403
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383226
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 307150
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413666
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399154
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384536
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367265
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367999
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383495
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368426
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384315
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352954
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337127
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322583
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 261043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429288
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383330
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443925
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337654
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368850
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367454
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352892
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444401
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383571
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398731
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445336
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 338934
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352700
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 367842
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429976
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352488
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429385
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444000
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398941
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 460018
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383640
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 413783
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337061
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398860
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 337390
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 398492
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 351518
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384119
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383893
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414716
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383721
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 445717
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353104
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383294
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 320987
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 459988
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 399195
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 429329
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 307132
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383747
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 322172
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368211
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 443607
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 384509
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 444499
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 506175
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368666
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 368710
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 414447
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383059
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 383641
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 353342
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG:urllib3.connectionpool:https://api-inference.huggingface.co:443 "POST /pipeline/feature-extraction/bert-base-uncased HTTP/1.1" 200 352726
DEBUG:matplotlib.pyplot:Loaded backend macosx version unknown.
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0.
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGunjalaGondi-Regular.otf', name='Noto Sans Gunjala Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Geneva.ttf', name='Geneva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.595454545454545
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifYezidi-Regular.otf', name='Noto Serif Yezidi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Academy Engraved LET Fonts.ttf', name='Academy Engraved LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMasaramGondi-Regular.otf', name='Noto Sans Masaram Gondi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Courier.ttc', name='Courier', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansWancho-Regular.ttf', name='Noto Sans Wancho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompact.ttf', name='.SF Compact', style='normal', variant='normal', weight=1000, stretch='normal', size='scalable')) = 10.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Monaco.ttf', name='Monaco', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactItalic.ttf', name='.SF Compact', style='italic', variant='normal', weight=1000, stretch='normal', size='scalable')) = 11.62
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFArabic.ttf', name='.SF Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PartyLET-plain.ttf', name='Party LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=295, stretch='normal', size='scalable')) = 10.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=295, stretch='normal', size='scalable')) = 11.14975
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
DEBUG:matplotlib.font_manager:findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=4.0 to DejaVu Sans ('/Users/aakash/miniconda3/envs/leviathan-dev/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
